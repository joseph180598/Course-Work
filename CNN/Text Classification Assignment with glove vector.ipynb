{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDMgSstPYv0P"
   },
   "source": [
    "# Text Classification:\n",
    "\n",
    "## Data\n",
    "<pre>\n",
    "1. we have total of 20 types of documents(Text files) and total 18828 documents(text files).\n",
    "2. You can download data from this <a href='https://drive.google.com/open?id=1rxD15nyeIPIAZ-J2VYPrDRZI66-TBWvM'>link</a>, in that you will get documents.rar folder. <br>If you unzip that, you will get total of 18828 documnets. document name is defined as'ClassLabel_DocumentNumberInThatLabel'. \n",
    "so from document name, you can extract the label for that document.\n",
    "4. Now our problem is to classify all the documents into any one of the class.\n",
    "5. Below we provided count plot of all the labels in our data. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64U9NzWFYv0V",
    "outputId": "f3f19ed2-f637-4a8c-cff7-40a603025e96"
   },
   "outputs": [],
   "source": [
    "### count plot of all the class labels. \n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.chunk import ne_chunk\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mK4TJOFYv0h"
   },
   "source": [
    "## Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VlqYFVI3Yv0k"
   },
   "source": [
    "#### sample document\n",
    "<pre>\n",
    "<font color='blue'>\n",
    "Subject: A word of advice\n",
    "From: jcopelan@nyx.cs.du.edu (The One and Only)\n",
    "\n",
    "In article < 65882@mimsy.umd.edu > mangoe@cs.umd.edu (Charley Wingate) writes:\n",
    ">\n",
    ">I've said 100 times that there is no \"alternative\" that should think you\n",
    ">might have caught on by now.  And there is no \"alternative\", but the point\n",
    ">is, \"rationality\" isn't an alternative either.  The problems of metaphysical\n",
    ">and religious knowledge are unsolvable-- or I should say, humans cannot\n",
    ">solve them.\n",
    "\n",
    "How does that saying go: Those who say it can't be done shouldn't interrupt\n",
    "those who are doing it.\n",
    "\n",
    "Jim\n",
    "--\n",
    "Have you washed your brain today?\n",
    "</font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAR5HoR1Yv0m"
   },
   "source": [
    "### Preprocessing:\n",
    "<pre>\n",
    "useful links: <a href='http://www.pyregex.com/'>http://www.pyregex.com/</a>\n",
    "\n",
    "<font color='blue'><b>1.</b></font> Find all emails in the document and then get the text after the \"@\". and then split those texts by '.' \n",
    "after that remove the words whose length is less than or equal to 2 and also remove'com' word and then combine those words by space. \n",
    "In one doc, if we have 2 or more mails, get all.\n",
    "<b>Eg:[test@dm1.d.com, test2@dm2.dm3.com]-->[dm1.d.com, dm3.dm4.com]-->[dm1,d,com,dm2,dm3,com]-->[dm1,dm2,dm3]-->\"dm1 dm2 dm3\" </b> \n",
    "append all those into one list/array. ( This will give length of 18828 sentences i.e one list for each of the document). \n",
    "Some sample output was shown below. \n",
    "\n",
    "> In the above sample document there are emails [jcopelan@nyx.cs.du.edu, 65882@mimsy.umd.edu, mangoe@cs.umd.edu]\n",
    "\n",
    "preprocessing:\n",
    "[jcopelan@nyx.cs.du.edu, 65882@mimsy.umd.edu, mangoe@cs.umd.edu] ==> [nyx cs du edu mimsy umd edu cs umd edu] ==> \n",
    "[nyx edu mimsy umd edu umd edu]\n",
    "\n",
    "<font color='blue'><b>2.</b></font> Replace all the emails by space in the original text. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KavKDD9FYv0p",
    "outputId": "0b87ab7b-46df-4995-eaca-4f5831ad223e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['juliet caltech edu',\n",
       "       'coding bchs edu newsgate sps mot austlcm sps mot austlcm sps mot com  dna bchs edu',\n",
       "       'batman bmd trw', ..., 'rbdc wsnc org dscomsa desy zeus  desy',\n",
       "       'rbdc wsnc org morrow stanford edu pangea Stanford EDU',\n",
       "       'rbdc wsnc org apollo apollo'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have collected all emails and preprocessed them, this is sample output\n",
    "preprocessed_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obReqs55Yv0v",
    "outputId": "10770414-9be0-4d63-9587-5363a8c10c4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18828"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIovFDQzYv03"
   },
   "source": [
    "<pre>\n",
    "<font color='blue'><b>3.</b></font> Get subject of the text i.e. get the total lines where \"Subject:\" occur and remove \n",
    "the word which are before the \":\" remove the newlines, tabs, punctuations, any special chars.\n",
    "<b>Eg: if we have sentance like \"Subject: Re: Gospel Dating @ \\r\\r\\n\" --> You have to get \"Gospel Dating\"</b> \n",
    "Save all this data into another list/array. \n",
    "\n",
    "<font color='blue'><b>4.</b></font> After you store it in the list, Replace those sentances in original text by space.\n",
    "\n",
    "<font color='blue'><b>5.</b></font> Delete all the sentances where sentence starts with <b>\"Write to:\"</b> or <b>\"From:\"</b>.\n",
    "> In the above sample document check the 2nd line, we should remove that\n",
    "\n",
    "<font color='blue'><b>6.</b></font> Delete all the tags like \"< anyword >\"\n",
    "> In the above sample document check the 4nd line, we should remove that \"< 65882@mimsy.umd.edu >\"\n",
    "\n",
    "\n",
    "<font color='blue'><b>7.</b></font> Delete all the data which are present in the brackets. \n",
    "In many text data, we observed that, they maintained the explanation of sentence \n",
    "or translation of sentence to another language in brackets so remove all those.\n",
    "<b>Eg: \"AAIC-The course that gets you HIRED(AAIC - Der Kurs, der Sie anstellt)\" --> \"AAIC-The course that gets you HIRED\"</b>\n",
    "\n",
    "> In the above sample document check the 4nd line, we should remove that \"(Charley Wingate)\"\n",
    "\n",
    "\n",
    "<font color='blue'><b>8.</b></font> Remove all the newlines('\\n'), tabs('\\t'), \"-\", \"\\\".\n",
    "\n",
    "<font color='blue'><b>9.</b></font> Remove all the words which ends with <b>\":\"</b>.\n",
    "<b>Eg: \"Anyword:\"</b>\n",
    "> In the above sample document check the 4nd line, we should remove that \"writes:\"\n",
    "\n",
    "\n",
    "<font color='blue'><b>10.</b></font> Decontractions, replace words like below to full words. \n",
    "please check the donors choose preprocessing for this \n",
    "<b>Eg: can't -> can not, 's -> is, i've -> i have, i'm -> i am, you're -> you are, i'll --> i will </b>\n",
    "\n",
    "<b> There is no order to do point 6 to 10. but you have to get final output correctly</b>\n",
    "\n",
    "<font color='blue'><b>11.</b></font> Do chunking on the text you have after above preprocessing. \n",
    "Text chunking, also referred to as shallow parsing, is a task that \n",
    "follows Part-Of-Speech Tagging and that adds more structure to the sentence.\n",
    "So it combines the some phrases, named entities into single word.\n",
    "So after that combine all those phrases/named entities by separating <b>\"_\"</b>. \n",
    "And remove the phrases/named entities if that is a \"Person\". \n",
    "You can use <b>nltk.ne_chunk</b> to get these. \n",
    "Below we have given one example. please go through it. \n",
    "\n",
    "useful links: \n",
    "<a href='https://www.nltk.org/book/ch07.html'>https://www.nltk.org/book/ch07.html</a>\n",
    "<a href='https://stackoverflow.com/a/31837224/4084039'>https://stackoverflow.com/a/31837224/4084039</a>\n",
    "<a href='http://www.nltk.org/howto/tree.html'>http://www.nltk.org/howto/tree.html</a>\n",
    "<a href='https://stackoverflow.com/a/44294377/4084039'>https://stackoverflow.com/a/44294377/4084039</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lAaKQ6EYv04",
    "outputId": "53b66a94-acef-4002-e51c-002bde4178b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am living in the New York --> [('i', 'NN'), ('am', 'VBP'), ('living', 'VBG'), ('in', 'IN'), ('the', 'DT'), Tree('GPE', [('New', 'NNP'), ('York', 'NNP')])]\n",
      " \n",
      "--------------------------------------------------\n",
      " \n",
      "My name is Srikanth Varma --> [('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), Tree('PERSON', [('Srikanth', 'NNP'), ('Varma', 'NNP')])]\n"
     ]
    }
   ],
   "source": [
    "#i am living in the New York\n",
    "print(\"i am living in the New York -->\", list(chunks))\n",
    "print(\" \")\n",
    "print(\"-\"*50)\n",
    "print(\" \")\n",
    "#My name is Srikanth Varma\n",
    "print(\"My name is Srikanth Varma -->\", list(chunks1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XV8gzLUjYv0-"
   },
   "source": [
    "<pre>We did chunking for above two lines and then We got one list where each word is mapped to a \n",
    "POS(parts of speech) and also if you see \"New York\" and \"Srikanth Varma\", \n",
    "they got combined and represented as a tree and \"New York\" was referred as \"GPE\" and \"Srikanth Varma\" was referred as \"PERSON\". \n",
    "so now you have to Combine the \"New York\" with <b>\"_\"</b> i.e \"New_York\"\n",
    "and remove the \"Srikanth Varma\" from the above sentence because it is a person.</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpaC-KF3Yv1A"
   },
   "source": [
    "<pre>\n",
    "<font color='blue'><b>13.</b></font> Replace all the digits with space i.e delete all the digits. \n",
    "> In the above sample document, the 6th line have digit 100, so we have to remove that.\n",
    "\n",
    "<font color='blue'><b>14.</b></font> After doing above points, we observed there might be few word's like\n",
    " <b> \"_word_\" (i.e starting and ending with the _), \"_word\" (i.e starting with the _),\n",
    "  \"word_\" (i.e ending with the _)</b> remove the <b>_</b> from these type of words. \n",
    "\n",
    "<font color='blue'><b>15.</b></font>  We also observed some words like <b> \"OneLetter_word\"- eg: d_berlin, \n",
    "\"TwoLetters_word\" - eg: dr_berlin </b>, in these words we remove the \"OneLetter_\" (d_berlin ==> berlin) and \n",
    "\"TwoLetters_\" (de_berlin ==> berlin). i.e remove the words \n",
    "which are length less than or equal to 2 after spliiting those words by \"_\". \n",
    "\n",
    "<font color='blue'><b>16.</b></font> Convert all the words into lower case and lowe case \n",
    "and remove the words which are greater than or equal to 15 or less than or equal to 2.\n",
    "\n",
    "<font color='blue'><b>17.</b></font> replace all the words except \"A-Za-z_\" with space. \n",
    "\n",
    "<font color='blue'><b>18.</b></font> Now You got Preprocessed Text, email, subject. create a dataframe with those. \n",
    "Below are the columns of the df. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hB43OGEfYv1C",
    "outputId": "945bc8a4-1f99-4410-94c8-c776a405b5f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'class', 'preprocessed_text', 'preprocessed_subject',\n",
      "       'preprocessed_emails'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AM6A19xFYv1I",
    "outputId": "9de13fa8-6604-49a2-8013-6b22f0a256a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                    From: arc1@ukc.ac.uk (Tony Curtis)\\r\\r\\r\\nSubj...\n",
      "class                                                         alt.atheism\n",
      "preprocessed_text       said re is article if followed the quoting rig...\n",
      "preprocessed_subject                                christian morality is\n",
      "preprocessed_emails                                   ukc mac macalstr edu\n",
      "Name: 567, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data.iloc[400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfWUeIN1Yv1N"
   },
   "source": [
    "### To get above mentioned data frame --> Try to Write Total Preprocessing steps in One Function Named Preprocess as below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEGEHTNQYv1N"
   },
   "outputs": [],
   "source": [
    "def preprocess(Input_Text):\n",
    "    \"\"\"Do all the Preprocessing as shown above and\n",
    "    return a tuple contain preprocess_email,preprocess_subject,preprocess_text for that Text_data\"\"\"\n",
    "    \n",
    "    pattern=r'([a-zA-Z0-9\\-\\.]+@[a-zA-z\\.]{2,})'\n",
    "    email_id=re.findall(pattern, Input_Text, flags=re.M|re.I)\n",
    "    \n",
    "    email_file=[]\n",
    "    for ids in email_id:\n",
    "        e_ids=ids.split('@')[1]\n",
    "        #print(e_ids)\n",
    "        domain=e_ids.split('.')\n",
    "        domain=' '.join(list(d for d in domain if (len(d)>2 and d!='com')))\n",
    "        email_file.append(domain)\n",
    "     \n",
    "    email_file=' '.join(email_file)\n",
    "    #print(email_file)\n",
    "    \n",
    "    #Replacing email with space\n",
    "    pattern=r'([a-zA-Z0-9\\-\\.]+@[a-zA-z\\.]{2,})'\n",
    "    Input_Text=re.sub(pattern,' ',Input_Text)\n",
    "    \n",
    "    #Input_Text\n",
    "    \n",
    "    #Extracting the subject>Removing any word before :>Then remove any character other than a-zA-Z\n",
    "    pattern_1=r'subject:.+'\n",
    "    data=re.findall(pattern_1, Input_Text, flags=re.M|re.I)\n",
    "    pattern_2=r'[a-zA-Z]+:'\n",
    "    text=re.sub(pattern_2,'',data[0])\n",
    "    pattern_3=r'[^a-zA-z]'\n",
    "    text=re.sub(pattern_3,' ',text,flags=re.M|re.I)\n",
    "    \n",
    "    subject=text.lower()\n",
    "    \n",
    "    #Removing the whole content from the text\n",
    "    pattern_1=r'(subject:.+)|(From:.+)|(Write to:.+)'\n",
    "    Input_Text=re.sub(pattern_1,' ',Input_Text)\n",
    "    \n",
    "    pattern_3=r'(<.+>)|(\\(.+\\))|(\\(.+\\))'\n",
    "    Input_Text=re.sub(pattern_3,'',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_4=r'\\b[a-z]+:'\n",
    "    Input_Text=re.sub(pattern_4,'',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_5=r'[\\r\\n]|[\\r\\t]'\n",
    "    Input_Text=re.sub(pattern_5,' ',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_6=r'>+|\\\\+|-+|\\\\|\\\"|,|\\?'\n",
    "    Input_Text=re.sub(pattern_6,'',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_8=r'\\'ve'\n",
    "    Input_Text=re.sub(pattern_8,' have',Input_Text,flags=re.M|re.I)\n",
    "\n",
    "    pattern_9=r'can\\'t'\n",
    "    Input_Text=re.sub(pattern_9,'can not',Input_Text,flags=re.M|re.I)\n",
    "\n",
    "    pattern_10=r'\\'s'\n",
    "    Input_Text=re.sub(pattern_10,'is',Input_Text,flags=re.M|re.I)\n",
    "\n",
    "    pattern_11=r'i\\'ve'\n",
    "    Input_Text=re.sub(pattern_11,'have',Input_Text,flags=re.M|re.I)\n",
    "\n",
    "    pattern_11=r'i\\'m'\n",
    "    Input_Text=re.sub(pattern_11,'i am',Input_Text,flags=re.M|re.I)\n",
    "\n",
    "    pattern_11=r'you\\'re'\n",
    "    Input_Text=re.sub(pattern_11,'you are',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_11=r'i\\'ll'\n",
    "    Input_Text=re.sub(pattern_11,'i will',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_11=r'\\'ll'\n",
    "    Input_Text=re.sub(pattern_11,' will',Input_Text,flags=re.M|re.I)\n",
    "   \n",
    "    pattern_12=r'_[a-zA-Z]+_'\n",
    "    values=re.findall(pattern_12,Input_Text,flags=re.M|re.I)\n",
    "    for x in values:\n",
    "        i=x.split('_')\n",
    "        i=[x for x in i if len(x)>=2]\n",
    "        for word in i:\n",
    "            Input_Text=re.sub(x,word,Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_12=r'[a-zA-Z]+_ '\n",
    "    values=re.findall(pattern_12,Input_Text,flags=re.M|re.I)\n",
    "    for x in values:\n",
    "        i=x.split('_')\n",
    "        i=[x for x in i if len(x)>=2]\n",
    "        for word in i:\n",
    "            Input_Text=re.sub(x,word+' ',Input_Text,flags=re.M|re.I)\n",
    "         \n",
    "    pattern_12=r'[a-zA-Z]{0,2}_[a-zA-Z]+'\n",
    "    values=re.findall(pattern_12,Input_Text,flags=re.M|re.I)\n",
    "    for x in values:\n",
    "        i=x.split('_')\n",
    "        i=[x for x in i if len(x)>2]\n",
    "        for word in i:\n",
    "            if len(i)==0:\n",
    "                Input_Text=re.sub(x,' ',Input_Text,flags=re.M|re.I)\n",
    "            else:\n",
    "                Input_Text=re.sub(x,str(word+' '),Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    tokens=nltk.word_tokenize(Input_Text)\n",
    "    pos=nltk.pos_tag(tokens)\n",
    "    chunks=ne_chunk(pos, binary=False)\n",
    "\n",
    "    named_entities=[]\n",
    "    person_entities=[]\n",
    "    for t in chunks.subtrees():\n",
    "        if t.label() == 'PERSON':\n",
    "            person_entities.append(list(t))\n",
    "        \n",
    "    for entity in person_entities:\n",
    "        word=[entity[x][0] for x in range(len(entity))]\n",
    "        pattern=re.escape(str(' '.join(word)))\n",
    "        #print(pattern)\n",
    "        Input_Text=re.sub(pattern,'',Input_Text)\n",
    "    \n",
    "\n",
    "    for t in chunks.subtrees():\n",
    "        if t.label() == 'GPE':\n",
    "            named_entities.append(list(t))\n",
    "        \n",
    "    for entity in named_entities:\n",
    "        word=[entity[x][0] for x in range(len(entity))]\n",
    "        pattern=re.escape(str(' '.join(word)))\n",
    "        Input_Text=re.sub(pattern,'_'.join(word),Input_Text)\n",
    "    \n",
    "    pattern_12=r'(\\b\\w{1}\\b)|(\\w{15,})'\n",
    "    Input_Text=re.sub(pattern_12,'',Input_Text,flags=re.M|re.I)\n",
    "\n",
    "    Input_Text=Input_Text.lower()\n",
    "\n",
    "    pattern_12=r'[^a-zA-Z_]'\n",
    "    Input_Text=re.sub(pattern_12,' ',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_7=r' +'\n",
    "    Input_Text=re.sub(pattern_7,' ',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    pattern_11=r' \\w{1} '\n",
    "    Input_Text=re.sub(pattern_11,'',Input_Text,flags=re.M|re.I)\n",
    "    \n",
    "    processed_text=Input_Text\n",
    "    return (email_file,subject,processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mantis netcom mantis', ' alt atheism  atheist resources', ' alt atheism atheist resources archive atheism resources resources last december atheist resources addresses of atheist organizations usa freedom from religion foundation fish bumper stickers and assorted other atheist paraphernalia are available from the freedom from religion foundation in the us evolution designs evolution designs sell the fish itis fish symbol like the ones stick on their cars but with feet and the word written inside the deluxe mouldedplastic fish is postpaid in the us ca people in the san francisco bay area can get fish from try mailing for net people who go to directly the price is per fish american atheist press aap publish various atheist books critiques of the bible lists of biblical contradictions and so on one such book the bible handbook by and american atheist press pp isbn nd edition bible contradictions absurdities atrocities immoralities contains the bible contradicts itself aap based on the king version of the bible tx prometheus books sell books including an alternate address prometheus books ny for humanism an organization promoting black secular humanism and uncovering the history of black freethought they publish quarterly newsletter aah examiner ny united kingdom rationalist press association national secular society street holloway roadewnl british humanist association south place ethical society lambis conduit passage conway hall wcrh red lion square wcrl fax the national secular society publish the freethinker monthly magazine founded in germany ibka bund der undberlin germany ibka publish miz materialien und zur zeit politisches journal der und ibka mizvertrieb postfachberlin germany for atheist books write ibdk bucherdienst derhannover germany books fiction thomas disch the claus compromise short story the ultimate proof that exists all characters and events are fictitious any similarity to living or dead gods uh well walter canticle for leibowitz one gem in this post atomic doomsday novel is the monks who spent their lives copying blueprints from filling the sheets of paper with ink and leaving white lines and letters edgar pangborn atomic doomsday novel set in clerical states the church for example forbids that anyone produce describe or use any substance containing atoms philip dick wrote many philosophical and short stories and novels his stories are bizarre at times but very approachable he wrote mainly sf but he wrote about people truth and religion rather than technology although he often believed that he had met some sort of he remained sceptical amongst his novels the following are of some galactic pothealer fallible alien deity summons group of craftsmen and women to remote planet to raise giant cathedral from beneath the oceans when the deity begins to demand faith from the earthers pothealer is unable to comply polished ironic and amusing novel maze of for its description of religion valis the schizophrenic hero searches for the hidden mysteries of gnostic ity after reality is fired into his brain by pink laser beam of unknown but possibly divine origin he is accompanied by his dogmatic and dismissively atheist friend and assorted other odd characters the divine invasion invades by making young woman pregnant as she returns from another star system unfortunately she is terminally ill and must be assisted by dead man whose brain is wired to hour easy listening music margaret atwood the handmaidis tale story based on the premise that the us congress is mysteriously assassinated and quickly take charge of the nation to set it right again the book is the diary of womanis life as she tries to live under the new theocracy right to own property is revoked and their bank accounts are closed sinful luxuries are outlawed and the radio is only used for readings from the bible crimes are punished doctors who performed legal abortions in the old world are hunted down and hanged atwoodis writing style is difficult to get used to at first but the tale grows more and more chilling as it goes on various authors the bible this somewhat dull and rambling work has often been criticized however it is probably worth reading if only so that you will know what all the fuss is about it exists in many different versions so make sure you get the one true version books nonfiction peter de rosa vicars of christ bantam press although de seems to be or even catholic this is very enlighting history of papal immoralities adulteries fallacies etc german gottes erste dunkle seite des droemerknaur michael martin philosophical justification temple university press philadelphia usa detailed and scholarly justification of atheism contains an outstanding appendix defining terminology and usage in this tendentious area argues both for negative atheism the nonbelief in the existence of god and also for positive atheism the belief in the nonexistence of god includes great refutations of the most challenging arguments for god particular attention is paid to refuting contempory theists such as and swinburne pages isbn the case against ity temple university press comprehensive critique of ity in which he considers the best contemporary defences of ity and demonstrates that they are unsupportable and or incoherent pages isbn james turner without the johns hopkins university press baltimore md usa subtitled the origins of unbelief in america examines the way in which unbelief became mainstream alternative worldview focusses on the period and while considering france and britain the emphasis is on american and particularly new_england developments neither religious history of secularization or atheism without is rather the intellectual history of the fate of single idea the belief that exists pages isbn george seldes the great thoughts antine books new york usa dictionary of quotations of different kind concentrating on statements and writings which explicitly or implicitly present the personis philosophy and worldview includes obscure opinions from many people for some popular observations traces the way in which various people expressed and twisted the idea over the centuries quite number of the quotations are derived from what of religion and views of religion pages isbnswinburne the existence of clarendon paperbacks oxford this book is the second volume in trilogy that began with the coherence of theism in this work swinburne attempts to construct series of inductive arguments for the existence of his arguments which are somewhat tendentious and rely upon the imputation of late th century western values and aesthetics to which is supposedly as simple as can be conceived were decisively rejected in is the miracle of theism in the revised edition of the existence of swinburne includes an appendix in which he makes somewhat incoherent attempt to rebut mackie the miracle of theism oxford this volume contains comprehensive review of the principal arguments for and against the existence of it ranges from the classical philosophical positions of et al through the moral arguments of newman kant and to the recent restatements of the classical theses by and swinburne it also addresses those positions which push the concept of beyond the realm of the rational such as those of kierkegaard kung and as well as replacements for such as lelieis axiarchism the book is delight to read less formalistic and better written than works and refreshingly direct when compared with the handwaving of swinburne james haught holy an illustrated history of religious murder and madness prometheus books looks at religious persecution from ancient times to the present day and not only by library of congress catalog card number norm allen jr african american an the listing for african americans for humanism above gordon stein an anthology of atheism and anthology covering wide range of subjects including the devil evil and morality and the history of freethought comprehensive bibliography edmund cohen the mind of the biblebeliever prometheus books study of why people become and what effect it has on them net resources thereis small mailbased archive server at mantis co uk which carries archives of old alt atheism moderated articles and assorted other files for more information send mail to saying help send atheism index and it will mail back reply mathew ')\n"
     ]
    }
   ],
   "source": [
    "data=open('documents/alt.atheism_49960.txt')\n",
    "text=data.read()\n",
    "print(preprocess(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: mathew <mathew@mantis.co.uk>\\nSubject: Alt.Atheism FAQ: Atheist Resources\\n\\nArchive-name: atheism/resources\\nAlt-atheism-archive-name: resources\\nLast-modified: 11 December 1992\\nVersion: 1.0\\n\\n                              Atheist Resources\\n\\n                      Addresses of Atheist Organizations\\n\\n                                     USA\\n\\nFREEDOM FROM RELIGION FOUNDATION\\n\\nDarwin fish bumper stickers and assorted other atheist paraphernalia are\\navailable from the Freedom From Religion Foundation in the US.\\n\\nWrite to:  FFRF, P.O. Box 750, Madison, WI 53701.\\nTelephone: (608) 256-8900\\n\\nEVOLUTION DESIGNS\\n\\nEvolution Designs sell the \"Darwin fish\".  It\\'s a fish symbol, like the ones\\nChristians stick on their cars, but with feet and the word \"Darwin\" written\\ninside.  The deluxe moulded 3D plastic fish is $4.95 postpaid in the US.\\n\\nWrite to:  Evolution Designs, 7119 Laurel Canyon #4, North Hollywood,\\n           CA 91605.\\n\\nPeople in the San Francisco Bay area can get Darwin Fish from Lynn Gold --\\ntry mailing <figmo@netcom.com>.  For net people who go to Lynn directly, the\\nprice is $4.95 per fish.\\n\\nAMERICAN ATHEIST PRESS\\n\\nAAP publish various atheist books -- critiques of the Bible, lists of\\nBiblical contradictions, and so on.  One such book is:\\n\\n\"The Bible Handbook\" by W.P. Ball and G.W. Foote.  American Atheist Press.\\n372 pp.  ISBN 0-910309-26-4, 2nd edition, 1986.  Bible contradictions,\\nabsurdities, atrocities, immoralities... contains Ball, Foote: \"The Bible\\nContradicts Itself\", AAP.  Based on the King James version of the Bible.\\n\\nWrite to:  American Atheist Press, P.O. Box 140195, Austin, TX 78714-0195.\\n      or:  7215 Cameron Road, Austin, TX 78752-2973.\\nTelephone: (512) 458-1244\\nFax:       (512) 467-9525\\n\\nPROMETHEUS BOOKS\\n\\nSell books including Haught\\'s \"Holy Horrors\" (see below).\\n\\nWrite to:  700 East Amherst Street, Buffalo, New York 14215.\\nTelephone: (716) 837-2475.\\n\\nAn alternate address (which may be newer or older) is:\\nPrometheus Books, 59 Glenn Drive, Buffalo, NY 14228-2197.\\n\\nAFRICAN-AMERICANS FOR HUMANISM\\n\\nAn organization promoting black secular humanism and uncovering the history of\\nblack freethought.  They publish a quarterly newsletter, AAH EXAMINER.\\n\\nWrite to:  Norm R. Allen, Jr., African Americans for Humanism, P.O. Box 664,\\n           Buffalo, NY 14226.\\n\\n                                United Kingdom\\n\\nRationalist Press Association          National Secular Society\\n88 Islington High Street               702 Holloway Road\\nLondon N1 8EW                          London N19 3NL\\n071 226 7251                           071 272 1266\\n\\nBritish Humanist Association           South Place Ethical Society\\n14 Lamb\\'s Conduit Passage              Conway Hall\\nLondon WC1R 4RH                        Red Lion Square\\n071 430 0908                           London WC1R 4RL\\nfax 071 430 1271                       071 831 7723\\n\\nThe National Secular Society publish \"The Freethinker\", a monthly magazine\\nfounded in 1881.\\n\\n                                   Germany\\n\\nIBKA e.V.\\nInternationaler Bund der Konfessionslosen und Atheisten\\nPostfach 880, D-1000 Berlin 41. Germany.\\n\\nIBKA publish a journal:\\nMIZ. (Materialien und Informationen zur Zeit. Politisches\\nJournal der Konfessionslosesn und Atheisten. Hrsg. IBKA e.V.)\\nMIZ-Vertrieb, Postfach 880, D-1000 Berlin 41. Germany.\\n\\nFor atheist books, write to:\\n\\nIBDK, Internationaler B\"ucherdienst der Konfessionslosen\\nPostfach 3005, D-3000 Hannover 1. Germany.\\nTelephone: 0511/211216\\n\\n\\n                               Books -- Fiction\\n\\nTHOMAS M. DISCH\\n\\n\"The Santa Claus Compromise\"\\nShort story.  The ultimate proof that Santa exists.  All characters and \\nevents are fictitious.  Any similarity to living or dead gods -- uh, well...\\n\\nWALTER M. MILLER, JR\\n\\n\"A Canticle for Leibowitz\"\\nOne gem in this post atomic doomsday novel is the monks who spent their lives\\ncopying blueprints from \"Saint Leibowitz\", filling the sheets of paper with\\nink and leaving white lines and letters.\\n\\nEDGAR PANGBORN\\n\\n\"Davy\"\\nPost atomic doomsday novel set in clerical states.  The church, for example,\\nforbids that anyone \"produce, describe or use any substance containing...\\natoms\". \\n\\nPHILIP K. DICK\\n\\nPhilip K. Dick Dick wrote many philosophical and thought-provoking short \\nstories and novels.  His stories are bizarre at times, but very approachable.\\nHe wrote mainly SF, but he wrote about people, truth and religion rather than\\ntechnology.  Although he often believed that he had met some sort of God, he\\nremained sceptical.  Amongst his novels, the following are of some relevance:\\n\\n\"Galactic Pot-Healer\"\\nA fallible alien deity summons a group of Earth craftsmen and women to a\\nremote planet to raise a giant cathedral from beneath the oceans.  When the\\ndeity begins to demand faith from the earthers, pot-healer Joe Fernwright is\\nunable to comply.  A polished, ironic and amusing novel.\\n\\n\"A Maze of Death\"\\nNoteworthy for its description of a technology-based religion.\\n\\n\"VALIS\"\\nThe schizophrenic hero searches for the hidden mysteries of Gnostic\\nChristianity after reality is fired into his brain by a pink laser beam of\\nunknown but possibly divine origin.  He is accompanied by his dogmatic and\\ndismissively atheist friend and assorted other odd characters.\\n\\n\"The Divine Invasion\"\\nGod invades Earth by making a young woman pregnant as she returns from\\nanother star system.  Unfortunately she is terminally ill, and must be\\nassisted by a dead man whose brain is wired to 24-hour easy listening music.\\n\\nMARGARET ATWOOD\\n\\n\"The Handmaid\\'s Tale\"\\nA story based on the premise that the US Congress is mysteriously\\nassassinated, and fundamentalists quickly take charge of the nation to set it\\n\"right\" again.  The book is the diary of a woman\\'s life as she tries to live\\nunder the new Christian theocracy.  Women\\'s right to own property is revoked,\\nand their bank accounts are closed; sinful luxuries are outlawed, and the\\nradio is only used for readings from the Bible.  Crimes are punished\\nretroactively: doctors who performed legal abortions in the \"old world\" are\\nhunted down and hanged.  Atwood\\'s writing style is difficult to get used to\\nat first, but the tale grows more and more chilling as it goes on.\\n\\nVARIOUS AUTHORS\\n\\n\"The Bible\"\\nThis somewhat dull and rambling work has often been criticized.  However, it\\nis probably worth reading, if only so that you\\'ll know what all the fuss is\\nabout.  It exists in many different versions, so make sure you get the one\\ntrue version.\\n\\n                             Books -- Non-fiction\\n\\nPETER DE ROSA\\n\\n\"Vicars of Christ\", Bantam Press, 1988\\nAlthough de Rosa seems to be Christian or even Catholic this is a very\\nenlighting history of papal immoralities, adulteries, fallacies etc.\\n(German translation: \"Gottes erste Diener. Die dunkle Seite des Papsttums\",\\nDroemer-Knaur, 1989)\\n\\nMICHAEL MARTIN\\n\\n\"Atheism: A Philosophical Justification\", Temple University Press,\\n Philadelphia, USA.\\nA detailed and scholarly justification of atheism.  Contains an outstanding\\nappendix defining terminology and usage in this (necessarily) tendentious\\narea.  Argues both for \"negative atheism\" (i.e. the \"non-belief in the\\nexistence of god(s)\") and also for \"positive atheism\" (\"the belief in the\\nnon-existence of god(s)\").  Includes great refutations of the most\\nchallenging arguments for god; particular attention is paid to refuting\\ncontempory theists such as Platinga and Swinburne.\\n541 pages. ISBN 0-87722-642-3 (hardcover; paperback also available)\\n\\n\"The Case Against Christianity\", Temple University Press\\nA comprehensive critique of Christianity, in which he considers\\nthe best contemporary defences of Christianity and (ultimately)\\ndemonstrates that they are unsupportable and/or incoherent.\\n273 pages. ISBN 0-87722-767-5\\n\\nJAMES TURNER\\n\\n\"Without God, Without Creed\", The Johns Hopkins University Press, Baltimore,\\n MD, USA\\nSubtitled \"The Origins of Unbelief in America\".  Examines the way in which\\nunbelief (whether agnostic or atheistic)  became a mainstream alternative\\nworld-view.  Focusses on the period 1770-1900, and while considering France\\nand Britain the emphasis is on American, and particularly New England\\ndevelopments.  \"Neither a religious history of secularization or atheism,\\nWithout God, Without Creed is, rather, the intellectual history of the fate\\nof a single idea, the belief that God exists.\" \\n316 pages. ISBN (hardcover) 0-8018-2494-X (paper) 0-8018-3407-4\\n\\nGEORGE SELDES (Editor)\\n\\n\"The great thoughts\", Ballantine Books, New York, USA\\nA \"dictionary of quotations\" of a different kind, concentrating on statements\\nand writings which, explicitly or implicitly, present the person\\'s philosophy\\nand world-view.  Includes obscure (and often suppressed) opinions from many\\npeople.  For some popular observations, traces the way in which various\\npeople expressed and twisted the idea over the centuries.  Quite a number of\\nthe quotations are derived from Cardiff\\'s \"What Great Men Think of Religion\"\\nand Noyes\\' \"Views of Religion\".\\n490 pages. ISBN (paper) 0-345-29887-X.\\n\\nRICHARD SWINBURNE\\n\\n\"The Existence of God (Revised Edition)\", Clarendon Paperbacks, Oxford\\nThis book is the second volume in a trilogy that began with \"The Coherence of\\nTheism\" (1977) and was concluded with \"Faith and Reason\" (1981).  In this\\nwork, Swinburne attempts to construct a series of inductive arguments for the\\nexistence of God.  His arguments, which are somewhat tendentious and rely\\nupon the imputation of late 20th century western Christian values and\\naesthetics to a God which is supposedly as simple as can be conceived, were\\ndecisively rejected in Mackie\\'s \"The Miracle of Theism\".  In the revised\\nedition of \"The Existence of God\", Swinburne includes an Appendix in which he\\nmakes a somewhat incoherent attempt to rebut Mackie.\\n\\nJ. L. MACKIE\\n\\n\"The Miracle of Theism\", Oxford\\nThis (posthumous) volume contains a comprehensive review of the principal\\narguments for and against the existence of God.  It ranges from the classical\\nphilosophical positions of Descartes, Anselm, Berkeley, Hume et al, through\\nthe moral arguments of Newman, Kant and Sidgwick, to the recent restatements\\nof the classical theses by Plantinga and Swinburne.  It also addresses those\\npositions which push the concept of God beyond the realm of the rational,\\nsuch as those of Kierkegaard, Kung and Philips, as well as \"replacements for\\nGod\" such as Lelie\\'s axiarchism.  The book is a delight to read - less\\nformalistic and better written than Martin\\'s works, and refreshingly direct\\nwhen compared with the hand-waving of Swinburne.\\n\\nJAMES A. HAUGHT\\n\\n\"Holy Horrors: An Illustrated History of Religious Murder and Madness\",\\n Prometheus Books\\nLooks at religious persecution from ancient times to the present day -- and\\nnot only by Christians.\\nLibrary of Congress Catalog Card Number 89-64079. 1990.\\n\\nNORM R. ALLEN, JR.\\n\\n\"African American Humanism: an Anthology\"\\nSee the listing for African Americans for Humanism above.\\n\\nGORDON STEIN\\n\\n\"An Anthology of Atheism and Rationalism\", Prometheus Books\\nAn anthology covering a wide range of subjects, including \\'The Devil, Evil\\nand Morality\\' and \\'The History of Freethought\\'.  Comprehensive bibliography.\\n\\nEDMUND D. COHEN\\n\\n\"The Mind of The Bible-Believer\", Prometheus Books\\nA study of why people become Christian fundamentalists, and what effect it\\nhas on them.\\n\\n                                Net Resources\\n\\nThere\\'s a small mail-based archive server at mantis.co.uk which carries\\narchives of old alt.atheism.moderated articles and assorted other files.  For\\nmore information, send mail to archive-server@mantis.co.uk saying\\n\\n   help\\n   send atheism/index\\n\\nand it will mail back a reply.\\n\\n\\nmathew\\nÿ\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=open('documents/alt.atheism_49960.txt')\n",
    "text=data.read()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 18828/18828 [38:35<00:00,  8.13it/s]\n"
     ]
    }
   ],
   "source": [
    "folder=os.listdir('documents')\n",
    "\n",
    "raw_text=[]\n",
    "email_data=[]\n",
    "subject_data=[]\n",
    "processed_text=[]\n",
    "file_name=[]\n",
    "class_details=[]\n",
    "\n",
    "for file in tqdm(folder):\n",
    "    class_name=file.split('_')[0]\n",
    "    doc_name=file.split('_')[1]\n",
    "    \n",
    "    data=open('documents/'+file)\n",
    "    input_text=data.read()\n",
    "    \n",
    "    email_file,subject,final_text=preprocess(input_text)\n",
    "    \n",
    "    raw_text.append(input_text)\n",
    "    email_data.append(email_file)\n",
    "    subject_data.append(subject)\n",
    "    processed_text.append(final_text)\n",
    "    file_name.append(doc_name)\n",
    "    class_details.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=[raw_text,\n",
    "email_data,\n",
    "subject_data,\n",
    "processed_text,\n",
    "file_name,\n",
    "class_details]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_data.pickle','wb') as fe_data_file:\n",
    "     pickle.dump(final_data, fe_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_data.pickle','rb') as fe_data_file:\n",
    "    final_data=pickle.load(fe_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text=final_data[0]\n",
    "email_data=final_data[1]\n",
    "subject_data=final_data[2]\n",
    "processed_text=final_data[3]\n",
    "file_name=final_data[4]\n",
    "class_details=final_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mantis co uk netcom com mantis co uk',\n",
       " 'mantis co uk mantis co uk mantis co uk',\n",
       " 'dbstu mimsy umd edu cs umd edu',\n",
       " 'mantis co uk kepler unh edu',\n",
       " 'Watson Ibm Com harder ccr harder ccr watson ibm com',\n",
       " 'dbstu batman bmd trw com batman bmd trw com',\n",
       " 'cco caltech edu jyusenkyou cs jhu edu',\n",
       " 'dbstu bu edu buphy bu edu',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu po CWRU edu',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu newton apple com',\n",
       " 'cco caltech edu jyusenkyou cs jhu edu',\n",
       " 'cco caltech edu vice ICO TEK COM',\n",
       " 'cco caltech edu vice ICO TEK COM',\n",
       " 'cco caltech edu vice ICO TEK COM',\n",
       " 'vice ICO TEK COM psilink com psilink com vice ICO TEK COM',\n",
       " 'vice ICO TEK COM monu yoyo cc monash edu au vice ICO TEK COM',\n",
       " 'vice ICO TEK COM blaze cs jhu edu jyusenkyou cs jhu edu fido asd sgi com solntze wpd sgi com vice ICO TEK COM',\n",
       " 'pooh bears SUVM SYR EDU SUVM SYR EDU',\n",
       " 'pooh bears jec MAINE MAINE EDU MAINE MAINE EDU',\n",
       " 'bmers mantis co uk mantis co uk andrew cmu edu bnr ca',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'ic ac uk kepler unh edu kepler unh edu ic ac uk sg',\n",
       " 'fiu edu unix portal com shell portal com',\n",
       " 'solntze wpd sgi com ultb isc rit edu ultb isc rit edu',\n",
       " 'solntze wpd sgi com monu yoyo cc monash edu au',\n",
       " 'carina unm edu cbnewsl cb att com cbnewsl cb att com',\n",
       " 'cco caltech edu mantis co uk',\n",
       " 'cco caltech edu mantis co uk',\n",
       " 'sw stratus com CompuServe COM rocket sw stratus com vos stratus com',\n",
       " 'mac cc macalstr edu macalstr edu',\n",
       " 'thnext mit edu dcs warwick ac uk dcs warwick ac uk mantis co uk dcs warwick ac uk thnext mit edu',\n",
       " 'andrew cmu edu ultb isc rit edu andrew cmu edu',\n",
       " 'andrew cmu edu next wam umd edu andrew cmu edu',\n",
       " 'snake gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'austin ibm com nyx cs du edu andy bgsu edu',\n",
       " 'netcom com netcom com',\n",
       " 'cco caltech edu TRMETU BITNET TRMETU BITNET',\n",
       " 'cco caltech edu vice ICO TEK COM',\n",
       " 'juliet caltech edu skyblu ccit arizona edu skyblu ccit arizona edu juliet caltech edu juliet caltech edu shakes caltech edu',\n",
       " 'cco caltech edu eagle wesleyan edu',\n",
       " 'po CWRU edu gap caltech edu cco caltech edu mantis co uk ultb isc rit edu',\n",
       " 'snake mac cc macalstr edu mac cc macalstr edu',\n",
       " 'cwis unomaha edu news unomaha edu cwis unomaha edu',\n",
       " 'cs ulowell edu lynx unm edu carina unm edu',\n",
       " 'psilink com next po CWRU edu po CWRU edu wam umd edu next',\n",
       " 'nyx cs du edu mimsy umd edu cs umd edu',\n",
       " 'andrew cmu edu batman bmd trw com andrew cmu edu',\n",
       " 'vice ICO TEK COM ultb isc rit edu ultb isc rit edu vice ICO TEK COM',\n",
       " 'vice ICO TEK COM ultb isc rit edu ultb isc rit edu vice ICO TEK COM',\n",
       " 'batman bmd trw com psilink com psilink com andrew cmu edu',\n",
       " 'austin ibm com Cadence COM Cadence COM austin ibm com austin ibm com austin vnet ibm com',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu vice ICO TEK COM',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu po CWRU edu',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'psuvm psu edu batman bmd trw com batman bmd trw com leland Stanford EDU leland Stanford EDU oz bmd trw com',\n",
       " 'solntze wpd sgi com cco bmerh bmers fido asd sgi com solntze wpd sgi com bmerh bmers',\n",
       " 'solntze wpd sgi com cco mac cc macalstr edu mac cc macalstr edu fido asd sgi com solntze wpd sgi com',\n",
       " 'solntze wpd sgi com monu yoyo cc monash edu au fido asd sgi com solntze wpd sgi com',\n",
       " 'solntze wpd sgi com bu edu buphy bu edu',\n",
       " 'csugrad cs vt edu ultb isc rit edu csugrad cs vt edu',\n",
       " 'leland Stanford EDU pogo isp pitt edu',\n",
       " 'stekt batman bmd trw com',\n",
       " 'solntze wpd sgi com mantis co uk mantis co uk blaze cs jhu edu jyusenkyou cs jhu edu',\n",
       " 'solntze wpd sgi com mantis co uk mantis co uk solntze wpd sgi com',\n",
       " 'solntze wpd sgi com batman bmd trw com batman bmd trw com psilink com psilink com andrew cmu edu',\n",
       " 'kraken itc gu edu au cs umd edu',\n",
       " 'kraken itc gu edu au vesta unm edu yoyo cc monash edu au vesta unm edu',\n",
       " 'juliet caltech edu njitgw njit edu hertz njit edu juliet caltech edu juliet caltech edu remarque berkeley edu shakes caltech edu',\n",
       " 'austin ibm com cco fido asd sgi com solntze wpd sgi com bmerh bmers fido asd sgi com solntze wpd sgi com austin vnet ibm com',\n",
       " 'po CWRU edu batman bmd trw com batman bmd trw com ultb isc rit edu',\n",
       " 'po CWRU edu stekt stekt ultb isc rit edu',\n",
       " 'st Princeton EDU princeton edu batman bmd trw com batman bmd trw com princeton edu',\n",
       " 'st acme gen nz acme gen nz dec acme gen nz',\n",
       " 'st ultb isc rit edu ultb isc rit edu',\n",
       " 'ernie Princeton EDU batman bmd trw com batman bmd trw com dbstu dbstu princeton edu',\n",
       " 'next po CWRU edu po CWRU edu wam umd edu next po CWRU edu po CWRU edu wam umd edu next wam umd edu',\n",
       " 'po CWRU edu wam umd edu next ultb isc rit edu',\n",
       " 'charlie usd edu fido asd sgi com solntze wpd sgi com darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'tafe sa edu au batman bmd trw com',\n",
       " 'engin umich edu batman bmd trw com batman bmd trw com engin umich edu',\n",
       " 'engin umich edu batman bmd trw com batman bmd trw com leland Stanford EDU leland Stanford EDU oz bmd trw com engin umich edu',\n",
       " 'psilink com solntze wpd sgi com bu edu buphy bu edu',\n",
       " 'phoenix oulu fi batman bmd trw com leland Stanford EDU leland Stanford EDU',\n",
       " 'enuxha eas asu edu dbstu dbstu monu yoyo cc monash edu au enuxha eas asu edu',\n",
       " 'its CSIRO AU ultb isc rit edu ultb isc rit edu its csiro au',\n",
       " 'solntze wpd sgi com cco austin ibm com austin ibm com',\n",
       " 'tafe sa edu au psilink com',\n",
       " 'solntze wpd sgi com ennews eas asu edu enuxha eas asu edu',\n",
       " 'engin umich edu batman bmd trw com batman bmd trw com bradford ac uk bradford ac uk engin umich edu',\n",
       " 'kraken itc gu edu au cco caltech edu mantis co uk',\n",
       " 'tamvm mimsy umd edu cs umd edu cs umd edu summa tamu edu',\n",
       " 'psilink com austin ibm com Cadence COM Cadence COM austin ibm com austin ibm com',\n",
       " 'skyblu ccit arizona edu bAARNie tafe sa edu au CCIT ARIZONA EDU ARIZVMS BITNET',\n",
       " 'skyblu ccit arizona edu po CWRU edu po CWRU edu stekt stekt CCIT ARIZONA EDU ARIZVMS BITNET',\n",
       " 'skyblu ccit arizona edu bAARNie tafe sa edu au batman bmd trw com CCIT ARIZONA EDU ARIZVMS BITNET',\n",
       " 'cbnewsl cb att com usl com',\n",
       " 'welch jhu edu mimsy umd edu cs umd edu',\n",
       " 'welch jhu edu',\n",
       " 'carina unm edu carina unm edu',\n",
       " 'tekig ra nrl navy mil itd itd nrl navy mil TEKIG',\n",
       " 'tekig ultb isc rit edu',\n",
       " 'harlqn co uk andrew cmu edu ultb isc rit edu harlequin com harlequin co uk UK AC CAMBRIDGE PHOENIX',\n",
       " 'cnsvax uwec edu austin ibm com cnsvax uwec edu',\n",
       " 'cco caltech edu mouse cmhnet org',\n",
       " 'cco caltech edu mouse cmhnet org',\n",
       " 'cco caltech edu iss nus sg',\n",
       " 'cco caltech edu adobe com',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu shrike und ac za cco caltech edu',\n",
       " 'cco caltech edu psuvm psu edu',\n",
       " 'mantis co uk stekt oulu fi batman bmd trw com',\n",
       " 'mantis co uk cco caltech edu mantis co uk',\n",
       " 'mantis co uk cco caltech edu mantis co uk',\n",
       " 'mantis co uk po CWRU edu',\n",
       " 'mantis co uk dbstu mantis co uk mantis co uk FINABO ABO FI mantis co uk uknet ac uk uk ac nsfnet phx cam ac uk',\n",
       " 'mantis co uk snake',\n",
       " 'FINABO ABO FI bu edu buphy bu edu',\n",
       " 'proxima alt za batman bmd trw com proxima Alt ZA',\n",
       " 'proxima alt za mantis co uk proxima Alt ZA',\n",
       " 'mantis co uk buphy bu edu',\n",
       " 'dbstu bu edu buphy bu edu',\n",
       " 'dbstu watson ibm com Watson Ibm Com dbstu dbstu',\n",
       " 'dsinc com midway uchicago edu midway uchicago edu dsi dsinc com dsinc com dsinc com',\n",
       " 'dbstu senator thnext mit edu',\n",
       " 'dsinc com watson ibm com Watson Ibm Com dsi dsinc com dsinc com dsinc com',\n",
       " 'cco caltech edu mantis co uk',\n",
       " 'dcs warwick ac uk ultb isc rit edu ultb isc rit edu dcs warwick ac uk',\n",
       " 'po CWRU edu cbnewsl cb att com cbnewsl cb att com ultb isc rit edu',\n",
       " 'unix amherst edu cbnewsl cb att com cbnewsl cb att com unix amherst edu AMHERST',\n",
       " 'dbstu watson ibm com Watson Ibm Com andrew cmu edu CMU EDU',\n",
       " 'dbstu mantis co uk mantis co uk FINABO ABO FI',\n",
       " 'lehtori cc tut fi ultb isc rit edu ultb isc rit edu cc tut fi',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'worldbank org cnsvax uwec edu cnsvax uwec edu austin ibm com',\n",
       " 'cco caltech edu vice ICO TEK COM',\n",
       " 'dsinc com mimsy umd edu cs umd edu dsinc com',\n",
       " 'engin umich edu mimsy umd edu cs umd edu engin umich edu',\n",
       " 'yoyo cc monash edu au lynx unm edu vesta unm edu monu yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'yoyo cc monash edu au kraken kraken itc gu edu au vesta unm edu yoyo cc monash edu au',\n",
       " 'yoyo cc monash edu au proxima alt za proxima alt za yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'yoyo cc monash edu au dbstu dbstu monu yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'engin umich edu mimsy umd edu cs umd edu engin umich edu',\n",
       " 'po CWRU edu dcs warwick ac uk dcs warwick ac uk ultb isc rit edu ultb isc rit edu',\n",
       " 'po CWRU edu mimsy umd edu cs umd edu ultb isc rit edu',\n",
       " 'engin umich edu darkside osrhe uoknor edu okcforum osrhe edu mips nott ac uk engin umich edu',\n",
       " 'kepler unh edu',\n",
       " 'po CWRU edu monu yoyo cc monash edu au ultb isc rit edu',\n",
       " 'po CWRU edu sei cmu edu sei cmu edu ultb isc rit edu',\n",
       " 'po CWRU edu darkside osrhe uoknor edu okcforum osrhe edu ultb isc rit edu',\n",
       " 'pipe cs fsu edu cs ulowell edu cs ulowell edu',\n",
       " 'okcforum osrhe edu mips nott ac uk',\n",
       " 'sail LABS TEK COM next RELAY CS NET sail LABS TEK COM',\n",
       " 'po CWRU edu darkside osrhe uoknor edu okcforum osrhe edu po CWRU edu ultb isc rit edu',\n",
       " 'po CWRU edu darkside osrhe uoknor edu okcforum osrhe edu ultb isc rit edu',\n",
       " 'dbstu mimsy umd edu cs umd edu',\n",
       " 'po CWRU edu austin ibm com austin ibm com ultb isc rit edu',\n",
       " 'dbstu mimsy umd edu cs umd edu',\n",
       " 'dsinc com bu edu buphy bu edu dsi dsinc com dsinc com dsinc com',\n",
       " 'crchh batman bmd trw com batman bmd trw com HQ Ileaf COM HQ Ileaf COM batman bmd trw com batman bmd trw com matt ksu ksu edu matt ksu ksu edu netcom com',\n",
       " 'crchh monu yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'dbstu mimsy umd edu cs umd edu',\n",
       " 'yoyo cc monash edu au psilink com psilink com yoyo cc monash edu au fido asd sgi com solntze wpd sgi com yoyo cc monash edu au',\n",
       " 'sei cmu edu cs umd edu',\n",
       " 'sei cmu edu cs umd edu',\n",
       " 'sei cmu edu',\n",
       " 'cco caltech edu pooh bears',\n",
       " 'sei cmu edu',\n",
       " 'dbstu mimsy umd edu cs umd edu',\n",
       " 'thnext mit edu dbstu dbstu senator thnext mit edu thnext mit edu',\n",
       " 'okcforum osrhe edu diag amdahl com',\n",
       " 'okcforum osrhe edu po CWRU edu',\n",
       " 'okcforum osrhe edu dsinc com',\n",
       " 'okcforum osrhe edu cs umd edu',\n",
       " 'okcforum osrhe edu juncol juniata edu',\n",
       " 'okcforum osrhe edu netcom com',\n",
       " 'okcforum osrhe edu andy bgsu edu',\n",
       " 'okcforum osrhe edu dsinc com',\n",
       " 'okcforum osrhe edu',\n",
       " 'yoyo cc monash edu au dbstu dbstu monu yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'yoyo cc monash edu au ennews eas asu edu enuxha eas asu edu yoyo cc monash edu au',\n",
       " 'bmers cco fido asd sgi com solntze wpd sgi com bmerh bmers bnr ca',\n",
       " 'mantis co uk mantis co uk',\n",
       " 'mantis co uk',\n",
       " 'mantis co uk cs cmu edu dsinc com ncsuvm cc ncsu edu gdr bath ac uk cs HUT FI East Sun COM sics se utdallas edu quads uchicago edu jyusenkyou cs jhu edu netcom com psuvm psu edu bmers open cs fsu edu bigbird hri com ira uka de unix ccit arizona edu rigel tamu edu phoenix princeton edu sdsc edu csservera usna navy mil unhh unh edu Kodak COM hertz dcs ed ac uk mips complang tuwien ac at math mit edu dcs warwick ac uk rtfm mit edu rtfm mit edu mantis co uk mantis co uk',\n",
       " 'psilink com mcl ucsb edu',\n",
       " 'tlcslip uncecs edu',\n",
       " 'newton apple com zeus calpoly edu hertz elee calpoly edu newton apple com',\n",
       " 'cwis unomaha edu mcl ucsb edu',\n",
       " 'alexia lis uiuc edu vice ICO TEK COM vice ICO TEK COM news cso uiuc edu alexia lis uiuc edu vice ICO TEK COM vice ICO TEK COM vice ICO TEK COM alexia lis uiuc edu',\n",
       " 'scubed com mantis co uk psilink com psilink com scubed scubed com',\n",
       " 'cco caltech edu psuvm psu edu psuvm psu edu PSUVM psu edu ecl psu edu',\n",
       " 'cco caltech edu',\n",
       " 'phoenix oulu fi okcforum osrhe edu',\n",
       " 'buphy bu edu vice ICO TEK COM vice ICO TEK COM bu edu buphy bu edu vice ICO TEK COM vice ICO TEK COM',\n",
       " 'cbnewsj cb att com saturn wwc edu saturn wwc edu',\n",
       " 'fraser sfu ca mcl ucsb edu',\n",
       " 'maths tcd ie saturn wwc edu',\n",
       " 'maths tcd ie next crl nmsu edu',\n",
       " 'dbstu saturn wwc edu saturn wwc edu',\n",
       " 'shnext wam umd edu next',\n",
       " 'seachg com cco caltech edu snake',\n",
       " 'crchh antioc antioch edu antioc antioch edu',\n",
       " 'vice ICO TEK COM horus ap mchp sni de vice ICO TEK COM',\n",
       " 'vice ICO TEK COM sandvik newton apple com vice ICO TEK COM',\n",
       " 'vice ICO TEK COM news wesleyan edu eagle wesleyan edu gap caltech edu cco caltech edu vice ICO TEK COM',\n",
       " 'crchh portal hq videocart com portal hq videocart com portal hq videocart com',\n",
       " 'crchh helios helios usq EDU AU csugrad cs vt edu saturn wwc edu',\n",
       " 'crchh',\n",
       " 'csugrad cs vt edu saturn wwc edu csugrad cs vt edu',\n",
       " 'lehtori cc tut fi po CWRU edu po CWRU edu cc tut fi',\n",
       " 'netcom com netcom com',\n",
       " 'newton apple com newton apple com',\n",
       " 'newton apple com monu yoyo cc monash edu au newton apple com',\n",
       " 'newton apple com portal hq videocart com portal hq videocart com newton apple com',\n",
       " 'newton apple com horus ap mchp sni de newton apple com',\n",
       " 'newton apple com saturn wwc edu saturn wwc edu newton apple com',\n",
       " 'solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com',\n",
       " 'cbnewsj cb att com gocart twisto compaq com twisto compaq com saturn wwc edu',\n",
       " 'solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com horus ap mchp sni de',\n",
       " 'stein washington edu antioc antioch edu antioc antioch edu',\n",
       " 'lehtori cc tut fi ultb isc rit edu ultb isc rit edu po CWRU edu po CWRU edu cc tut fi',\n",
       " 'ofa po CWRU edu po cwru edu leland Stanford EDU leland Stanford EDU',\n",
       " 'eagle wesleyan edu ultb isc rit edu ultb isc rit edu eagle wesleyan edu eagle wesleyan edu',\n",
       " 'abo fi FINABO ABO FI horus ap mchp sni de ursa bear com pooh bears sse ie',\n",
       " 'buphy bu edu monu yoyo cc monash edu au ra nrl navy mil itd itd nrl navy mil',\n",
       " 'monu yoyo cc monash edu au',\n",
       " '',\n",
       " 'silicon csci csusb edu horus ap mchp sni de fido asd sgi com solntze wpd sgi com horus ap mchp sni de silicon csci csusb edu',\n",
       " 'eagle wesleyan edu netcom com netcom com',\n",
       " 'stein washington edu saturn wwc edu saturn wwc edu',\n",
       " 'lehtori cc tut fi ultb isc rit edu ultb isc rit edu cc tut fi',\n",
       " 'solntze wpd sgi com bu edu buphy bu edu fido asd sgi com solntze wpd sgi com',\n",
       " 'solntze wpd sgi com mimsy umd edu cs umd edu',\n",
       " 'lehtori cc tut fi ultb isc rit edu ultb isc rit edu cc tut fi',\n",
       " 'monu yoyo cc monash edu au ra nrl navy mil itd itd nrl navy mil',\n",
       " 'tekig sandvik newton apple com',\n",
       " 'psuvm psu edu news wesleyan edu eagle wesleyan edu',\n",
       " 'solntze wpd sgi com horus ap mchp sni de',\n",
       " 'mac cc macalstr edu senator athena mit edu macalstr edu',\n",
       " 'mac cc macalstr edu saturn wwc edu saturn wwc edu macalstr edu',\n",
       " 'mac cc macalstr edu nuscc nus sg iss nus sg newton apple com uxa ecn bgu edu uxa ecn bgu edu macalstr edu iss nus sg',\n",
       " 'East Sun COM sunlight llnl gov nazareth israel rel Tomobiki apollo HP COM uavax media mit edu East Sun COM',\n",
       " 'cco caltech edu nyx cs du edu',\n",
       " 'cco caltech edu nyx cs du edu',\n",
       " 'cco caltech edu po CWRU edu',\n",
       " 'cco caltech edu newton apple com',\n",
       " 'cco caltech edu vice ICO TEK COM',\n",
       " 'cco caltech edu adobe com',\n",
       " 'alexia lis uiuc edu andrew cmu edu andrew cmu edu alexia lis uiuc edu',\n",
       " 'alexia lis uiuc edu horus ap mchp sni de spac spacsun rice edu horus ap mchp sni de sse ie alexia lis uiuc edu',\n",
       " 'alexia lis uiuc edu po CWRU edu po CWRU edu horus ap mchp sni de alexia lis uiuc edu',\n",
       " 'alexia lis uiuc edu exodus Eng Sun COM hernes ux ux alexia lis uiuc edu',\n",
       " 'newton apple com newton apple com',\n",
       " 'portal hq videocart com portal hq videocart com',\n",
       " 'portal hq videocart com iss nus sg portal hq videocart com',\n",
       " 'andrew cmu edu po CWRU edu andrew cmu edu',\n",
       " 'psuvm psu edu',\n",
       " 'cco caltech edu nyx cs du edu',\n",
       " 'nyx cs du edu portal hq videocart com portal hq videocart com portal hq videocart com',\n",
       " 'buphy bu edu blaze cs jhu edu jyusenkyou cs jhu edu bu edu buphy bu edu',\n",
       " 'buphy bu edu bradford ac uk bradford ac uk buphy bu edu',\n",
       " 'buphy bu edu bradford ac uk bradford ac uk buphy bu edu',\n",
       " 'buphy bu edu bradford ac uk bradford ac uk buphy bu edu',\n",
       " 'buphy bu edu fido asd sgi com solntze wpd sgi com',\n",
       " 'buphy bu edu bradford ac uk bradford ac uk buphy bu edu',\n",
       " 'saturn wwc edu vice ICO TEK COM vice ICO TEK COM vice ICO TEK COM saturn wwc edu saturn wwc edu vice ICO TEK COM',\n",
       " 'saturn wwc edu daffy cs wisc edu snake snake monu yoyo cc monash edu au netcom com netcom com yoyo cc monash edu au',\n",
       " 'cco caltech edu nyx cs du edu',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu nmsu edu',\n",
       " 'buphy bu edu ics uci edu ics uci edu bu edu buphy bu edu',\n",
       " 'saturn wwc edu sandvik newton apple com newton apple com saturn wwc edu saturn wwc edu newton apple com',\n",
       " 'saturn wwc edu dbstu dbstu dbstu saturn wwc edu saturn wwc edu',\n",
       " 'cco caltech edu jyusenkyou cs jhu edu',\n",
       " 'cco caltech edu psuvm psu edu',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'saturn wwc edu po CWRU edu po CWRU edu po CWRU edu',\n",
       " 'saturn wwc edu vice ICO TEK COM vice ICO TEK COM vice ICO TEK COM saturn wwc edu saturn wwc edu vice ICO TEK COM',\n",
       " 'saturn wwc edu ultb isc rit edu ultb isc rit edu ultb isc rit edu saturn wwc edu saturn wwc edu',\n",
       " 'leland Stanford EDU vice ICO TEK COM vice ICO TEK COM leland Stanford EDU leland Stanford EDU vice ICO TEK COM',\n",
       " 'kraken itc gu edu au saturn wwc edu',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu po CWRU edu',\n",
       " 'helios usq EDU AU saturn wwc edu helios usq edu au',\n",
       " 'solntze wpd sgi com bu edu buphy bu edu fido asd sgi com solntze wpd sgi com',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu nyx cs du edu',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu jyusenkyou cs jhu edu',\n",
       " 'andrew cmu edu portal hq vi',\n",
       " 'andrew cmu edu',\n",
       " 'spacsun rice edu rambo atlanta dg com atlanta dg com atlanta dg com',\n",
       " 'cco caltech edu saturn wwc edu',\n",
       " 'po CWRU edu horus ap mchp sni de',\n",
       " 'seachg com ultb isc rit edu wam umd edu next Religious',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'psuvm psu edu gap caltech edu cco caltech edu psuvm psu edu',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'carson washington edu bu edu buphy bu edu ics uci edu ics uci edu bu edu buphy bu edu',\n",
       " 'Cadence COM dbstu dbstu cadence com',\n",
       " 'Cadence COM bradford ac uk bradford ac uk bradford ac uk cadence com',\n",
       " 'cco caltech edu psuvm psu edu',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'andrew cmu edu nyx cs du edu',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'solntze wpd sgi com Cadence COM Cadence COM',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'vice ICO TEK COM news cso uiuc edu alexia lis uiuc edu vice ICO TEK COM',\n",
       " 'vice ICO TEK COM bu edu buphy bu edu fido asd sgi com solntze wpd sgi com vice ICO TEK COM',\n",
       " 'vice ICO TEK COM gap caltech edu cco caltech edu vice ICO TEK COM',\n",
       " 'vice ICO TEK COM gap caltech edu cco caltech edu vice ICO TEK COM',\n",
       " 'vice ICO TEK COM gap caltech edu cco caltech edu vice ICO TEK COM',\n",
       " 'vice ICO TEK COM andrew cmu edu vice ICO TEK COM',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'pooh bears ultb isc rit edu ultb isc rit edu',\n",
       " 'pooh bears bu edu buphy bu edu',\n",
       " 'pooh bears ursa bear com pooh bears bu edu buphy bu edu',\n",
       " 'pooh bears daffy cs wisc edu snake',\n",
       " 'psilink com eagle wesleyan edu netcom com netcom com',\n",
       " 'levels unisa edu au gap caltech edu cco caltech edu levels unisa edu au wh whyalla unisa edu au dsinc com',\n",
       " 'mips nott ac uk saturn wwc edu saturn wwc edu mips nott ac uk',\n",
       " 'unicorn nott ac uk dcs ed ac uk dcs ed ac uk horus ap mchp sni de',\n",
       " 'levels unisa edu au tekig tekig levels unisa edu au wh whyalla unisa edu au dsinc com',\n",
       " 'levels unisa edu au gap caltech edu cco caltech edu levels unisa edu au wh whyalla unisa edu au dsinc com',\n",
       " 'portal hq videocart com andrew cmu edu',\n",
       " 'vesta unm edu mcl mcl ucsb edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'mantis co uk buphy bu edu vice ICO TEK COM vice ICO TEK COM',\n",
       " 'nasa kodak com vice ICO TEK COM vice ICO TEK COM',\n",
       " 'panther bears mantis co uk mantis co uk snake ursa bear com pooh bears ursa bear com panther bears Princeton EDU phoenix Princeton EDU',\n",
       " 'andrew cmu edu mcl ucsb edu andrew cmu edu',\n",
       " 'dsinc com ra nrl navy mil itd itd nrl navy mil dsi dsinc com dsinc com dsinc com',\n",
       " 'mcl ucsb edu',\n",
       " 'yoyo cc monash edu au dbstu dbstu monu yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'yoyo cc monash edu au solan solan yoyo cc monash edu au',\n",
       " 'cleveland Freenet Edu',\n",
       " 'citation ksu ksu edu news cso uiuc edu alexia lis uiuc edu alexia lis uiuc edu',\n",
       " 'batman bmd trw com cs nott ac uk mips nott ac uk',\n",
       " 'vice ICO TEK COM netcom com netcom com vice ICO TEK COM',\n",
       " 'vice ICO TEK COM saturn wwc edu saturn wwc edu vice ICO TEK COM',\n",
       " 'vice ICO TEK COM sandvik newton apple com vice ICO TEK COM',\n",
       " 'vice ICO TEK COM shelley washington edu carson washington edu vice ICO TEK COM',\n",
       " 'vice ICO TEK COM eastman UUCP nasa kodak com vice ICO TEK COM vice ICO TEK COM vice ICO TEK COM',\n",
       " 'mcl ucsb edu mcl ucsb edu',\n",
       " 'enkidu mic cl enkidu mic cl',\n",
       " 'batman bmd trw com bmerh bmers bnr ca',\n",
       " 'mcl ucsb edu fraser sfu ca mcl ucsb edu',\n",
       " 'po CWRU edu',\n",
       " 'phoenix oulu fi mac cc macalstr edu',\n",
       " 'news cso uiuc edu alexia lis uiuc edu horus ap mchp sni de news cso uiuc edu alexia lis uiuc edu sse ie',\n",
       " 'yoyo cc monash edu au psilink com psilink com monu yoyo cc monash edu au psilink com psilink com yoyo cc monash edu au',\n",
       " 'mcl ucsb edu',\n",
       " 'psuvm psu edu news cso uiuc edu alexia lis uiuc edu vice ICO TEK COM vice ICO TEK COM news cso uiuc edu alexia lis uiuc edu',\n",
       " 'batman bmd trw com mantis co uk mantis co uk batman bmd trw com mantis co uk mantis co uk',\n",
       " 'dbstu dbstu horus ap mchp sni de sse ie',\n",
       " 'after math uiuc edu cbnewsj cb att com portal hq videocart com portal hq videocart com psuvm psu edu',\n",
       " 'cbnewsj cb att com portal hq videocart com portal hq videocart com psuvm psu edu',\n",
       " 'psuvm psu edu darkside osrhe uoknor edu okcforum osrhe edu cbnewsj cb att com',\n",
       " 'carson washington edu mcl mcl ucsb edu',\n",
       " 'dbstu horus ap mchp sni de',\n",
       " 'dbstu horus ap mchp sni de',\n",
       " 'po CWRU edu dr East Sun COM sunlight llnl gov nazareth israel rel Tomobiki apollo HP COM uavax media mit edu',\n",
       " 'po CWRU edu gap caltech edu cco caltech edu',\n",
       " 'po CWRU edu gap caltech edu cco caltech edu',\n",
       " 'dbstu saturn wwc edu saturn wwc edu',\n",
       " 'dbstu srvr engin umich edu',\n",
       " 'po CWRU edu gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'nyx cs du edu dr East Sun COM sunlight llnl gov nazareth israel rel Tomobiki apollo HP COM uavax media mit edu branch davidian compound waco tx us',\n",
       " 'alexia lis uiuc edu citation ksu ksu edu citation ksu ksu edu news cso uiuc edu alexia lis uiuc edu alexia lis uiuc edu alexia lis uiuc edu',\n",
       " 'minster york ac uk',\n",
       " 'alexia lis uiuc edu alexia lis uiuc edu',\n",
       " 'jyusenkyou cs jhu edu eastman UUCP nasa kodak com jyusenkyou cs jhu edu',\n",
       " 'jyusenkyou cs jhu edu batman bmd trw com batman bmd trw com jyusenkyou cs jhu edu',\n",
       " 'pipe cs fsu edu eastman UUCP nasa kodak com',\n",
       " 'alexia lis uiuc edu cnsvax uwec edu cnsvax uwec edu alexia lis uiuc edu cnsvax uwec edu alexia lis uiuc edu',\n",
       " 'po CWRU edu dbstu dbstu eagle wesleyan edu eagel wesleyan edu',\n",
       " 'cbnewsj cb att com darkside osrhe uoknor edu okcforum osrhe edu cbnewsj cb att com',\n",
       " 'batman bmd trw com mantis co uk mantis co uk batman bmd trw com mantis co uk mantis co uk',\n",
       " 'dsinc com watson ibm com Watson Ibm Com dsinc com dsinc com',\n",
       " 'dsinc com bu edu buphy bu edu dsinc com dsinc com',\n",
       " 'dsinc com srvr engin umich edu dsinc com',\n",
       " 'dsinc com dsinc com dsinc com',\n",
       " 'dsinc com darkside osrhe uoknor edu okcforum osrhe edu dsinc com dsinc com dsinc com',\n",
       " 'cbnewsj cb att com cs nott ac uk mips nott ac uk',\n",
       " 'nyx cs du edu shelley washington edu carson washington edu',\n",
       " 'phoenix oulu fi nasa kodak com',\n",
       " 'batman bmd trw com mantis co uk mantis co uk snake',\n",
       " 'mcl ucsb edu mcl ucsb edu',\n",
       " 'fermi wustl edu',\n",
       " 'CHEMICAL watstar uwaterloo ca mcl mcl ucsb edu mcl ucsb edu',\n",
       " 'dsinc com senator athena mit edu dsinc com',\n",
       " 'mac cc macalstr edu macalstr edu',\n",
       " 'mac cc macalstr edu neat cs toronto edu cs toronto edu cs toronto edu macalstr edu',\n",
       " 'buphy bu edu blaze cs jhu edu jyusenkyou cs jhu edu bu edu buphy bu edu',\n",
       " 'buphy bu edu vice ICO TEK COM vice ICO TEK COM bu edu buphy bu edu',\n",
       " 'engr LaTech edu',\n",
       " 'buphy bu edu unix portal com shell portal com blaze cs jhu edu jyusenkyou cs jhu edu bu edu buphy bu edu',\n",
       " 'po CWRU edu monu yoyo cc monash edu au',\n",
       " 'CHEMICAL watstar uwaterloo ca news cso uiuc edu alexia lis uiuc edu alexia lis uiuc edu',\n",
       " 'snake mantis co uk mantis co uk whipple cs wisc edu',\n",
       " 'mcl ucsb edu whipple cs wisc edu',\n",
       " 'poori East Sun COM bozo dsinc com dsinc com East Sun COM',\n",
       " 'cnsvax uwec edu cnsvax uwec edu',\n",
       " 'cnsvax uwec edu po CWRU edu cnsvax uwec edu',\n",
       " 'cnsvax uwec edu cnsvax uwec edu',\n",
       " 'cnsvax uwec edu mcl ucsb edu cnsvax uwec edu',\n",
       " 'cnsvax uwec edu carson washington edu cnsvax uwec edu',\n",
       " 'netcom com mcl ucsb edu netcom com',\n",
       " 'psilink com mantis co uk',\n",
       " 'psilink com mcl ucsb edu',\n",
       " 'kraken itc gu edu au alexia lis uiuc edu',\n",
       " 'saturn wwc edu nuscc nus sg iss nus sg iss nus sg psuvm psu edu psuvm psu edu iss nus sg',\n",
       " 'lerc nasa gov psuvm psu edu psuvm psu edu daffy cs wisc edu snake helium helium gas uug arizona edu lerc nasa gov',\n",
       " 'vesta unm edu saturn wwc edu saturn wwc edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'lerc nasa gov saturn wwc edu saturn wwc edu lerc nasa gov',\n",
       " 'twisto compaq com saturn wwc edu twisto compaq com',\n",
       " 'twisto compaq com vice ICO TEK COM andrew cmu edu twisto compaq com',\n",
       " 'twisto compaq com levels unisa edu au twisto compaq com',\n",
       " 'mantis co uk abo fi FINABO ABO FI',\n",
       " 'mantis co uk',\n",
       " 'twisto compaq com senator athena mit edu twisto compaq com',\n",
       " 'cnsvax uwec edu cnsvax uwec edu',\n",
       " 'buphy bu edu st st',\n",
       " 'alexia lis uiuc edu vice ICO TEK COM vice ICO TEK COM news cso uiuc edu alexia lis uiuc edu vice ICO TEK COM alexia lis uiuc edu',\n",
       " 'twisto compaq com mantis co uk twisto compaq com',\n",
       " 'unicorn acs ttu edu next',\n",
       " 'ccsua ctstateu edu po CWRU edu po CWRU edu usenet INS CWRU Edu cleveland Freenet Edu',\n",
       " 'saturn wwc edu cbnewsj cb att com cbnewsj cb att com cbnewsj cb att com portal hq videocart com portal hq videocart com psuvm psu edu',\n",
       " 'CMU EDU batman bmd trw com batman bmd trw com batman bmd trw com cmu edu',\n",
       " 'mac cc macalstr edu news cso uiuc edu alexia lis uiuc edu citation ksu ksu edu citation ksu ksu edu news cso uiuc edu alexia lis uiuc edu alexia lis uiuc edu alexia lis uiuc edu macalstr edu',\n",
       " 'mac cc macalstr edu news cso uiuc edu alexia lis uiuc edu alexia lis uiuc edu macalstr edu',\n",
       " 'mac cc macalstr edu news cso uiuc edu alexia lis uiuc edu cnsvax uwec edu cnsvax uwec edu alexia lis uiuc edu cnsvax uwec edu alexia lis uiuc edu macalstr edu',\n",
       " 'po CWRU edu saturn wwc edu saturn wwc edu',\n",
       " 'mac cc macalstr edu minster york ac uk minster york ac uk',\n",
       " 'mac cc macalstr edu macalstr edu',\n",
       " 'snake mcl mcl ucsb edu whipple cs wisc edu whipple cs wisc edu',\n",
       " 'psilink com cortex dixie com unicorn acs ttu edu elekta com',\n",
       " 'csugrad cs vt edu cs toronto edu csugrad cs vt edu',\n",
       " 'csugrad cs vt edu ofa csugrad cs vt edu csugrad cs vt edu csugrad cs vt edu',\n",
       " 'vice ICO TEK COM gocart twisto compaq com twisto compaq com vice ICO TEK COM',\n",
       " 'solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com horus ap mchp sni de',\n",
       " 'solntze wpd sgi com monu yoyo cc monash edu au fido asd sgi com solntze wpd sgi com',\n",
       " 'cs arizona edu bozo dsinc com dsinc com cs arizona edu uunet uu net',\n",
       " 'spacsun rice edu IASTATE EDU IASTATE EDU',\n",
       " 'solntze wpd sgi com bu edu buphy bu edu fido asd sgi com solntze wpd sgi com',\n",
       " 'solntze wpd sgi com monu yoyo cc monash edu au',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'solntze wpd sgi com bmerh bmers fido asd sgi com solntze wpd sgi com gap caltech edu cco caltech edu',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'solntze wpd sgi com daffy cs wisc edu snake fido asd sgi com solntze wpd sgi com gap caltech edu cco caltech edu',\n",
       " 'solntze wpd sgi com mimsy umd edu cs umd edu',\n",
       " 'shell portal com andrew cmu edu andrew cmu edu mcl ucsb edu',\n",
       " 'pooh bears aurora engr LaTech edu engr LaTech edu cs toronto edu bear com',\n",
       " 'spacsun rice edu eastman UUCP nasa kodak com vice ICO TEK COM vice ICO TEK COM',\n",
       " 'spacsun rice edu cbnewsj cb att com cbnewsj cb att com portal hq videocart com portal hq videocart com psuvm psu edu',\n",
       " 'solntze wpd sgi com monu yoyo cc monash edu au fido asd sgi com solntze wpd sgi com monu yoyo cc monash edu au',\n",
       " 'solntze wpd sgi com monu yoyo cc monash edu au',\n",
       " 'solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com',\n",
       " 'cs toronto edu csugrad cs vt edu csugrad cs vt edu',\n",
       " 'cs toronto edu aurora engr LaTech edu engr LaTech edu',\n",
       " 'shell portal com aurora engr LaTech edu engr LaTech edu cs toronto edu',\n",
       " 'okcforum osrhe edu dbstu',\n",
       " 'okcforum osrhe edu eagle wesleyan edu',\n",
       " 'okcforum osrhe edu lerc nasa gov',\n",
       " 'okcforum osrhe edu newton apple com vice ICO TEK COM vice ICO TEK COM',\n",
       " 'okcforum osrhe edu twisto compaq com vice ICO TEK COM andrew cmu edu',\n",
       " 'okcforum osrhe edu newton apple com',\n",
       " 'okcforum osrhe edu netcom com nyx cs du edu',\n",
       " 'okcforum osrhe edu po CWRU edu',\n",
       " 'okcforum osrhe edu',\n",
       " 'okcforum osrhe edu thnext mit edu',\n",
       " 'netcom com mcl ucsb edu netcom com',\n",
       " 'newton apple com vice ICO TEK COM vice ICO TEK COM sandvik newton apple com newton apple com',\n",
       " 'newton apple com vice ICO TEK COM vice ICO TEK COM gocart twisto compaq com twisto compaq com newton apple com',\n",
       " 'newton apple com newton apple com',\n",
       " 'cs arizona edu abo fi FINABO ABO FI mantis co uk cs arizona edu uunet uu net',\n",
       " 'shell portal com darkside osrhe uoknor edu okcforum osrhe edu lerc nasa gov',\n",
       " 'bmers darkside osrhe uoknor edu okcforum osrhe edu newton apple com bnr ca',\n",
       " 'bmers fido asd sgi com solntze wpd sgi com bmerh bmers bnr ca',\n",
       " 'psilink com leland Stanford EDU enkidu mic cl psilink com',\n",
       " 'ernie Princeton EDU eastman UUCP nasa kodak com princeton edu',\n",
       " 'saturn wwc edu vice ICO TEK COM vice ICO TEK COM vice ICO TEK COM mailer cc fsu edu cs fsu edu vice ICO TEK COM',\n",
       " 'saturn wwc edu enkidu mic cl enkidu mic cl enkidu mic cl enkidu mic cl',\n",
       " 'trumpet calpoly edu nasa kodak com oboe calpoly edu',\n",
       " 'trumpet calpoly edu po CWRU edu oboe calpoly edu',\n",
       " 'trumpet calpoly edu oboe calpoly edu',\n",
       " 'newton apple com news cso uiuc edu alexia lis uiuc edu newton apple com',\n",
       " 'newton apple com monu yoyo cc monash edu au newton apple com',\n",
       " 'newton apple com darkside osrhe uoknor edu okcforum osrhe edu newton apple com',\n",
       " 'newton apple com blaze cs jhu edu jyusenkyou cs jhu edu bu edu buphy bu edu newton apple com',\n",
       " 'abo fi FINABO ABO FI horus ap mchp sni de abo fi FINABO ABO FI sse ie',\n",
       " 'newton apple com monu yoyo cc monash edu au newton apple com',\n",
       " 'newton apple com darkside osrhe uoknor edu okcforum osrhe edu newton apple com vice ICO TEK COM vice ICO TEK COM newton apple com',\n",
       " 'newton apple com spac spacsun rice edu newton apple com',\n",
       " 'newton apple com darkside osrhe uoknor edu okcforum osrhe edu newton apple com newton apple com',\n",
       " 'newton apple com darkside osrhe uoknor edu okcforum osrhe edu newton apple com',\n",
       " 'newton apple com darkside osrhe uoknor edu okcforum osrhe edu newton apple com',\n",
       " 'psilink com liverpool ac uk',\n",
       " 'psilink com mcl ucsb edu',\n",
       " 'fido asd sgi com solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com sse ie',\n",
       " 'fido asd sgi com solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com sse ie',\n",
       " 'newton apple com mantis co uk mantis co uk unicorn nott ac uk newton apple com',\n",
       " 'dbstu monu yoyo cc monash edu au',\n",
       " 'dbstu horus ap mchp sni de',\n",
       " 'yoyo cc monash edu au fido asd sgi com solntze wpd sgi com bu edu buphy bu edu fido asd sgi com solntze wpd sgi com yoyo cc monash edu au',\n",
       " 'cs arizona edu cs arizona edu uunet uu net',\n",
       " 'snake mantis co uk mantis co uk snake whipple cs wisc edu',\n",
       " 'batman bmd trw com fido asd sgi com solntze wpd sgi com batman bmd trw com batman bmd trw com bmerh bmers',\n",
       " 'shell portal com eastman UUCP nasa kodak com ousrvr oulu fi phoenix oulu fi nasa kodak com',\n",
       " 'solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com',\n",
       " 'snake mantis co uk mantis co uk batman bmd trw com whipple cs wisc edu',\n",
       " 'monu yoyo cc monash edu au',\n",
       " 'bu edu buphy bu edu',\n",
       " 'phoenix oulu fi cs nott ac uk',\n",
       " 'phoenix oulu fi eagle wesleyan edu cs nott ac uk cs nott ac uk',\n",
       " 'cs nott ac uk ousrvr oulu fi phoenix oulu fi cs nott ac uk cs nott ac uk',\n",
       " 'spacsun rice edu eastman UUCP nasa kodak com',\n",
       " 'spacsun rice edu aurora engr LaTech edu engr LaTech edu trumpet calpoly edu',\n",
       " 'snake mantis co uk mantis co uk batman bmd trw com whipple cs wisc edu',\n",
       " 'snake optima cs arizona edu cs arizona edu whipple cs wisc edu',\n",
       " 'verdix com',\n",
       " 'andrew cmu edu portal hq videocart com andrew cmu edu',\n",
       " 'vice ICO TEK COM ra nrl navy mil itd itd nrl navy mil vice ICO TEK COM',\n",
       " 'hertz elee calpoly edu bnr ca hertz elee calpoly edu',\n",
       " 'buphy bu edu cs nott ac uk mips nott ac uk bu edu buphy bu edu',\n",
       " 'ccl umist ac uk news chalmers se dtek chalmers se ccl umist ac uk ccl umist ac uk',\n",
       " 'vice ICO TEK COM',\n",
       " 'physics adelaide edu au saturn wwc edu',\n",
       " 'vos stratus com ccsua ctstateu edu ccsua ctstateu edu po CWRU edu po CWRU edu vos stratus com',\n",
       " 'mayo edu ra nrl navy mil itd itd nrl navy mil mayo edu',\n",
       " 'utarlg uta edu',\n",
       " 'vice ICO TEK COM news cso uiuc edu alexia lis uiuc edu vice ICO TEK COM vice ICO TEK COM vice ICO TEK COM',\n",
       " 'uuserv cc utah edu spac spacsun rice edu spacsun rice edu gap caltech edu cco caltech edu',\n",
       " 'bradford ac uk itd itd nrl navy mil bradford ac uk',\n",
       " 'engr LaTech edu skyblu ccit arizona edu',\n",
       " 'psuvm psu edu',\n",
       " 'bu edu buphy bu edu',\n",
       " 'dcs warwick ac uk ultb isc rit edu ultb isc rit edu dcs warwick ac uk',\n",
       " 'saturn wwc edu dbstu dbstu dbstu saturn wwc edu saturn wwc edu',\n",
       " 'saturn wwc edu',\n",
       " 'saturn wwc edu',\n",
       " 'po CWRU edu dr East Sun COM',\n",
       " 'mac cc macalstr edu cs nott ac uk cs nott ac uk eastman UUCP nasa kodak com cs nott ac uk macalstr edu',\n",
       " 'mac cc macalstr edu eastman UUCP nasa kodak com ousrvr oulu fi phoenix oulu fi nasa kodak com macalstr edu',\n",
       " 'mac cc macalstr edu macalstr edu',\n",
       " 'mac cc macalstr edu nuscc nus sg iss nus sg andrew cmu edu cnsvax uwec edu iss nus sg macalstr edu',\n",
       " '',\n",
       " 'logica co uk cs ucla edu cs ucla edu',\n",
       " 'ukc ac uk mac cc macalstr edu',\n",
       " 'triton unm edu triton unm edu',\n",
       " 'carina unm edu',\n",
       " 'phoenix oulu fi mouse cmhnet org',\n",
       " 'minster york ac uk snake minster york ac uk',\n",
       " 'minster york ac uk cs arizona edu',\n",
       " 'minster york ac uk snake',\n",
       " 'minster york ac uk snake',\n",
       " 'minster york ac uk snake',\n",
       " 'vesta unm edu darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'mantis co uk',\n",
       " 'po CWRU edu lynx unm edu vesta unm edu',\n",
       " 'unix amherst edu unix amherst edu unix amherst ed',\n",
       " 'dcs warwick ac uk senator thnext mit edu dcs warwick ac uk dcs warwick ac uk thnext mit edu dcs warwick ac uk',\n",
       " 'netcom com saturn wwc edu netcom com',\n",
       " 'newton apple com bu edu buphy bu edu newton apple com',\n",
       " 'newton apple com bu edu buphy bu edu newton apple com',\n",
       " 'newton apple com gap caltech edu cco caltech edu newton apple com',\n",
       " 'newton apple com saturn wwc edu saturn wwc edu newton apple com',\n",
       " 'cbnewsj cb att com po CWRU edu po CWRU edu',\n",
       " 'okcforum osrhe edu eagle wesleyan edu',\n",
       " 'solntze wpd sgi com bu edu buphy bu edu fido asd sgi com solntze wpd sgi com',\n",
       " 'solntze wpd sgi com dbstu dbstu fido asd sgi com solntze wpd sgi com',\n",
       " 'solntze wpd sgi com news cso uiuc edu alexia lis uiuc edu fido asd sgi com solntze wpd sgi com news cso uiuc edu alexia lis uiuc edu',\n",
       " 'cnsvax uwec edu cnsvax uwec edu alexia lis uiuc edu sse ie',\n",
       " 'cnsvax uwec edu cs toronto edu cnsvax uwec edu',\n",
       " 'dbstu bu edu buphy bu edu bu edu buphy bu edu',\n",
       " 'dbstu horus ap mchp sni de',\n",
       " 'dbstu lynx unm edu vesta unm edu',\n",
       " 'dbstu horus ap mchp sni de',\n",
       " 'dbstu darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'mantis co uk batman bmd trw com',\n",
       " 'mantis co uk batman bmd trw com',\n",
       " 'mantis co uk snake',\n",
       " 'mantis co uk batman bmd trw com',\n",
       " 'mantis co uk mac cc macalstr edu',\n",
       " 'mantis co uk dsinc com',\n",
       " 'buphy bu edu bnr ca bu edu buphy bu edu',\n",
       " 'buphy bu edu bnr ca bu edu buphy bu edu',\n",
       " 'dbstu dbstu horus ap mchp sni de sse ie',\n",
       " 'twisto compaq com leland Stanford EDU enkidu mic cl twisto compaq com',\n",
       " 'alexia lis uiuc edu alexia lis uiuc edu',\n",
       " 'twisto compaq com newton apple com twisto compaq com',\n",
       " 'uxa ecn bgu edu news cso uiuc edu alexia lis uiuc edu',\n",
       " 'dbstu dbstu horus ap mchp sni de sse ie',\n",
       " 'cnsvax uwec edu cnsvax uwec edu sse ie',\n",
       " 'crchh minster york ac uk minster york ac uk',\n",
       " 'crchh',\n",
       " 'spacsun rice edu IASTATE EDU IASTATE EDU gap caltech edu cco caltech edu',\n",
       " 'eustis cs ucf edu cyclops iucf indiana edu eola cs ucf edu',\n",
       " 'sunee uwaterloo ca mcl mcl ucsb edu',\n",
       " 'mips nott ac uk darkside osrhe uoknor edu okcforum osrhe edu lerc nasa gov mips nott ac uk',\n",
       " 'mips nott ac uk darkside osrhe uoknor edu okcforum osrhe edu mips nott ac uk',\n",
       " 'psuvm psu edu',\n",
       " 'wam umd edu ncsu edu news ncsu edu psuvm psu edu ncsu edu PSUVM',\n",
       " 'augustana edu therose pdx com helios usq EDU AU saturn wwc edu',\n",
       " 'cs nott ac uk eastman UUCP nasa kodak com cs nott ac uk',\n",
       " 'horus ap mchp sni de sse ie',\n",
       " 'dsinc com batman bmd trw com batman bmd trw com bmerh bmers dsinc com',\n",
       " 'FINABO ABO FI horus ap mchp sni de',\n",
       " 'wam umd edu eustis eustis cs ucf edu cyclops iucf indiana edu',\n",
       " 'unity ncsu edu storm cs orst edu ncsu edu',\n",
       " 'fido asd sgi com solntze wpd sgi com horus ap mchp sni de fido asd sgi com solntze wpd sgi com stop sse ie',\n",
       " 'vice eustis eustis cs ucf edu vice ICO TEK COM',\n",
       " 'vice ubvms ubvms vice ICO TEK COM',\n",
       " 'dirac phys ualberta ca news rich bnr ca crchh',\n",
       " 'pooh bears po CWRU edu po CWRU edu lynx unm edu vesta unm edu bear com',\n",
       " 'risc sps mot com psuvm psu edu psuvm psu edu',\n",
       " 'risc sps mot com',\n",
       " 'risc sps mot com bnr ca',\n",
       " 'austin ibm com mks com mks com mac cc macalstr edu mac cc macalstr edu saturn wwc edu saturn wwc edu austin vnet ibm com',\n",
       " 'yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'nyx cs du edu andrew cmu edu andrew cmu edu nyx cs du edu',\n",
       " 'batman bmd trw com mantis co uk mantis co uk leland Stanford EDU seachg com seachg com',\n",
       " 'yoyo cc monash edu au cs nott ac uk mips nott ac uk monu yoyo cc monash edu au yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'phoenix oulu fi unix amherst edu',\n",
       " 'dbstu dbstu horus ap mchp sni de sse ie',\n",
       " 'nasa kodak com ousrvr oulu fi phoenix oulu fi nasa kodak com',\n",
       " 'jyusenkyou cs jhu edu jyusenkyou cs jhu edu',\n",
       " 'eagle wesleyan edu okcforum osrhe edu eagle wesleyan edu',\n",
       " 'andrew cmu edu twisto compaq com andrew cmu edu',\n",
       " 'andrew cmu edu cnsvax uwec edu cnsvax uwec edu andrew cmu edu',\n",
       " 'nic csu net silicon csci csusb edu bnr ca',\n",
       " 'cs arizona edu bu edu buphy bu edu cs arizona edu uunet uu net',\n",
       " 'eagle wesleyan edu bu edu buphy bu edu st st',\n",
       " 'twisto compaq com psuvm psu edu twisto compaq com',\n",
       " 'buphy bu edu dbstu dbstu',\n",
       " 'buphy bu edu dbstu dbstu bu edu buphy bu edu',\n",
       " 'phoenix Princeton EDU po CWRU edu po CWRU edu Princeton EDU phoenix Princeton EDU princeton edu',\n",
       " 'buphy bu edu bnr ca',\n",
       " 'psilink com mantis co uk',\n",
       " 'psilink com itd itd nrl navy mil',\n",
       " 'cco caltech edu levels unisa edu au',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'cco caltech edu newton apple com',\n",
       " 'carson washington edu bnr ca zeus calpoly edu hertz elee calpoly edu bnr ca',\n",
       " 'cco caltech edu po CWRU edu',\n",
       " 'cco caltech edu solntze wpd sgi com',\n",
       " 'po CWRU edu bu edu buphy bu edu',\n",
       " 'dirac scri fsu edu',\n",
       " 'shell portal com news cso uiuc edu alexia lis uiuc edu',\n",
       " 'washington edu ucs umass edu',\n",
       " 'washington edu leland Stanford EDU',\n",
       " 'po CWRU edu gap caltech edu cco caltech edu',\n",
       " 'pipe cs fsu edu dcs warwick ac uk dcs warwick ac uk',\n",
       " 'dsinc com optima cs arizona edu cs arizona edu bozo dsinc com dsinc com dsinc com',\n",
       " 'doe carleton ca aurora engr LaTech edu engr LaTech edu',\n",
       " 'sail LABS TEK COM ctron com IASTATE EDU RELAY CS NET sail LABS TEK COM',\n",
       " 'owlnet rice edu mailer cc fsu edu dirac scri fsu edu',\n",
       " 'nyx cs du edu gap caltech edu cco caltech edu nyx cs du edu nyx cs du edu',\n",
       " 'dcs warwick ac uk dcs warwick ac uk horus ap mchp sni de dcs warwick ac uk dcs warwick ac uk sse ie',\n",
       " 'astro ocis temple edu cyclops iucf indiana edu astro ocis temple edu',\n",
       " 'nyx cs du edu horus ap mchp sni de nuscc nus sg iss nus sg nyx cs du edu',\n",
       " 'eagle wesleyan edu newton apple com eagle wesleyan edu',\n",
       " 'eagle wesleyan edu mantis co uk',\n",
       " 'ECL PSU EDU',\n",
       " '',\n",
       " 'nyx cs du edu pharaoh cyborg bt co uk pharaoh cyborg bt co uk psuvm psu edu nyx cs du edu',\n",
       " 'solntze wpd sgi com mailer cc fsu edu pipe cs fsu edu spac spacsun rice edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'solntze wpd sgi com news cso uiuc edu alexia lis uiuc edu citation ksu ksu edu citation ksu ksu edu news cso uiuc edu alexia lis uiuc edu',\n",
       " 'solntze wpd sgi com cc tut fi lehtori cc tut fi bu edu buphy bu edu blaze cs jhu edu jyusenkyou cs jhu edu bu edu buphy bu edu',\n",
       " 'yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'iss nus sg acsu buffalo edu iss nus sg',\n",
       " 'iss nus sg eastman UUCP nasa kodak com iss nus sg iss nus sg',\n",
       " 'cbnewsj cb att com netcom com netcom com saturn wwc edu',\n",
       " 'po CWRU edu cbnewsj cb att com cbnewsj cb att com',\n",
       " 'po CWRU edu saturn wwc edu saturn wwc edu',\n",
       " 'newcastle ac uk trumpet calpoly edu uk ac ncl',\n",
       " 'cbnewsj cb att com saturn wwc edu saturn wwc edu mnemosyne cs du edu nyx cs du edu nyx cs du edu pharaoh cyborg bt co uk pharaoh cyborg bt co uk psuvm psu edu',\n",
       " 'dbstu horus ap mchp sni de dbstu dbstu',\n",
       " 'cbnewsj cb att com blaze cs jhu edu jyusenkyou cs jhu edu ccresources postoffice utas edu au',\n",
       " 'cbnewsj cb att com daffy cs wisc edu snake blaze cs jhu edu jyusenkyou cs jhu edu',\n",
       " 'cbnewsj cb att com po CWRU edu po CWRU edu cbnewsj cb att com cbnewsj cb att com',\n",
       " 'dbstu ccresources postoffice utas edu au',\n",
       " 'csugrad cs vt edu okcforum osrhe edu csugrad cs vt edu',\n",
       " 'dsinc com augustana edu augustana edu dsinc com',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu solntze wpd sgi com',\n",
       " 'aero org',\n",
       " 'dbstu monu yoyo cc monash edu au',\n",
       " 'solntze wpd sgi com gap caltech edu cco caltech edu po CWRU edu',\n",
       " 'mantis co uk netcom com mantis co uk',\n",
       " 'mantis co uk cs cmu edu dsinc com ncsuvm cc ncsu edu gdr bath ac uk cs HUT FI East Sun COM sics se utdallas edu quads uchicago edu jyusenkyou cs jhu edu netcom com psuvm psu edu bmers open cs fsu edu bigbird hri com ira uka de unix ccit arizona edu rigel tamu edu phoenix princeton edu sdsc edu csservera usna navy mil unhh unh edu Kodak COM hertz dcs ed ac uk mips complang tuwien ac at math mit edu dcs warwick ac uk cc helsinki fi rtfm mit edu rtfm mit edu mantis co uk mantis co uk',\n",
       " 'pooh bears ccl umist ac uk ccl umist ac uk',\n",
       " 'dbstu bu edu buphy bu edu',\n",
       " 'dbstu eagle wesleyan edu eagle wesleyan edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'elvis wri com sandvik newton apple com avignon avignon',\n",
       " 'twisto compaq com vice twisto compaq com',\n",
       " 'mouse cmhnet org newton apple com darkside osrhe uoknor edu okcforum osrhe edu mouse cmhnet org',\n",
       " 'mouse cmhnet org okcforum osrhe edu mouse cmhnet org',\n",
       " 'mouse cmhnet org okcforum osrhe edu thnext mit edu mouse cmhnet org',\n",
       " 'mouse cmhnet org nasa kodak com vice ICO TEK COM vice ICO TEK COM mouse cmhnet org',\n",
       " 'mouse cmhnet org mcl ucsb edu whipple cs wisc edu mouse cmhnet org',\n",
       " 'netcom com netcom com netcom com',\n",
       " 'mayo edu monu yoyo cc monash edu au bmw mayo edu mayo edu mayo edu',\n",
       " 'nyx cs du edu gap caltech edu cco caltech edu nyx cs du edu cco caltech edu nyx cs du edu nyx cs du edu',\n",
       " 'FINABO ABO FI horus ap mchp sni de',\n",
       " 'nyx cs du edu gap caltech edu cco caltech edu nyx cs du edu nyx cs du edu',\n",
       " 'mantis co uk jyusenkyou cs jhu edu',\n",
       " 'mantis co uk sce carleton ca po CWRU edu saturn wwc edu saturn wwc edu',\n",
       " 'mantis co uk cs umd edu',\n",
       " 'mantis co uk snake',\n",
       " 'mantis co uk phoenix oulu fi mantis co uk',\n",
       " 'cs utexas edu psilink com psilink com',\n",
       " 'psuvm psu edu horus ap mchp sni de psuvm psu edu',\n",
       " 'elsegundoca ncr com asl dl nec com aslss microsoft com microsoft com teradata com ElSegundoCA ncr com teradata com ElSegundoCA ncr com',\n",
       " 'dsinc com monu yoyo cc monash edu au dsinc com',\n",
       " 'dsinc com bu edu buphy bu edu dsinc com',\n",
       " 'csugrad cs vt edu okcforum osrhe edu csugrad cs vt edu',\n",
       " 'csugrad cs vt edu cs toronto edu csugrad cs vt edu',\n",
       " 'lukasiewicz cc nd edu ctron ctron com IASTATE EDU irishmvs lukasiewicz cc nd edu',\n",
       " 'lukasiewicz cc nd edu ursa bear com pooh bears usenet ucs indiana edu sunflower bio indiana edu bear com irishmvs lukasiewicz cc nd edu',\n",
       " 'uxa cso uiuc edu dirac scri fsu edu uxa cso uiuc edu',\n",
       " 'phoenix Princeton EDU ursa bear com pooh bears horus ap mchp sni de',\n",
       " 'eagle wesleyan edu batman bmd trw com batman bmd trw com eagle wesleyan edu',\n",
       " 'FINABO ABO FI news cso uiuc edu alexia lis uiuc edu',\n",
       " 'buphy bu edu fido asd sgi com solntze wpd sgi com bu edu buphy bu edu',\n",
       " 'buphy bu edu shelley washington edu carson washington edu',\n",
       " 'IASTATE EDU news cso uiuc edu alexia lis uiuc edu morrow stanford edu pangea Stanford EDU news cso uiuc edu alexia lis uiuc edu iastate edu',\n",
       " 'FINABO ABO FI psuvm psu edu psuvm psu edu',\n",
       " 'solntze wpd sgi com zeus calpoly edu tuba calpoly edu',\n",
       " 'okcforum osrhe edu',\n",
       " 'okcforum osrhe edu netcom com',\n",
       " 'solntze wpd sgi com darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'po CWRU edu darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'po CWRU edu darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'po CWRU edu darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'cs arizona edu daffy cs wisc edu snake optima cs arizona edu cs arizona edu cs arizona edu uunet uu net',\n",
       " 'cs utexas edu psilink com psilink com yoyo cc monash edu au yoyo cc monash edu au',\n",
       " 'okcforum osrhe edu psuvm psu edu',\n",
       " 'okcforum osrhe edu lerc nasa gov',\n",
       " 'okcforum osrhe edu newton apple com',\n",
       " 'po CWRU edu bu edu buphy bu edu',\n",
       " 'po CWRU edu daffy cs wisc edu snake',\n",
       " 'cco caltech edu po CWRU edu',\n",
       " 'phoenix oulu fi nasa kodak com ousrvr oulu fi phoenix oulu fi',\n",
       " 'cs uiuc edu cs uiuc edu',\n",
       " 'solntze wpd sgi com darkside osrhe uoknor edu okcforum osrhe edu darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'noao edu po CWRU edu po CWRU edu',\n",
       " 'psuvm psu edu wam umd edu wam umd edu ncsu edu news ncsu edu psuvm psu edu PSUVM',\n",
       " 'po CWRU edu darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'po CWRU edu gap caltech edu cco caltech edu',\n",
       " 'astro ocis temple edu',\n",
       " 'astro ocis temple edu engr LaTech edu trumpet calpoly edu astro ocis temple edu',\n",
       " 'netcom com iss nus sg netcom com',\n",
       " 'wente llnl gov dcs ed ac uk dcs ed ac uk eustis cs ucf edu eustis wente llnl gov',\n",
       " 'okcforum osrhe edu cbnewsj cb att com',\n",
       " 'okcforum osrhe edu snake ursa bear com pooh bears',\n",
       " 'okcforum osrhe edu alexia lis uiuc edu',\n",
       " 'okcforum osrhe edu newton apple com darkside osrhe uoknor edu okcforum osrhe edu',\n",
       " 'okcforum osrhe edu vice ICO TEK COM',\n",
       " 'cnsvax uwec edu',\n",
       " 'phoenix oulu fi nasa kodak com',\n",
       " 'netcom com okcforum osrhe edu netcom com',\n",
       " 'po CWRU edu cnsvax uwec edu cnsvax uwec edu',\n",
       " 'hertz elee calpoly edu doug cae wisc edu hprisc hertz elee calpoly edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'pangea Stanford EDU news cso uiuc edu alexia lis uiuc edu',\n",
       " 'cs umd edu cs umd edu',\n",
       " 'atlanta dg com',\n",
       " 'atlanta dg com',\n",
       " '',\n",
       " 'helios usq EDU AU saturn wwc edu',\n",
       " 'trumpet calpoly edu vice oboe calpoly edu',\n",
       " 'pipe cs fsu edu netcom com netcom com',\n",
       " 'dbstu psuvm psu edu psuvm psu edu psuvm psu edu psuvm psu edu psuvm psu edu PSUVM BITNET',\n",
       " 'dbstu bu edu buphy bu edu',\n",
       " 'dbstu monu yoyo cc monash edu au',\n",
       " 'dbstu psilink com psilink com',\n",
       " 'dbstu bu edu buphy bu edu',\n",
       " 'skyblu ccit arizona edu panix com panix com netcom com netcom com CCIT ARIZONA EDU ARIZVMS BITNET',\n",
       " 'oasys dt navy mil oasys dt navy mil oasys dt navy mil ocean dt navy mil long legs',\n",
       " 'ucssun ucssun',\n",
       " 'coconut cis ufl edu usl edu ucs usl edu usl edu cis ufl edu',\n",
       " 'onyx cs Virginia EDU virginia edu',\n",
       " 'ersys edmonton ab ca ersys edmonton ab ca',\n",
       " 'cco caltech edu dtek chalmers se cco caltech edu',\n",
       " 'picard cs wisc edu picard cs wisc edu',\n",
       " 'talus msk su talus msk su',\n",
       " 'pocomoco NoSubdomain NoDomain cc tut fi lehtori cc tut fi kpc com kpc com',\n",
       " 'cis uab edu csc ti com hc ti com cis uab edu',\n",
       " 'optimla aimla com zola esd sgi com westworld esd sgi com aimla com',\n",
       " 'iti gov sg iti gov sg',\n",
       " 'garfield catt ncsu edu garfield catt ncsu edu',\n",
       " 'netcom com optimla aimla com optimla aimla com zola esd sgi com westworld esd sgi com aimla com',\n",
       " 'eehp',\n",
       " 'DIALix oz au sndcrft DIALix oz au',\n",
       " 'tahko lpr carel fi carel fi',\n",
       " 'fwi uva nl ixos de fwi uva nl',\n",
       " 'lehtori cc tut fi cis uab edu cis uab edu',\n",
       " 'amertume ufr',\n",
       " 'amertume ufr',\n",
       " 'falcon aamrl wpafb af mil taurus cs nps navy mil oahu oc nps navy mil',\n",
       " 'hemel bull co uk',\n",
       " 'tekn hj se tekn hj se hjds',\n",
       " 'IBM',\n",
       " 'IBM',\n",
       " 'IBM',\n",
       " 'st unocal COM',\n",
       " 'husc',\n",
       " 'travis csd harris com',\n",
       " 'gaul csd uwo ca obelix gaul csd uwo ca',\n",
       " 'OFFICE WANG COM ece arizona edu',\n",
       " 'cis uab edu cis uab edu cis uab edu cis uab edu',\n",
       " 'server uwindsor ca',\n",
       " 'cis uab edu travis csd harris com travis csd harris com cis uab edu',\n",
       " 'krypton asd sgi com travis csd harris com travis csd harris com sgi com',\n",
       " 'dtek chalmers se cco caltech edu dtek chalmers se dtek chalmers se',\n",
       " 'falcon aamrl wpafb af mil falcon aamrl wpafb af mil falcon aamrl wpafb af mil taurus cs nps navy mil oahu oc nps navy mil',\n",
       " 'cad gmeds com cad gmeds com',\n",
       " 'ns',\n",
       " 'engr engr uark edu',\n",
       " 'nova cc purdue edu pdxgate UUCP rigel cs pdx edu',\n",
       " 'cs ubc ca',\n",
       " 'uxa cso uiuc edu uiuc sumter cso uiuc edu',\n",
       " 'shograf com',\n",
       " 'cosc canterbury ac nz cosc canterbury ac nz',\n",
       " 'cs ubc ca st unocal COM',\n",
       " 'rpi edu mustang stu rpi edu rpi edu',\n",
       " 'ccmail larc nasa gov',\n",
       " 'vmsb is csupomona edu',\n",
       " 'eng umd edu wam umd edu',\n",
       " 'eng sdsu edu eng sdsu edu',\n",
       " 'nova cc purdue edu shelley washington edu stein washington edu',\n",
       " 'nova cc purdue edu galki toppoint de galki toppoint de',\n",
       " 'rjck UUCP essex ecn uoknor edu constellation ecn uoknor edu rjck UUCP',\n",
       " 'rjck UUCP iastate edu class rjck UUCP',\n",
       " 'aix rpi edu caspian usc edu caspian usc edu',\n",
       " 'saturn aitc rest tasc com',\n",
       " 'scr siemens com',\n",
       " 'iesd auc dk elysium esd sgi com iesd auc dk',\n",
       " 'ckctpa UUCP rintintin Colorado EDU rintintin colorado edu myrddin sybus com',\n",
       " 'craft camp clarkson edu sage cc purdue edu ornl gov sacam OREN ORTN EDU craft camp clarkson edu craft camp clarkson edu',\n",
       " 'Ra MsState Edu ra msstate edu',\n",
       " 'po CWRU Edu Ra MsState Edu email sp paramax com po CWRU Edu',\n",
       " 'student tc umn edu rjck UUCP rjck UUCP essex ecn uoknor edu constellation ecn uoknor edu rjck UUCP',\n",
       " 'cudnvr denver colorado edu COPPER DENVER COLORADO EDU CUDNVR DENVER COLORADO EDU',\n",
       " 'dgp toronto edu dgp utoronto ca',\n",
       " 'maths uwa edu au caspian usc edu maths uwa edu au',\n",
       " 'cbnewsi cb att com',\n",
       " 'nmt edu ornl gov sacam OREN ORTN EDU',\n",
       " 'labtam labtam oz au nwnexus WA COM halcyon com',\n",
       " 'eis calstate edu',\n",
       " 'wampyr cc uow edu au',\n",
       " 'rrz Uni khm uni',\n",
       " 'lis lis',\n",
       " 'hemel bull co uk',\n",
       " 'goshawk mcc ac uk',\n",
       " 'cleveland Freenet Edu cleveland freenet edu bobcat ent ohiou edu voxel zool ohiou edu',\n",
       " 'oasys dt navy mil wizard dt navy mil oasys dt navy mil nas nasa gov',\n",
       " 'amber rjck UUCP iastate edu class csd harris com',\n",
       " 'lds loral com',\n",
       " 'mccarthy csd uwo ca labtam labtam oz au article csd uwo ca',\n",
       " 'jhunix hcf jhu edu',\n",
       " 'ivem ucsd edu uk hemel bull co uk szechuan ucsd edu',\n",
       " 'oeinck waterland wlink nl hutcs cs hut fi',\n",
       " 'isy liu se hemel bull co uk charisma graphics cornell edu ndsuvax UUCP alice UUCP svax cs cornell edu isy liu se',\n",
       " 'caspian usc edu uk hemel bull co uk',\n",
       " 'austin ibm com trantor harris unix portal com shell portal com austin ibm com',\n",
       " 'nova cc purdue edu pdxgate UUCP rigel cs pdx edu',\n",
       " 'acaps cs mcgill ca cs ust hk hemel bull co uk cs mcgill ca',\n",
       " 'med unc edu mentor cc purdue edu nova cc purdue edu galki toppoint de galki toppoint de med unc edu',\n",
       " 'tamarack cray com',\n",
       " 'deadhead asd sgi com relay nswc navy mil nswc sgi com',\n",
       " 'nova cc purdue edu gouraud isy liu se charisma graphics cornell edu cc purdue edu',\n",
       " 'cpuserver acsc com acsc com',\n",
       " 'cpuserver acsc com acsc com',\n",
       " 'Freenet carleton ca snycanva bitnet',\n",
       " 'ux uxa cso uiuc edu ux',\n",
       " 'rincon ema rockwell com rincon ema rockwell com',\n",
       " 'argus msk su argus msk su',\n",
       " 'pi eai iastate edu',\n",
       " 'parsec paradyne com',\n",
       " 'aeg dsto gov au nye nscee edu',\n",
       " 'bcstec ca boeing com',\n",
       " 'postoffice utas edu au usenet INS CWRU Edu po CWRU Edu Ra MsState Edu',\n",
       " 'franklin cc utas edu au aqueous ml csiro au',\n",
       " 'server uwindsor ca server uwindsor ca',\n",
       " 'bonnie ics uci edu ics uci edu',\n",
       " 'stein washington edu',\n",
       " 'seas gwu edu seas gwu edu',\n",
       " 'caspian usc edu',\n",
       " 'krusty eecs umich edu darkstar UCSC EDU secs ucsc edu secs ucsc edu',\n",
       " 'luke rsg hac com bu edu PROBLEM_WITH_INEWS_GATEWAY_FILE obiwan rsg hac com',\n",
       " 'iscsvax uni edu',\n",
       " 'ultb isc rit edu',\n",
       " 'dstos',\n",
       " 'altair csustan edu speedsail Eng Sun COM almac co uk',\n",
       " 'ghost dsi unimi it ghost sm dsi unimi it',\n",
       " 'unixd optimla aimla com',\n",
       " 'csv warwick ac uk bcstec ca boeing com bcstec ca boeing com',\n",
       " 'sax sax de uriah sax de sax de hadrian hrz tu tcd',\n",
       " 'umcc umcc umich edu pandonia canberra edu au umcc umich edu',\n",
       " 'abo fi abo fi',\n",
       " 'mfltd co uk mfltd co uk',\n",
       " 'athena research ptt nl research ptt nl hlsdnl',\n",
       " 'is waynar lcec lockheed is',\n",
       " 'qmgate anl gov qmgate anl gov',\n",
       " 'ivem ucsd edu hacgate SCG HAC COM luke rsg hac com szechuan ucsd edu',\n",
       " 'access digex com iiic ethz ch mac archive umich edu',\n",
       " 'visser el wau nl wampyr cc uow edu au wampyr cc uow edu au VISSER EL WAU NL',\n",
       " 'mindlink bc ca mindlink bc ca',\n",
       " 'ghost dsi unimi it ghost sm dsi unimi it',\n",
       " 'ccmail larc nasa gov freenet carleton ca Freenet carleton ca Freenet carleton ca snycanva bitnet',\n",
       " 'shearson com shearson com',\n",
       " 'sipi usc edu sipi usc edu',\n",
       " 'masg masg',\n",
       " 'unt edu rchland ibm com rchland vnet ibm com unt edu',\n",
       " 'sparc sparc whitehouse dc gov',\n",
       " 'ux med unc edu ux mrcnext cso uiuc edu',\n",
       " 'deadhead asd sgi com sgi com',\n",
       " 'trident datasys swri edu swri edu',\n",
       " 'balboa eng uci edu balboa eng uci edu sunkist West Sun COM',\n",
       " 'fraser sfu ca sfu ca',\n",
       " 'osage csc ti com csc ti com',\n",
       " 'cs buffalo edu',\n",
       " 'cpuserver acsc com acsc com',\n",
       " 'CUNYVM BITNET',\n",
       " 'med umich edu med umich edu',\n",
       " 'carson washington edu washington edu max bitnet milton washington edu',\n",
       " 'husc husc harvard edu husc harvard edu',\n",
       " 'sacam OREN ORTN EDU',\n",
       " 'suncad camosun bc ca camosun bc ca',\n",
       " 'bcstec ca boeing com',\n",
       " 'bcstec ca boeing com',\n",
       " 'hcrlgw shelley washington edu carson washington edu crl hitachi co jp',\n",
       " 'netcom com carson washington edu netcom com',\n",
       " 'FNAL FNAL GOV fnal fnal gov',\n",
       " 'falcon depaul edu falcon depaul edu',\n",
       " 'tsoft net eis calstate edu gilligan tsoft net tsoft sf thetech com',\n",
       " '',\n",
       " 'cvtstu cvt stuba cs mentor cc purdue edu nova cc purdue edu cvt stuba cs',\n",
       " 'iti gov sg shelley washington edu carson washington edu iti gov sg',\n",
       " 'nestvx enet dec com mercury unt edu unt edu nestvx enet dec com',\n",
       " 'melomys co rmit oz AU rmit edu au rmit edu au',\n",
       " 'rjck UUCP student tc umn edu news rjck UUCP rjck UUCP',\n",
       " 'blade stack urc tue nl stack urc tue nl',\n",
       " 'astro ocis temple edu',\n",
       " 'daresbury ac uk',\n",
       " 'fi gs com',\n",
       " 'uvacs cs Virginia EDU uvacs cs Virginia EDU',\n",
       " 'cs uct ac za',\n",
       " 'uts mcc ac uk cs hull ac uk',\n",
       " 'black ox ac uk hcrlgw hcrlgw shelley washington edu carson washington edu oxford ac uk',\n",
       " 'hydra unm edu hydra unm edu',\n",
       " 'fs',\n",
       " 'midway ecn uoknor edu crockett uokmax ecn uoknor edu uokmax ecn uoknor edu',\n",
       " 'konech UUCP',\n",
       " 'gnv ifas ufl edu GNV IFAS UFL EDU',\n",
       " 'midway ecn uoknor edu uokmax ecn uoknor edu uokmax ecn uoknor edu',\n",
       " 'SLACVM SLAC STANFORD EDU carson washington edu slacvm slac stanford edu',\n",
       " 'access digex com access digex com',\n",
       " 'sophia smith edu caspian usc edu caspian usc edu article',\n",
       " 'prlhp',\n",
       " 'hook corp mot com',\n",
       " 'bskewe atr bso nl uk hemel bull co uk bskewe atr bso nl',\n",
       " 'lescsse jsc nasa gov sun sun tahko lpr carel fi tahko lpr carel fi blkbox com',\n",
       " 'schultz kgn ibm com vnet ibm com',\n",
       " 'cellar org bcstec ca boeing com cellar org',\n",
       " 'cellar org cellar org',\n",
       " 'watson ibm com watson ibm com',\n",
       " 'utkvx utk edu UTKVX UTK EDU',\n",
       " 'auriga rose brandeis edu tammy harvard edu',\n",
       " 'rchland vnet ibm com mercury unt edu unt edu rchland ibm com rchland vnet ibm com unt edu',\n",
       " 'north acpub duke edu',\n",
       " 'nova gmi edu nova gmi edu nyx cs du edu',\n",
       " 'spartan ac BrockU CA hook corp mot com spartan ac brocku ca',\n",
       " 'nova gmi edu nova gmi edu nyx cs du edu',\n",
       " 'chaos cs brandeis edu',\n",
       " 'netcom com netcom com',\n",
       " 'sophia smith edu murdoch acc Virginia EDU uvacs cs Virginia EDU uvacs cs Virginia EDU',\n",
       " 'tamsun tamu edu cellar org bcstec ca boeing com',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(list(zip(raw_text,email_data,subject_data,processed_text,file_name,class_details)),\n",
    "             columns=['text','email_id','subject','processed_text','file_name','class'])\n",
    "x=data['email_id']+data['subject']+ data['processed_text']\n",
    "y=data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_class=list(data['class'].unique())\n",
    "class_labels=dict()\n",
    "for i in range(len(total_class)):\n",
    "    class_labels[i]=total_class[i]\n",
    "    y[y==total_class[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(y).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceASjKizYv1U"
   },
   "source": [
    "### Code checking:\n",
    "\n",
    "<font color='red' size=4>\n",
    "After Writing preprocess function. call that functoin with the input text of 'alt.atheism_49960' doc and print the output of the preprocess function\n",
    "<br>\n",
    "This will help us to evaluate faster, based on the output we can suggest you if there are any changes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2x3og_iaYv1S"
   },
   "source": [
    "### After writing Preprocess function, call the function for each of the document(18828 docs) and then create a dataframe as mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3ucJLtWYv1V"
   },
   "source": [
    "### Training The models to Classify: \n",
    "\n",
    "<pre>\n",
    "1. Combine \"preprocessed_text\", \"preprocessed_subject\", \"preprocessed_emails\" into one column. use that column to model. \n",
    "\n",
    "2. Now Split the data into Train and test. use 25% for test also do a stratify split. \n",
    "\n",
    "3. Analyze your text data and pad the sequnce if required. \n",
    "Sequnce length is not restricted, you can use anything of your choice. \n",
    "you need to give the reasoning\n",
    "\n",
    "4. Do Tokenizer i.e convert text into numbers. please be careful while doing it. \n",
    "if you are using tf.keras \"Tokenizer\" API, it removes the <b>\"_\"</b>, but we need that.\n",
    "\n",
    "5. code the model's ( Model-1, Model-2 ) as discussed below \n",
    "and try to optimize that models.  \n",
    "\n",
    "6. For every model use predefined Glove vectors. \n",
    "<b>Don't train any word vectors while Training the model.</b>\n",
    "\n",
    "7. Use \"categorical_crossentropy\" as Loss. \n",
    "\n",
    "8. Use <b>Accuracy and Micro Avgeraged F1 score</b> as your as Key metrics to evaluate your model. \n",
    "\n",
    "9.  Use Tensorboard to plot the loss and Metrics based on the epoches.\n",
    "\n",
    "10. Please save your best model weights in to <b>'best_model_L.h5' ( L = 1 or 2 )</b>. \n",
    "\n",
    "11. You are free to choose any Activation function, learning rate, optimizer.\n",
    "But have to use the same architecture which we are giving below.\n",
    "\n",
    "12. You can add some layer to our architecture but you <b>deletion</b> of layer is not acceptable.\n",
    "\n",
    "13. Try to use <b>Early Stopping</b> technique or any of the callback techniques that you did in the previous assignments.\n",
    "\n",
    "14. For Every model save your model to image ( Plot the model) with shapes \n",
    "and inlcude those images in the notebook markdown cell, \n",
    "upload those imgages to Classroom. You can use \"plot_model\" \n",
    "please refer <a href='https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model'>this</a> if you don't know how to plot the model with shapes. \n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14121,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25, stratify=y)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/nlp-preparing-text-for-deep-learning-model-using-tensorflow2-461428138657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "trained_text_embedding=pd.read_csv('glove.6B/glove.6B.100d.txt', sep=' ', header=None,lineterminator='\\n',quoting=csv.QUOTE_NONE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=[]\n",
    "for i in trained_text_embedding_chars:\n",
    "    if type(i)==float:\n",
    "        f.append(i)\n",
    "f\n",
    "# The code had given an error stating the df has an attribute which is float. Now discarding these 3 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_text_embedding=trained_text_embedding.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_text_embedding_chars=trained_text_embedding[0]\n",
    "trained_text_embedding_vector=trained_text_embedding.drop(0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 1: To create a dictionary with index value: char value\n",
    "Step 2: Create a matrix where index value has the vector value\n",
    "Step 3: pre-trained word embeddings matrix'''\n",
    "\n",
    "text_dict={}\n",
    "embedding_matrix=np.zeros((len(trained_text_embedding_chars)+1,trained_text_embedding_vector.shape[1]))\n",
    "\n",
    "for i,text in enumerate(trained_text_embedding_chars.tolist()):\n",
    "    text_dict[text.lower()]= i\n",
    "    embedding_matrix[i]=trained_text_embedding_vector.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n',oov_token='UNK')\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index=text_dict\n",
    "tokenizer.word_index[tokenizer.oov_token] = max(text_dict.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokenized=tokenizer.texts_to_sequences(x_train)\n",
    "x_test_tokenized=tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399997"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_values_in_list=[]\n",
    "for j in x_train_tokenized:\n",
    "    value=max(j)\n",
    "    max_values_in_list.append(value)\n",
    "    \n",
    "input_dim=max(max_values_in_list)\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 21.0 GiB for an array with shape (14121, 399999) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-32ae217c1aee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpadded_x_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_tokenized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pre'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpadded_x_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_tokenized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pre'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m    152\u001b[0m   return sequence.pad_sequences(\n\u001b[0;32m    153\u001b[0m       \u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m       padding=padding, truncating=truncating, value=value)\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m keras_export(\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m     83\u001b[0m                          .format(dtype, type(value)))\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 21.0 GiB for an array with shape (14121, 399999) and data type int32"
     ]
    }
   ],
   "source": [
    "padded_x_train=tf.keras.preprocessing.sequence.pad_sequences(x_train_tokenized,maxlen=(len(tokenizer.word_index) + 1), padding='pre')\n",
    "padded_x_test=tf.keras.preprocessing.sequence.pad_sequences(x_test_tokenized,maxlen=(len(tokenizer.word_index) + 1), padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14121, 64337)\n",
      "(4707, 64337)\n"
     ]
    }
   ],
   "source": [
    "print(padded_x_train.shape)\n",
    "print(padded_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0mwdtcvYv1X"
   },
   "source": [
    "### Model-1: Using 1D convolutions with word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXPPsovJ3ePk"
   },
   "source": [
    "<pre>\n",
    "<b>Encoding of the Text </b> --> For a given text data create a Matrix with Embedding layer as shown Below. \n",
    "In the example we have considered d = 5, but in this assignment we will get d = dimension of Word vectors we are using.\n",
    " i.e if we have maximum of 350 words in a sentence and embedding of 300 dim word vector, \n",
    " we result in 350*300 dimensional matrix for each sentance as output after embedding layer\n",
    "<img src='https://i.imgur.com/kiVQuk1.png'>\n",
    "Ref: https://i.imgur.com/kiVQuk1.png\n",
    "\n",
    "<b>Reference:</b>\n",
    "<a href='https://stackoverflow.com/a/43399308/4084039'>https://stackoverflow.com/a/43399308/4084039</a>\n",
    "<a href='https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/'>https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/</a>\n",
    "\n",
    "<b><a href='https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work'>How EMBEDDING LAYER WORKS </a></b>\n",
    "\n",
    "</pre>\n",
    "\n",
    "### Go through this blog, if you have any doubt on using predefined Embedding values in Embedding layer - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clearing Logs before running the Model\n",
    "import shutil\n",
    "shutil.rmtree('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "shutil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64337)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 64337, 100)   6433700     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 64337, 100)   6433700     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 64337, 100)   6433700     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 32167, 10)    5010        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 32167, 20)    10020       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 32167, 40)    20040       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32167, 70)    0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 16083, 70)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 8039, 10)     4910        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 8039, 20)     9820        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 8039, 40)     19640       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8039, 70)     0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 4019, 70)     0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 2007, 35)     17185       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 70245)        0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 70245)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20)           1404920     dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,792,645\n",
      "Trainable params: 20,792,645\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building the model\n",
    "input_shape=(padded_x_train.shape[1])#input is just of this dimension\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "\n",
    "conv_m=tf.keras.layers.Embedding(input_dim=(input_dim+1),output_dim=100,input_shape=(1,input_shape))(inputs) #Input shape=(Batch_size, Size of input)\n",
    "conv_m=tf.keras.layers.Conv1D(10,5,strides=2,activation='relu',input_shape=(1,100), kernel_initializer=tf.keras.initializers.HeUniform(10))(conv_m)\n",
    "\n",
    "conv_n=tf.keras.layers.Embedding(input_dim=(input_dim+1),output_dim=100,input_shape=(1,input_shape))(inputs) #Input shape=(Batch_size, Size of input)\n",
    "conv_n=tf.keras.layers.Conv1D(20,5,strides=2,activation='relu',input_shape=(1,100), kernel_initializer=tf.keras.initializers.HeUniform(20))(conv_n)\n",
    "\n",
    "conv_o=tf.keras.layers.Embedding(input_dim=(input_dim+1),output_dim=100,input_shape=(1,input_shape))(inputs) #Input shape=(Batch_size, Size of input)\n",
    "conv_o=tf.keras.layers.Conv1D(40,5,strides=2,activation='relu',input_shape=(1,100), kernel_initializer=tf.keras.initializers.HeUniform(30))(conv_o)\n",
    "\n",
    "output_1= tf.keras.layers.concatenate([conv_m,conv_n,conv_o])\n",
    "\n",
    "output_1=tf.keras.layers.MaxPool1D()(output_1)\n",
    "\n",
    "conv_i=tf.keras.layers.Conv1D(10,7,strides=2,activation='relu',input_shape=output_1.shape, kernel_initializer=tf.keras.initializers.HeUniform(40))(output_1)\n",
    "\n",
    "conv_j=tf.keras.layers.Conv1D(20,7,strides=2,activation='relu',input_shape=output_1.shape, kernel_initializer=tf.keras.initializers.HeUniform(50))(output_1)\n",
    "\n",
    "conv_k=tf.keras.layers.Conv1D(40,7,strides=2,activation='relu',input_shape=output_1.shape, kernel_initializer=tf.keras.initializers.HeUniform(60))(output_1)\n",
    "\n",
    "output_2= tf.keras.layers.concatenate([conv_i,conv_j,conv_k])\n",
    "\n",
    "output_2=tf.keras.layers.MaxPool1D()(output_2)\n",
    "output_2=tf.keras.layers.Conv1D(35,7,strides=2,activation='relu', kernel_initializer=tf.keras.initializers.HeUniform(150))(output_2)\n",
    "output_2=tf.keras.layers.Flatten()(output_2)\n",
    "output_2=tf.keras.layers.Dropout(0.2)(output_2)\n",
    "output_2=tf.keras.layers.Dense(20, activation = 'softmax')(output_2)\n",
    "\n",
    "model=tf.keras.Model(inputs=inputs,outputs=output_2)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 14/353 [>.............................] - ETA: 1:05:37 - loss: 3.0077 - accuracy: 0.0670"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-94463ba51c8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_x_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping=tf.keras.callbacks.EarlyStopping(patience=3,monitor='accuracy',min_delta=0.001)\n",
    "tensorboard=tf.keras.callbacks.TensorBoard(log_dir='logs/model_1')\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy',tfa.metrics.F1Score(num_classes=20, \n",
    "                      average='micro',\n",
    "                      threshold=0.5)], )\n",
    "model.fit(padded_x_train,y_train,epochs=50,callbacks=[early_stopping,tensorboard],validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir {'./logs'}  --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1537 predict_step\n        return self(x, training=False)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:269 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 9830), found shape=(None, 4858)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1c7c9050f109>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_x_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1749\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1751\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1752\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 760\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3308\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1537 predict_step\n        return self(x, training=False)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:269 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 9830), found shape=(None, 4858)\n"
     ]
    }
   ],
   "source": [
    "model.predict(padded_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGVQKge3Yv1e"
   },
   "source": [
    "<img src='https://i.imgur.com/fv1GvFJ.png'>\n",
    "ref: 'https://i.imgur.com/fv1GvFJ.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GC6SBG5AYv1f"
   },
   "source": [
    "<pre>\n",
    "1. all are Conv1D layers with any number of filter and filter sizes, there is no restriction on this.\n",
    "\n",
    "2. use concatenate layer is to concatenate all the filters/channels. \n",
    "\n",
    "3. You can use any pool size and stride for maxpooling layer.\n",
    "\n",
    "4. Don't use more than 16 filters in one Conv layer becuase it will increase the no of params. \n",
    "( Only recommendation if you have less computing power )\n",
    "\n",
    "5. You can use any number of layers after the Flatten Layer.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cg4L1V4Yv1d"
   },
   "source": [
    "### Model-2 : Using 1D convolutions with character embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Djg4YVA3oQx"
   },
   "source": [
    "<pre>\n",
    "<pre><img src=\"https://i.ytimg.com/vi/CNY8VjJt-iQ/maxresdefault.jpg\" width=\"70%\">\n",
    "Here are the some papers based on Char-CNN\n",
    " 1. Xiang Zhang, Junbo Zhao, Yann LeCun. <a href=\"http://arxiv.org/abs/1509.01626\">Character-level Convolutional Networks for Text Classification</a>.NIPS 2015\n",
    " 2. Yoon Kim, Yacine Jernite, David Sontag, Alexander M. Rush. <a href=\"https://arxiv.org/abs/1508.06615\">Character-Aware Neural Language Models</a>. AAAI 2016\n",
    " 3. Shaojie Bai, J. Zico Kolter, Vladlen Koltun. <a href=\"https://arxiv.org/pdf/1803.01271.pdf\">An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</a>\n",
    " 4. Use the pratrained char embeddings <a href='https://github.com/minimaxir/char-embeddings/blob/master/glove.840B.300d-char.txt'>https://github.com/minimaxir/char-embeddings/blob/master/glove.840B.300d-char.txt</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXvKSEIeSvN5"
   },
   "source": [
    "<img src='https://i.imgur.com/EuuoJtr.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_char_embed=pd.read_csv('Character_Embedding.txt', delimiter=' ', columns=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "input_shape=(7544)#input is just of this dimension\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "\n",
    "conv_m=tf.keras.layers.Embedding(input_dim=(input_dim+1),output_dim=100,input_shape=(1,7544))(inputs) #Input shape=(Batch_size, Size of input)\n",
    "conv_m=tf.keras.layers.Conv1D(1,8,strides=2,activation='relu',input_shape=(1,100))(conv_m)\n",
    "\n",
    "conv_n=tf.keras.layers.Embedding(input_dim=(input_dim+1),output_dim=100,input_shape=(1,7544))(inputs) #Input shape=(Batch_size, Size of input)\n",
    "conv_n=tf.keras.layers.Conv1D(1,8,strides=2,activation='relu',input_shape=(1,100))(conv_n)\n",
    "\n",
    "conv_o=tf.keras.layers.Embedding(input_dim=(input_dim+1),output_dim=100,input_shape=(1,7544))(inputs) #Input shape=(Batch_size, Size of input)\n",
    "conv_o=tf.keras.layers.Conv1D(1,8,strides=2,activation='relu',input_shape=(1,100))(conv_o)\n",
    "\n",
    "output_1= tf.keras.layers.concatenate([conv_m,conv_n,conv_o])\n",
    "\n",
    "output_1=tf.keras.layers.MaxPool1D()(output_1)\n",
    "\n",
    "conv_i=tf.keras.layers.Conv1D(1,8,strides=2,activation='relu',input_shape=output_1.shape)(output_1)\n",
    "\n",
    "conv_j=tf.keras.layers.Conv1D(1,8,strides=2,activation='relu',input_shape=output_1.shape)(output_1)\n",
    "\n",
    "conv_k=tf.keras.layers.Conv1D(1,8,strides=2,activation='relu',input_shape=output_1.shape)(output_1)\n",
    "\n",
    "output_2= tf.keras.layers.concatenate([conv_i,conv_j,conv_k])\n",
    "\n",
    "output_2=tf.keras.layers.MaxPool1D()(output_2)\n",
    "output_2=tf.keras.layers.Conv1D(1,8,strides=2,activation='relu')(output_2)\n",
    "output_2=tf.keras.layers.Flatten()(output_2)\n",
    "output_2=tf.keras.layers.Dropout(0.2)(output_2)\n",
    "output_2=tf.keras.layers.Dense(20, activation = 'softmax')(output_2)\n",
    "\n",
    "model=tf.keras.Model(inputs=inputs,outputs=output_2)\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text Classification Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
