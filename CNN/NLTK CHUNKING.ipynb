{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='India and United States of America are really good friends and hopefully plans are underway to improve the economical rules'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=(nltk.word_tokenize(sentence))\n",
    "#Returns a list of words, where words also include the collins and semicollins\n",
    "#IMP: The tokenization does not happen assumming the spaces, but it actually happens considering the actual meaning of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India and United States of America are really good friends and hopefully plans are underway to improve the economical rules']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nltk.sent_tokenize(sentence))\n",
    "#Returns are listof sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postag, requires a list of words as input and then it tags then whether they are noun/verb etc\n",
    "pos_tags=nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "    #List of Pos Tags in NLTK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number Tag Description\n",
    "1.\tCC\tCoordinating conjunction\n",
    "2.\tCD\tCardinal number\n",
    "3.\tDT\tDeterminer\n",
    "4.\tEX\tExistential there\n",
    "5.\tFW\tForeign word\n",
    "6.\tIN\tPreposition or subordinating conjunction\n",
    "7.\tJJ\tAdjective\n",
    "8.\tJJR\tAdjective, comparative\n",
    "9.\tJJS\tAdjective, superlative\n",
    "10.\tLS\tList item marker\n",
    "11.\tMD\tModal\n",
    "12.\tNN\tNoun, singular or mass\n",
    "13.\tNNS\tNoun, plural\n",
    "14.\tNNP\tProper noun, singular\n",
    "15.\tNNPS\tProper noun, plural\n",
    "16.\tPDT\tPredeterminer\n",
    "17.\tPOS\tPossessive ending\n",
    "18.\tPRP\tPersonal pronoun\n",
    "19.\tPRP\tPossessive pronoun\n",
    "20.\tRB\tAdverb\n",
    "21.\tRBR\tAdverb, comparative\n",
    "22.\tRBS\tAdverb, superlative\n",
    "23.\tRP\tParticle\n",
    "24.\tSYM\tSymbol\n",
    "25.\tTO\tto\n",
    "26.\tUH\tInterjection\n",
    "27.\tVB\tVerb, base form\n",
    "28.\tVBD\tVerb, past tense\n",
    "29.\tVBG\tVerb, gerund or present participle\n",
    "30.\tVBN\tVerb, past participle\n",
    "31.\tVBP\tVerb, non-3rd person singular present\n",
    "32.\tVBZ\tVerb, 3rd person singular present\n",
    "33.\tWDT\tWh-determiner\n",
    "34.\tWP\tWh-pronoun\n",
    "35.\tWP\tPossessive wh-pronoun\n",
    "36.\tWRB\tWh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chunking is kind of a regex thing where we write a rule based on the POS Tags for eg <NN>+<Verb> and \n",
    "#it will give us all the chunks of data which are in this format.\n",
    "#Chunking uses postags to perform this chunking\n",
    "from nltk.chunk import *\n",
    "from nltk.chunk.util import *\n",
    "from nltk.chunk.regexp import *\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  India/NNP\n",
      "  and/CC\n",
      "  United/NNP\n",
      "  States/NNPS\n",
      "  of/IN\n",
      "  America/NNP\n",
      "  are/VBP\n",
      "  really/RB\n",
      "  good/JJ\n",
      "  friends/NNS\n",
      "  and/CC\n",
      "  hopefully/RB\n",
      "  plans/NNS\n",
      "  are/VBP\n",
      "  underway/RB\n",
      "  to/TO\n",
      "  improve/VB\n",
      "  the/DT\n",
      "  economical/JJ\n",
      "  rules/NNS)\n"
     ]
    }
   ],
   "source": [
    "chunk_rule='''ChunkRule:{<VB>*<VBZ>}'''\n",
    "chunking_obj=nltk.RegexpParser(chunk_rule)\n",
    "print(chunking_obj.parse(pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE India/NNP)\n",
      "  and/CC\n",
      "  (GPE United/NNP States/NNPS)\n",
      "  of/IN\n",
      "  (GPE America/NNP)\n",
      "  are/VBP\n",
      "  really/RB\n",
      "  good/JJ\n",
      "  friends/NNS\n",
      "  and/CC\n",
      "  hopefully/RB\n",
      "  plans/NNS\n",
      "  are/VBP\n",
      "  underway/RB\n",
      "  to/TO\n",
      "  improve/VB\n",
      "  the/DT\n",
      "  economical/JJ\n",
      "  rules/NNS)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank_chunk\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "print(ne_chunk(pos_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
