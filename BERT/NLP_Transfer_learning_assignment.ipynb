{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5el_8SqFqVAT"
   },
   "source": [
    "\n",
    "In this notebook, You will do amazon review classification with BERT.[Download data from [this](https://www.kaggle.com/snap/amazon-fine-food-reviews/data) link]\n",
    "<pre> \n",
    "It contains 5 parts as below.  Detailed instrctions are given in the each cell. please read every comment we have written. \n",
    "    1. Preprocessing \n",
    "    2. Creating a BERT model from the Tensorflow HUB.\n",
    "    3. Tokenization\n",
    "    4. getting the pretrained embedding Vector for a given review from the BERT.\n",
    "    5. Using the embedding data apply NN and classify the reviews.\n",
    "    6. Creating a Data pipeline for BERT Model. \n",
    "\n",
    "<font size=5>instructions:</font>\n",
    "\n",
    "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. \n",
    "    If you manipulate any, it will be considered as plagiarised. \n",
    "    \n",
    "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
    "    \n",
    "    3. please return outputs in the same format what we asked. Eg. Don't return List if we are asking for a numpy array.\n",
    "    \n",
    "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
    "    \n",
    "    5. We are giving instructions at each section if necessary, please follow them. \n",
    "\n",
    "<font size=5>Every Grader function has to return True. </font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6JSKPjKwOLP"
   },
   "outputs": [],
   "source": [
    "#in this assignment you need two files reviews.csv and tokenization file\n",
    "#you can use gdown module to import both the files in colab from Google drive\n",
    "#the syntax is for gdown is !gdown --id file_id\n",
    "#please run the below cell to import the required files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUGbEZafwwzX",
    "outputId": "84e65666-ecdd-4616-9d83-bb502ac7ade6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt\n",
      "To: /home/josephnadar1998/BERT/Reviews.csv\n",
      "100%|████████████████████████████████████████| 301M/301M [00:04<00:00, 69.8MB/s]\n",
      "/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=13exfXiyiByluh1PfYK1EyZyizqxeCVG9\n",
      "To: /home/josephnadar1998/BERT/tokenization.py\n",
      "100%|██████████████████████████████████████| 17.3k/17.3k [00:00<00:00, 21.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "'''!gdown --id 1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt\n",
    "!gdown --id 13exfXiyiByluh1PfYK1EyZyizqxeCVG9'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wOtG4cf0qVAZ"
   },
   "outputs": [],
   "source": [
    "#all imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0Epckid5XDi",
    "outputId": "84d102e8-f82b-4448-a00c-691e010d9491"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OcmiHdAJqVAi",
    "outputId": "be198c09-ee47-4212-f518-ca53bbf60daf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBsay58AqVAo"
   },
   "source": [
    "<font size=4>Grader function 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTBvOKFeqVAq",
    "outputId": "8cf7f9ef-3feb-4b61-c039-c261c5e064ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_tf_version():\n",
    "    assert((tf.__version__)>'2')\n",
    "    return True\n",
    "grader_tf_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTWRqbrBqVAu"
   },
   "source": [
    "<pre><font size=6>Part-1: Preprocessing</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3csZKDrqVAv",
    "outputId": "b218c2b2-6da8-45c2-8f71-d26a5be24327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Read the dataset - Amazon fine food reviews\n",
    "reviews = pd.read_csv(r\"Reviews.csv\")\n",
    "#check the info of the dataset\n",
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xokNn7qZqVAz",
    "outputId": "4b99150c-0d31-4a5e-9a68-c2912cc9a75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Text    568454 non-null  object\n",
      " 1   Score   568454 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.7+ MB\n",
      "None\n",
      "**************************************************\n",
      "Shape before dropping NA (568454, 2)\n",
      "Shape after dropping NA (568454, 2)\n"
     ]
    }
   ],
   "source": [
    "#get only 2 columns - Text, Score\n",
    "#drop the NAN values\n",
    "print(reviews[['Text','Score']].info())\n",
    "print('*'*50)\n",
    "print('Shape before dropping NA',reviews[['Text','Score']].shape)\n",
    "\n",
    "review_text=reviews[['Text','Score']].dropna(axis=0)\n",
    "\n",
    "print('Shape after dropping NA',review_text.shape)\n",
    "\n",
    "#if score> 3, set score = 1\n",
    "#if score<=2, set score = 0\n",
    "#if score == 3, remove the rows. \n",
    "\n",
    "review_text.loc[review_text['Score']<=2,'Score']=0\n",
    "review_text.loc[review_text['Score']>3,'Score']=1\n",
    "review_text=review_text.drop(review_text[review_text['Score']==3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "8S8ufdYj6_mL",
    "outputId": "7134250f-8900-43c5-a8c5-c8d7698f08d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Text, Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text[review_text['Score']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogpscOlX7adN",
    "outputId": "ef992da4-8217-48df-e8f0-36149b4bacb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=review_text\n",
    "review_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVe8LlkrqVA6"
   },
   "source": [
    "<font size=4>Grader function 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mDXSiJpqVA7",
    "outputId": "63e0eb68-8907-4569-a451-f04793a715c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_reviews():\n",
    "    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n",
    "    assert(temp_shape == True)\n",
    "    return True\n",
    "grader_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xYZ-UB9UqVA-"
   },
   "outputs": [],
   "source": [
    "def get_wordlen(x):\n",
    "    return len(x.split())\n",
    "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
    "reviews = reviews[reviews.len<50]\n",
    "reviews = reviews.sample(n=100000, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "2eI_C5diNqWm",
    "outputId": "01c892e9-1667-4396-a185-c41e71281355"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "x='I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most <Hope><>.'\n",
    "pattern=r'<.+>'\n",
    "re.sub(pattern,'',x,flags=re.I|re.M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CvldQriGqVBB"
   },
   "outputs": [],
   "source": [
    "#remove HTML from the Text column and save in the Text column only\n",
    "import re\n",
    "\n",
    "def text_preprocess(x):\n",
    "  pattern=r'<.+>'\n",
    "  a=re.sub(pattern,'',x,flags=re.I|re.M)\n",
    "  return a\n",
    "\n",
    "reviews['Text']=reviews['Text'].apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AhfN1s2mqVBD",
    "outputId": "22f9b2b1-b259-4f88-bd60-4ba242417fec",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64117</th>\n",
       "      <td>The tea was of great quality and it tasted lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418112</th>\n",
       "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357829</th>\n",
       "      <td>Great product. Does not completely get rid of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175872</th>\n",
       "      <td>This gum is my favorite!  I would advise every...</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178716</th>\n",
       "      <td>I also found out about this product because of...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  len\n",
       "64117   The tea was of great quality and it tasted lik...      1   30\n",
       "418112  My cat loves this.  The pellets are nice and s...      1   31\n",
       "357829  Great product. Does not completely get rid of ...      1   41\n",
       "175872  This gum is my favorite!  I would advise every...      1   27\n",
       "178716  I also found out about this product because of...      1   22"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print head 5\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to disk. if we need, we can load preprocessed data directly. \n",
    "#reviews.to_csv('preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The tea was of great quality and it tasted lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great product. Does not completely get rid of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  len\n",
       "0  The tea was of great quality and it tasted lik...      1   30\n",
       "1  My cat loves this.  The pellets are nice and s...      1   31\n",
       "2  Great product. Does not completely get rid of ...      1   41"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=pd.read_csv('preprocessed.csv')\n",
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NsYDd3okqVBF"
   },
   "outputs": [],
   "source": [
    "#split the data into train and test data(20%) with Stratify sampling, random state 33, \n",
    "from sklearn.model_selection import train_test_split\n",
    "x=reviews.drop('Score', axis=1)\n",
    "y=reviews['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "1C4QS3GrV2VS",
    "outputId": "a4c982be-25bd-47d7-c0bf-2e124e3ee671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_train.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "-Q6OAcrOqVBI",
    "outputId": "28b0ff43-2781-4fae-955e-2dd24a0e77a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGYCAYAAACgQ/O7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmNUlEQVR4nO3df1TVdYL/8ddV45Kt9/qD4MKJUaYfoiOi0g7eNk1XlqtxmmHH3Sm1tEIdZ7FJKUMm10Hds7i65NgZleOW0Z7RzdxTnEIPeqWUHG4qKJI2cFJhsJMXt0yuUiHq/f4xh8+3e0SLgpC3z8c5nzN8Pu/3/dz3hzPG89z74WILBoNBAQAAGKZXdy8AAACgKxA5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIzUp7sX0J2uXLmiTz75RP369ZPNZuvu5QAAgG8hGAzq/PnziomJUa9e13695qaOnE8++USxsbHdvQwAAPAdnDp1Snfcccc1x2/qyOnXr5+kv36THA5HN68GAAB8G4FAQLGxsdbP8Wu5qSOn7S0qh8NB5AAA0MN8060m3HgMAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMFKHI6esrEwPPfSQYmJiZLPZVFRUFDJus9na3VavXm3NGTJkyFXjK1euDDlPdXW1xo0bp/DwcMXGxmrVqlVXrWXbtm2Kj49XeHi4EhIStGPHjo5eDgAAMFSHI6e5uVmJiYlat25du+OnT58O2TZt2iSbzaapU6eGzFu+fHnIvKeeesoaCwQCSk1N1eDBg1VZWanVq1crNzdXGzdutOaUl5dr2rRpysjI0OHDh5Wenq709HQdPXq0o5cEAAAMZAsGg8Hv/GCbTW+++abS09OvOSc9PV3nz59XaWmpdWzIkCFasGCBFixY0O5jNmzYoOeff15+v19hYWGSpMWLF6uoqEg1NTWSpIcffljNzc0qLi62Hjd27FiNGjVKBQUF32r9gUBATqdTTU1N/FkHAAB6iG/787tL78lpbGzU9u3blZGRcdXYypUrNWjQII0ePVqrV6/WpUuXrDGfz6fx48dbgSNJHo9HtbW1+vzzz605KSkpIef0eDzy+XzXXE9LS4sCgUDIBgAAzNSlf6Dz1VdfVb9+/fSLX/wi5PhvfvMbjRkzRgMHDlR5eblycnJ0+vRpvfDCC5Ikv9+vuLi4kMdERUVZYwMGDJDf77eOfX2O3++/5nry8vK0bNmyzrg0AABwg+vSyNm0aZNmzJih8PDwkONZWVnW1yNHjlRYWJh+9atfKS8vT3a7vcvWk5OTE/LcbX+qHQAAmKfLIue9995TbW2ttm7d+o1zk5OTdenSJdXX12vo0KFyuVxqbGwMmdO273K5rP9tb07beHvsdnuXRlRPMmTx9u5eAn5A9SvTunsJAPCD67J7cl5++WUlJSUpMTHxG+dWVVWpV69eioyMlCS53W6VlZWptbXVmuP1ejV06FANGDDAmvP1m5nb5rjd7k68CgAA0FN1OHIuXLigqqoqVVVVSZLq6upUVVWlhoYGa04gENC2bds0e/bsqx7v8/n0+9//XkeOHNHJkye1efNmLVy4UI8++qgVMNOnT1dYWJgyMjJ07Ngxbd26VWvXrg15q+npp59WSUmJ8vPzVVNTo9zcXFVUVGj+/PkdvSQAAGCgDr9dVVFRoYkTJ1r7beExa9YsFRYWSpJee+01BYNBTZs27arH2+12vfbaa8rNzVVLS4vi4uK0cOHCkIBxOp3atWuXMjMzlZSUpIiICC1dulRz58615tx3333asmWLlixZot/+9re6++67VVRUpBEjRnT0kgAAgIG+1+fk9HQ38+fkcE/OzYV7cgCY5Ib4nBwAAIDuQuQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADBShyOnrKxMDz30kGJiYmSz2VRUVBQy/vjjj8tms4VskydPDplz9uxZzZgxQw6HQ/3791dGRoYuXLgQMqe6ulrjxo1TeHi4YmNjtWrVqqvWsm3bNsXHxys8PFwJCQnasWNHRy8HAAAYqsOR09zcrMTERK1bt+6acyZPnqzTp09b2//8z/+EjM+YMUPHjh2T1+tVcXGxysrKNHfuXGs8EAgoNTVVgwcPVmVlpVavXq3c3Fxt3LjRmlNeXq5p06YpIyNDhw8fVnp6utLT03X06NGOXhIAADCQLRgMBr/zg202vfnmm0pPT7eOPf744zp37txVr/C0+fOf/6zhw4fr4MGDuvfeeyVJJSUlevDBB/Xxxx8rJiZGGzZs0PPPPy+/36+wsDBJ0uLFi1VUVKSamhpJ0sMPP6zm5mYVFxdb5x47dqxGjRqlgoKCb7X+QCAgp9OppqYmORyO7/Ad6LmGLN7e3UvAD6h+ZVp3LwEAOs23/fndJffk7NmzR5GRkRo6dKh+/etf67PPPrPGfD6f+vfvbwWOJKWkpKhXr17av3+/NWf8+PFW4EiSx+NRbW2tPv/8c2tOSkpKyPN6PB75fL5rrqulpUWBQCBkAwAAZur0yJk8ebL++7//W6WlpfqP//gP7d27V1OmTNHly5clSX6/X5GRkSGP6dOnjwYOHCi/32/NiYqKCpnTtv9Nc9rG25OXlyen02ltsbGx3+9iAQDADatPZ5/wkUcesb5OSEjQyJEjdeedd2rPnj2aNGlSZz9dh+Tk5CgrK8vaDwQChA4AAIbq8l8h//GPf6yIiAgdP35ckuRyuXTmzJmQOZcuXdLZs2flcrmsOY2NjSFz2va/aU7beHvsdrscDkfIBgAAzNTlkfPxxx/rs88+U3R0tCTJ7Xbr3LlzqqystOa88847unLlipKTk605ZWVlam1tteZ4vV4NHTpUAwYMsOaUlpaGPJfX65Xb7e7qSwIAAD1AhyPnwoULqqqqUlVVlSSprq5OVVVVamho0IULF7Ro0SK9//77qq+vV2lpqX7+85/rrrvuksfjkSQNGzZMkydP1pw5c3TgwAH96U9/0vz58/XII48oJiZGkjR9+nSFhYUpIyNDx44d09atW7V27dqQt5qefvpplZSUKD8/XzU1NcrNzVVFRYXmz5/fCd8WAADQ03U4cioqKjR69GiNHj1akpSVlaXRo0dr6dKl6t27t6qrq/Wzn/1M99xzjzIyMpSUlKT33ntPdrvdOsfmzZsVHx+vSZMm6cEHH9T9998f8hk4TqdTu3btUl1dnZKSkvTMM89o6dKlIZ+lc99992nLli3auHGjEhMT9b//+78qKirSiBEjvs/3AwAAGOJ7fU5OT8fn5OBmwefkADBJt35ODgAAQHcjcgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYKQOR05ZWZkeeughxcTEyGazqaioyBprbW1Vdna2EhISdNtttykmJkYzZ87UJ598EnKOIUOGyGazhWwrV64MmVNdXa1x48YpPDxcsbGxWrVq1VVr2bZtm+Lj4xUeHq6EhATt2LGjo5cDAAAM1eHIaW5uVmJiotatW3fV2BdffKFDhw7pX//1X3Xo0CG98cYbqq2t1c9+9rOr5i5fvlynT5+2tqeeesoaCwQCSk1N1eDBg1VZWanVq1crNzdXGzdutOaUl5dr2rRpysjI0OHDh5Wenq709HQdPXq0o5cEAAAM1KejD5gyZYqmTJnS7pjT6ZTX6w059oc//EE//elP1dDQoB/96EfW8X79+snlcrV7ns2bN+vixYvatGmTwsLC9JOf/ERVVVV64YUXNHfuXEnS2rVrNXnyZC1atEiStGLFCnm9Xv3hD39QQUFBRy8LAAAYpsvvyWlqapLNZlP//v1Djq9cuVKDBg3S6NGjtXr1al26dMka8/l8Gj9+vMLCwqxjHo9HtbW1+vzzz605KSkpIef0eDzy+XxddzEAAKDH6PArOR3x1VdfKTs7W9OmTZPD4bCO/+Y3v9GYMWM0cOBAlZeXKycnR6dPn9YLL7wgSfL7/YqLiws5V1RUlDU2YMAA+f1+69jX5/j9/muup6WlRS0tLdZ+IBD43tcIAABuTF0WOa2trfrlL3+pYDCoDRs2hIxlZWVZX48cOVJhYWH61a9+pby8PNnt9q5akvLy8rRs2bIuOz8AALhxdMnbVW2B85e//EVerzfkVZz2JCcn69KlS6qvr5ckuVwuNTY2hsxp22+7j+dac651n48k5eTkqKmpydpOnTrV0UsDAAA9RKdHTlvgfPTRR9q9e7cGDRr0jY+pqqpSr169FBkZKUlyu90qKytTa2urNcfr9Wro0KEaMGCANae0tDTkPF6vV263+5rPY7fb5XA4QjYAAGCmDr9ddeHCBR0/ftzar6urU1VVlQYOHKjo6Gj90z/9kw4dOqTi4mJdvnzZukdm4MCBCgsLk8/n0/79+zVx4kT169dPPp9PCxcu1KOPPmoFzPTp07Vs2TJlZGQoOztbR48e1dq1a7VmzRrreZ9++mk98MADys/PV1paml577TVVVFSE/Jo5AAC4edmCwWCwIw/Ys2ePJk6ceNXxWbNmKTc396obhtu8++67mjBhgg4dOqR/+Zd/UU1NjVpaWhQXF6fHHntMWVlZIffjVFdXKzMzUwcPHlRERISeeuopZWdnh5xz27ZtWrJkierr63X33Xdr1apVevDBB7/1tQQCATmdTjU1Nd10r+oMWby9u5eAH1D9yrTuXgIAdJpv+/O7w5FjEiIHNwsiB4BJvu3Pb/52FQAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASB2OnLKyMj300EOKiYmRzWZTUVFRyHgwGNTSpUsVHR2tW2+9VSkpKfroo49C5pw9e1YzZsyQw+FQ//79lZGRoQsXLoTMqa6u1rhx4xQeHq7Y2FitWrXqqrVs27ZN8fHxCg8PV0JCgnbs2NHRywEAAIbqcOQ0NzcrMTFR69ata3d81apVevHFF1VQUKD9+/frtttuk8fj0VdffWXNmTFjho4dOyav16vi4mKVlZVp7ty51nggEFBqaqoGDx6syspKrV69Wrm5udq4caM1p7y8XNOmTVNGRoYOHz6s9PR0paen6+jRox29JAAAYCBbMBgMfucH22x68803lZ6eLumvr+LExMTomWee0bPPPitJampqUlRUlAoLC/XII4/oz3/+s4YPH66DBw/q3nvvlSSVlJTowQcf1Mcff6yYmBht2LBBzz//vPx+v8LCwiRJixcvVlFRkWpqaiRJDz/8sJqbm1VcXGytZ+zYsRo1apQKCgq+1foDgYCcTqeamprkcDi+67ehRxqyeHt3LwE/oPqVad29BADoNN/253en3pNTV1cnv9+vlJQU65jT6VRycrJ8Pp8kyefzqX///lbgSFJKSop69eql/fv3W3PGjx9vBY4keTwe1dbW6vPPP7fmfP152ua0PU97WlpaFAgEQjYAAGCmTo0cv98vSYqKigo5HhUVZY35/X5FRkaGjPfp00cDBw4MmdPeOb7+HNea0zbenry8PDmdTmuLjY3t6CUCAIAe4qb67aqcnBw1NTVZ26lTp7p7SQAAoIt0auS4XC5JUmNjY8jxxsZGa8zlcunMmTMh45cuXdLZs2dD5rR3jq8/x7XmtI23x263y+FwhGwAAMBMnRo5cXFxcrlcKi0ttY4FAgHt379fbrdbkuR2u3Xu3DlVVlZac9555x1duXJFycnJ1pyysjK1trZac7xer4YOHaoBAwZYc77+PG1z2p4HAADc3DocORcuXFBVVZWqqqok/fVm46qqKjU0NMhms2nBggX6t3/7N7311lv64IMPNHPmTMXExFi/gTVs2DBNnjxZc+bM0YEDB/SnP/1J8+fP1yOPPKKYmBhJ0vTp0xUWFqaMjAwdO3ZMW7du1dq1a5WVlWWt4+mnn1ZJSYny8/NVU1Oj3NxcVVRUaP78+d//uwIAAHq8Ph19QEVFhSZOnGjtt4XHrFmzVFhYqOeee07Nzc2aO3euzp07p/vvv18lJSUKDw+3HrN582bNnz9fkyZNUq9evTR16lS9+OKL1rjT6dSuXbuUmZmppKQkRUREaOnSpSGfpXPfffdpy5YtWrJkiX7729/q7rvvVlFRkUaMGPGdvhEAAMAs3+tzcno6PicHNws+JweASbrlc3IAAABuFEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACM1OmRM2TIENlstqu2zMxMSdKECROuGps3b17IORoaGpSWlqa+ffsqMjJSixYt0qVLl0Lm7NmzR2PGjJHdbtddd92lwsLCzr4UAADQg/Xp7BMePHhQly9ftvaPHj2qf/iHf9A///M/W8fmzJmj5cuXW/t9+/a1vr58+bLS0tLkcrlUXl6u06dPa+bMmbrlllv07//+75Kkuro6paWlad68edq8ebNKS0s1e/ZsRUdHy+PxdPYlAQCAHqjTI+f2228P2V+5cqXuvPNOPfDAA9axvn37yuVytfv4Xbt26cMPP9Tu3bsVFRWlUaNGacWKFcrOzlZubq7CwsJUUFCguLg45efnS5KGDRumffv2ac2aNUQOAACQ1MX35Fy8eFF//OMf9eSTT8pms1nHN2/erIiICI0YMUI5OTn64osvrDGfz6eEhARFRUVZxzwejwKBgI4dO2bNSUlJCXkuj8cjn8/XlZcDAAB6kE5/JefrioqKdO7cOT3++OPWsenTp2vw4MGKiYlRdXW1srOzVVtbqzfeeEOS5Pf7QwJHkrXv9/uvOycQCOjLL7/Urbfe2u56Wlpa1NLSYu0HAoHvfY0AAODG1KWR8/LLL2vKlCmKiYmxjs2dO9f6OiEhQdHR0Zo0aZJOnDihO++8syuXo7y8PC1btqxLnwMAANwYuuztqr/85S/avXu3Zs+efd15ycnJkqTjx49LklwulxobG0PmtO233cdzrTkOh+Oar+JIUk5Ojpqamqzt1KlTHbsoAADQY3RZ5LzyyiuKjIxUWlradedVVVVJkqKjoyVJbrdbH3zwgc6cOWPN8Xq9cjgcGj58uDWntLQ05Dxer1dut/u6z2W32+VwOEI2AABgpi6JnCtXruiVV17RrFmz1KfP/39H7MSJE1qxYoUqKytVX1+vt956SzNnztT48eM1cuRISVJqaqqGDx+uxx57TEeOHNHOnTu1ZMkSZWZmym63S5LmzZunkydP6rnnnlNNTY3Wr1+v119/XQsXLuyKywEAAD1Ql0TO7t271dDQoCeffDLkeFhYmHbv3q3U1FTFx8frmWee0dSpU/X2229bc3r37q3i4mL17t1bbrdbjz76qGbOnBnyuTpxcXHavn27vF6vEhMTlZ+fr5deeolfHwcAABZbMBgMdvciuksgEJDT6VRTU9NN99bVkMXbu3sJ+AHVr7z+28YA0JN825/f/O0qAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICROj1ycnNzZbPZQrb4+Hhr/KuvvlJmZqYGDRqkv/mbv9HUqVPV2NgYco6GhgalpaWpb9++ioyM1KJFi3Tp0qWQOXv27NGYMWNkt9t11113qbCwsLMvBQAA9GBd8krOT37yE50+fdra9u3bZ40tXLhQb7/9trZt26a9e/fqk08+0S9+8Qtr/PLly0pLS9PFixdVXl6uV199VYWFhVq6dKk1p66uTmlpaZo4caKqqqq0YMECzZ49Wzt37uyKywEAAD1Qny45aZ8+crlcVx1vamrSyy+/rC1btujv//7vJUmvvPKKhg0bpvfff19jx47Vrl279OGHH2r37t2KiorSqFGjtGLFCmVnZys3N1dhYWEqKChQXFyc8vPzJUnDhg3Tvn37tGbNGnk8nq64JAAA0MN0ySs5H330kWJiYvTjH/9YM2bMUENDgySpsrJSra2tSklJsebGx8frRz/6kXw+nyTJ5/MpISFBUVFR1hyPx6NAIKBjx45Zc75+jrY5bee4lpaWFgUCgZANAACYqdMjJzk5WYWFhSopKdGGDRtUV1encePG6fz58/L7/QoLC1P//v1DHhMVFSW/3y9J8vv9IYHTNt42dr05gUBAX3755TXXlpeXJ6fTaW2xsbHf93IBAMANqtPfrpoyZYr19ciRI5WcnKzBgwfr9ddf16233trZT9chOTk5ysrKsvYDgQChAwCAobr8V8j79++ve+65R8ePH5fL5dLFixd17ty5kDmNjY3WPTwul+uq37Zq2/+mOQ6H47ohZbfb5XA4QjYAAGCmLo+cCxcu6MSJE4qOjlZSUpJuueUWlZaWWuO1tbVqaGiQ2+2WJLndbn3wwQc6c+aMNcfr9crhcGj48OHWnK+fo21O2zkAAAA6PXKeffZZ7d27V/X19SovL9c//uM/qnfv3po2bZqcTqcyMjKUlZWld999V5WVlXriiSfkdrs1duxYSVJqaqqGDx+uxx57TEeOHNHOnTu1ZMkSZWZmym63S5LmzZunkydP6rnnnlNNTY3Wr1+v119/XQsXLuzsywEAAD1Up9+T8/HHH2vatGn67LPPdPvtt+v+++/X+++/r9tvv12StGbNGvXq1UtTp05VS0uLPB6P1q9fbz2+d+/eKi4u1q9//Wu53W7ddtttmjVrlpYvX27NiYuL0/bt27Vw4UKtXbtWd9xxh1566SV+fRwAAFhswWAw2N2L6C6BQEBOp1NNTU033f05QxZv7+4l4AdUvzKtu5cAAJ3m2/785m9XAQAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACM1OmRk5eXp7/9279Vv379FBkZqfT0dNXW1obMmTBhgmw2W8g2b968kDkNDQ1KS0tT3759FRkZqUWLFunSpUshc/bs2aMxY8bIbrfrrrvuUmFhYWdfDgAA6KE6PXL27t2rzMxMvf/++/J6vWptbVVqaqqam5tD5s2ZM0enT5+2tlWrVlljly9fVlpami5evKjy8nK9+uqrKiws1NKlS605dXV1SktL08SJE1VVVaUFCxZo9uzZ2rlzZ2dfEgAA6IH6dPYJS0pKQvYLCwsVGRmpyspKjR8/3jret29fuVyuds+xa9cuffjhh9q9e7eioqI0atQorVixQtnZ2crNzVVYWJgKCgoUFxen/Px8SdKwYcO0b98+rVmzRh6Pp7MvCwB6jCGLt3f3EvADql+Z1t1LuGF1+T05TU1NkqSBAweGHN+8ebMiIiI0YsQI5eTk6IsvvrDGfD6fEhISFBUVZR3zeDwKBAI6duyYNSclJSXknB6PRz6f75praWlpUSAQCNkAAICZOv2VnK+7cuWKFixYoL/7u7/TiBEjrOPTp0/X4MGDFRMTo+rqamVnZ6u2tlZvvPGGJMnv94cEjiRr3+/3X3dOIBDQl19+qVtvvfWq9eTl5WnZsmWdeo0AAODG1KWRk5mZqaNHj2rfvn0hx+fOnWt9nZCQoOjoaE2aNEknTpzQnXfe2WXrycnJUVZWlrUfCAQUGxvbZc8HAAC6T5e9XTV//nwVFxfr3Xff1R133HHducnJyZKk48ePS5JcLpcaGxtD5rTtt93Hc605Doej3VdxJMlut8vhcIRsAADATJ0eOcFgUPPnz9ebb76pd955R3Fxcd/4mKqqKklSdHS0JMntduuDDz7QmTNnrDler1cOh0PDhw+35pSWloacx+v1yu12d9KVAACAnqzTIyczM1N//OMftWXLFvXr109+v19+v19ffvmlJOnEiRNasWKFKisrVV9fr7feekszZ87U+PHjNXLkSElSamqqhg8frscee0xHjhzRzp07tWTJEmVmZsput0uS5s2bp5MnT+q5555TTU2N1q9fr9dff10LFy7s7EsCAAA9UKdHzoYNG9TU1KQJEyYoOjra2rZu3SpJCgsL0+7du5Wamqr4+Hg988wzmjp1qt5++23rHL1791ZxcbF69+4tt9utRx99VDNnztTy5cutOXFxcdq+fbu8Xq8SExOVn5+vl156iV8fBwAAkrrgxuNgMHjd8djYWO3du/cbzzN48GDt2LHjunMmTJigw4cPd2h9AADg5sDfrgIAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYKQeHznr1q3TkCFDFB4eruTkZB04cKC7lwQAAG4APTpytm7dqqysLP3ud7/ToUOHlJiYKI/HozNnznT30gAAQDfr0ZHzwgsvaM6cOXriiSc0fPhwFRQUqG/fvtq0aVN3Lw0AAHSzPt29gO/q4sWLqqysVE5OjnWsV69eSklJkc/na/cxLS0tamlpsfabmpokSYFAoGsXewO60vJFdy8BP6Cb8f/jNzP+fd9cbsZ/323XHAwGrzuvx0bOp59+qsuXLysqKirkeFRUlGpqatp9TF5enpYtW3bV8djY2C5ZI3CjcP6+u1cAoKvczP++z58/L6fTec3xHhs530VOTo6ysrKs/StXrujs2bMaNGiQbDZbN64MP4RAIKDY2FidOnVKDoeju5cDoBPx7/vmEgwGdf78ecXExFx3Xo+NnIiICPXu3VuNjY0hxxsbG+Vyudp9jN1ul91uDznWv3//rloiblAOh4P/CAKG4t/3zeN6r+C06bE3HoeFhSkpKUmlpaXWsStXrqi0tFRut7sbVwYAAG4EPfaVHEnKysrSrFmzdO+99+qnP/2pfv/736u5uVlPPPFEdy8NAAB0sx4dOQ8//LD+7//+T0uXLpXf79eoUaNUUlJy1c3IgPTXtyt/97vfXfWWJYCej3/faI8t+E2/fwUAANAD9dh7cgAAAK6HyAEAAEYicgAAgJGIHAAAYCQiBwAAGKlH/wo5AODm8+mnn2rTpk3y+Xzy+/2SJJfLpfvuu0+PP/64br/99m5eIW4UvJKDm9KpU6f05JNPdvcyAHTQwYMHdc899+jFF1+U0+nU+PHjNX78eDmdTr344ouKj49XRUVFdy8TNwg+Jwc3pSNHjmjMmDG6fPlydy8FQAeMHTtWiYmJKigouOoPKweDQc2bN0/V1dXy+XzdtELcSHi7CkZ66623rjt+8uTJH2glADrTkSNHVFhYeFXgSJLNZtPChQs1evToblgZbkREDoyUnp4um82m671Q2d5/JAHc2Fwulw4cOKD4+Ph2xw8cOMCf9oGFyIGRoqOjtX79ev385z9vd7yqqkpJSUk/8KoAfF/PPvus5s6dq8rKSk2aNMkKmsbGRpWWluq//uu/9J//+Z/dvErcKIgcGCkpKUmVlZXXjJxvepUHwI0pMzNTERERWrNmjdavX2/dV9e7d28lJSWpsLBQv/zlL7t5lbhRcOMxjPTee++publZkydPbne8ublZFRUVeuCBB37glQHoLK2trfr0008lSREREbrlllu6eUW40RA5AADASHxODgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBI/w/Q5UZZUzUKDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBtqNGN9qVBM"
   },
   "source": [
    "<pre><font size=6>Part-2: Creating BERT Model</font> \n",
    "\n",
    "If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n",
    "we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n",
    "\n",
    "\n",
    "For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
    "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i8xd2HejqVBN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:From /home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "## Loading the Pretrained Model from tensorflow HUB\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
    "max_seq_length = 55\n",
    "\n",
    "#BERT takes 3 inputs\n",
    "\n",
    "#this is input words. Sequence of words represented as integers\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "\n",
    "#mask vector if you are padding anything\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "\n",
    "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
    "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
    "#second seq segment vector are 1's\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "#bert layer \n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "#Bert model\n",
    "#We are using only pooled output not sequence out. \n",
    "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQJsjg6fqVBQ",
    "outputId": "b06e65c1-9608-4b3f-9d0f-23c572b4625c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 55)]         0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 55)]         0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 55)]         0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
      "                                 (None, 55, 768)]                 'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,482,241\n",
      "Trainable params: 0\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3z0OMA5qVBS",
    "outputId": "8d073bb7-4ed5-47de-bb7e-5a94d8b460ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ewv4hFCsqVBU"
   },
   "source": [
    "<pre><font size=6>Part-3: Tokenization</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tX3VEFjiqVBU"
   },
   "outputs": [],
   "source": [
    "#getting Vocab file\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Y_iPwa99qVBW",
    "outputId": "ab5dfd5f-fc91-4e00-cfd4-9e57f068c55d"
   },
   "outputs": [],
   "source": [
    "import tokenization #We have given tokenization.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "guJMLJ8bqVBY"
   },
   "outputs": [],
   "source": [
    "# Create tokenizer \" Instantiate FullTokenizer\" \n",
    "# name must be \"tokenizer\"\n",
    "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
    "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
    "# please check the \"tokenization.py\" file the complete implementation\n",
    "tokenizer=tokenization.FullTokenizer(vocab_file,do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qlGFtp2xxzt6"
   },
   "outputs": [],
   "source": [
    "# if you are getting error for sentencepiece module you can install it using below command while running this cell for the first time\n",
    "#!pip install sentencepiece\n",
    "tokenizer=tokenization.FullTokenizer(vocab_file,do_lower_case )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKkGLhR-qVBd"
   },
   "source": [
    "<font size=4>Grader function 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2CPu850xqVBe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it has to give no error \n",
    "def grader_tokenize(tokenizer):\n",
    "    out = False\n",
    "    try:\n",
    "        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n",
    "    except:\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9crhPylQqVBg"
   },
   "outputs": [],
   "source": [
    "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
    "\n",
    "x_train['Text']=x_train['Text'].astype(str)\n",
    "x_test['Text']=x_test['Text'].astype(str)\n",
    "\n",
    "X_train_tokens=x_train['Text'].apply(tokenizer.tokenize)\n",
    "X_test_tokens=x_test['Text'].apply(tokenizer.tokenize)\n",
    "\n",
    "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
    "def preprocess(x):\n",
    "    tokens=x[:(max_seq_length-2)]\n",
    "    tokens=['[CLS]',*tokens,'[SEP]']\n",
    "    return tokens\n",
    "\n",
    "X_train_tokens=X_train_tokens.apply(preprocess)\n",
    "X_test_tokens=X_test_tokens.apply(preprocess)\n",
    "\n",
    "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
    "def padding(x):\n",
    "    if len(x)>max_seq_length:\n",
    "        a=x[:max_seq_length]\n",
    "        a=np.array([*a,'[SEP]'])\n",
    "        \n",
    "    elif len(x)<max_seq_length:\n",
    "        a=x.copy()\n",
    "        pad=[]\n",
    "        for i in range((max_seq_length-len(x))):\n",
    "            pad.append('[PAD]')\n",
    "        a=np.array([*a,*pad])\n",
    "    else:\n",
    "        a=x\n",
    "    return a\n",
    "\n",
    "X_train_tokens=X_train_tokens.apply(padding)\n",
    "X_test_tokens=X_test_tokens.apply(padding)\n",
    "\n",
    "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
    "\n",
    "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
    "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
    "def masking(x):\n",
    "    mask=[]\n",
    "    for tokens in x:\n",
    "        if tokens=='[PAD]':\n",
    "            mask.append(0)\n",
    "        else:\n",
    "            mask.append(1)\n",
    "    return np.array(mask)\n",
    "\n",
    "X_train_mask=X_train_tokens.apply(masking)\n",
    "X_test_mask=X_test_tokens.apply(masking)\n",
    "\n",
    "X_train_tokens=X_train_tokens.apply(tokenizer.convert_tokens_to_ids)\n",
    "X_test_tokens=X_test_tokens.apply(tokenizer.convert_tokens_to_ids)\n",
    "\n",
    "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
    "X_train_segment=np.zeros((len(X_train_tokens),55))\n",
    "X_test_segment=np.zeros((len(X_test_tokens),55))\n",
    "\n",
    "# type of all the above arrays should be numpy arrays\n",
    "\n",
    "# after execution of this cell, you have to get \n",
    "# X_train_tokens, X_train_mask, X_train_segment\n",
    "# X_test_tokens, X_test_mask, X_test_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens=X_train_tokens.values\n",
    "X_train_tokens=np.array([np.array(i) for i in X_train_tokens])\n",
    "\n",
    "X_test_tokens=X_test_tokens.values\n",
    "X_test_tokens=np.array([np.array(i) for i in X_test_tokens])\n",
    "\n",
    "X_train_mask=X_train_mask.values\n",
    "X_train_mask=np.array([np.array(i) for i in X_train_mask])\n",
    "\n",
    "X_test_mask=X_test_mask.values\n",
    "X_test_mask=np.array([np.array(i) for i in X_test_mask])\n",
    "\n",
    "X_test_segment\n",
    "X_train_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (80000, 55)\n",
      "<class 'numpy.ndarray'> (80000, 55)\n",
      "<class 'numpy.ndarray'> (20000, 55)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_tokens),X_train_tokens.shape)\n",
    "print(type(X_train_mask),X_train_mask.shape)\n",
    "print(type(X_test_segment),X_test_segment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv1-t4OjqVBj"
   },
   "source": [
    "#### Example\n",
    "<img src='https://i.imgur.com/5AhhmgU.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dxhggBxwqVBj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "xF0idMRDqVBm"
   },
   "outputs": [],
   "source": [
    "##save all your results to disk so that, no need to run all again. \n",
    "#import pickle\n",
    "#.dump((x_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
    "#pickle.dump((x_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Leu1URGzqVBo"
   },
   "outputs": [],
   "source": [
    "#you can load from disk\n",
    "import pickle\n",
    "X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
    "X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjPv8VkJqVBr"
   },
   "source": [
    "<font size=4>Grader function 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qekHJgmdqVBs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_train():\n",
    "    out = False\n",
    "    \n",
    "    if type(X_train_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_train_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_train_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "\n",
    "grader_alltokens_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnvC6X_wqVBu"
   },
   "source": [
    "<font size=4>Grader function 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Av4SRMPSqVBv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_test():\n",
    "    out = False\n",
    "    if type(X_test_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_test_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_test_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_alltokens_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEj-Eua5qVBx"
   },
   "source": [
    "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
    "We already created the BERT model in the part-2 and input data in the part-3. \n",
    "We will utlize those two and will get the embeddings for each sentence in the \n",
    "Train and test data.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QwOVgQFDqVBy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_word_ids')>,\n",
       " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_mask')>,\n",
       " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'segment_ids')>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ZcpkQq1OqVB0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "IxdIlOIBlm7j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 317s 125ms/step\n"
     ]
    }
   ],
   "source": [
    "# get the train output, BERT model will give one output so save in\n",
    "# X_train_pooled_output\n",
    "#this cell will take some time to execute, make sure thay you have stable internet connection\n",
    "X_train_pooled_output=bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "yZT11BCol4gL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 78s 125ms/step\n"
     ]
    }
   ],
   "source": [
    "# get the test output, BERT model will give one output so save in\n",
    "# X_test_pooled_output\n",
    "X_test_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "DL6JVojfqVB8"
   },
   "outputs": [],
   "source": [
    "##save all your results to disk so that, no need to run all again. \n",
    "#pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump((x_train,y_train),open('training_data.pkl','wb'))\n",
    "#pickle.dump((x_test,y_test),open('testing_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oSQcBdROqVB9"
   },
   "outputs": [],
   "source": [
    "X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))\n",
    "#x_train,y_train= pickle.load(open('training_data.pkl', 'rb'))\n",
    "#x_test,y_test = pickle.load(open('testing_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulEXFE7aqVCA"
   },
   "source": [
    "<font size=4>Grader function 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oHCsW0IvqVCB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have X_train_pooled_output, y_train\n",
    "#X_test_pooled_ouput, y_test\n",
    "\n",
    "#please use this grader to evaluate\n",
    "def greader_output():\n",
    "    assert(X_train_pooled_output.shape[1]==768)\n",
    "    assert(len(y_train)==len(X_train_pooled_output))\n",
    "    assert(X_test_pooled_output.shape[1]==768)\n",
    "    assert(len(y_test)==len(X_test_pooled_output))\n",
    "    assert(len(y_train.shape)==1)\n",
    "    assert(len(X_train_pooled_output.shape)==2)\n",
    "    assert(len(y_test.shape)==1)\n",
    "    assert(len(X_test_pooled_output.shape)==2)\n",
    "    return True\n",
    "greader_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYwS1QbAqVCD"
   },
   "source": [
    "<pre><font size=6>Part-5: Training a NN with 768 features</font>\n",
    "\n",
    "Create a NN and train the NN. \n",
    "1.<b> You have to use AUC as metric. Do not use tf.keras.metrics.AUC</b> \n",
    "<b> You have to write custom code for AUC and print it at the end of each epoch</b> \n",
    "2. You can use any architecture you want. \n",
    "3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n",
    "4. Print the loss and metric at every epoch. \n",
    "5. You have to submit without overfitting and underfitting. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_class=2\n",
    "y_train=tf.keras.utils.to_categorical(y_train, num_of_class)\n",
    "y_test=tf.keras.utils.to_categorical(y_test, num_of_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_1, x_cv, y_train_1, y_cv=train_test_split(X_train_pooled_output,y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, LSTM\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DSnmX3WnqVCG"
   },
   "outputs": [],
   "source": [
    "##create an Neural Network and train your model on X_train_pooled_output and y_train\n",
    "# you can start as follows\n",
    "input_layer=Input(shape=(X_train_pooled_output.shape[1],1))\n",
    "layer_1=LSTM(32,return_sequences=True)(input_layer)\n",
    "layer_1=Flatten()(layer_1)\n",
    "layer_1=tf.keras.layers.BatchNormalization()(layer_1)\n",
    "layer_2=Dense(64,'relu',kernel_initializer=tf.keras.initializers.HeNormal(10))(layer_1)\n",
    "layer_3=Dropout(0.3)(layer_2)\n",
    "layer_4=Dense(32,'relu',kernel_initializer=tf.keras.initializers.HeNormal(30))(layer_3)\n",
    "layer_5=Dense(16,'relu',kernel_initializer=tf.keras.initializers.HeNormal(40))(layer_4)\n",
    "layer_6=Dense(8,'relu',kernel_initializer=tf.keras.initializers.HeNormal(60))(layer_5)\n",
    "layer_6=Dense(2,'relu',kernel_initializer=tf.keras.initializers.HeNormal(60))(layer_6)\n",
    "\n",
    "output=Dense(2,activation='sigmoid')(layer_6)\n",
    "\n",
    "model=Model(inputs=input_layer, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 768, 1)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 768, 32)           4352      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24576)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24576)            98304     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1572928   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,678,352\n",
      "Trainable params: 1,629,200\n",
      "Non-trainable params: 49,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.84733764, 0.57468622])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(y),y=y)\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl={0:class_weights[0],1:class_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class RocCallback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_train = self.model.predict(self.x, batch_size=128)\n",
    "        roc_train = roc_auc_score(self.y, y_pred_train)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc_train: %s - roc-auc_val: %s' % (str(round(roc_train,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)\n",
    "\n",
    "paths='saved_models/final_models/f_model.hdf5'\n",
    "\n",
    "checkpoint_save = tf.keras.callbacks.ModelCheckpoint(paths, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "training_data=(x_train_1,y_train_1)\n",
    "validation_data=(x_cv,y_cv)\n",
    "\n",
    "#auc=RocCallback(training_data,validation_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/55968792/why-do-my-models-keep-getting-exactly-0-5-auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),loss='categorical_crossentropy', metrics=[auc,'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.4442 - auc: 0.8775 - accuracy: 0.7355\n",
      "Epoch 1: val_auc improved from -inf to 0.93819, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 43s 40ms/step - loss: 0.4440 - auc: 0.8777 - accuracy: 0.7357 - val_loss: 0.3869 - val_auc: 0.9382 - val_accuracy: 0.8116 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.3446 - auc: 0.9304 - accuracy: 0.8230\n",
      "Epoch 2: val_auc improved from 0.93819 to 0.94464, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.3446 - auc: 0.9304 - accuracy: 0.8230 - val_loss: 0.3442 - val_auc: 0.9446 - val_accuracy: 0.8314 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.3234 - auc: 0.9391 - accuracy: 0.8410\n",
      "Epoch 3: val_auc improved from 0.94464 to 0.94483, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3236 - auc: 0.9391 - accuracy: 0.8409 - val_loss: 0.3764 - val_auc: 0.9448 - val_accuracy: 0.8133 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3099 - auc: 0.9438 - accuracy: 0.8429\n",
      "Epoch 4: val_auc improved from 0.94483 to 0.94902, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3100 - auc: 0.9438 - accuracy: 0.8429 - val_loss: 0.2890 - val_auc: 0.9490 - val_accuracy: 0.8625 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3003 - auc: 0.9477 - accuracy: 0.8516\n",
      "Epoch 5: val_auc did not improve from 0.94902\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3005 - auc: 0.9477 - accuracy: 0.8517 - val_loss: 0.3051 - val_auc: 0.9489 - val_accuracy: 0.8608 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2937 - auc: 0.9491 - accuracy: 0.8562\n",
      "Epoch 6: val_auc improved from 0.94902 to 0.95161, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2937 - auc: 0.9491 - accuracy: 0.8562 - val_loss: 0.3080 - val_auc: 0.9516 - val_accuracy: 0.8539 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2930 - auc: 0.9501 - accuracy: 0.8621\n",
      "Epoch 7: val_auc improved from 0.95161 to 0.95323, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.2930 - auc: 0.9501 - accuracy: 0.8621 - val_loss: 0.3292 - val_auc: 0.9532 - val_accuracy: 0.8473 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2871 - auc: 0.9525 - accuracy: 0.8627\n",
      "Epoch 8: val_auc improved from 0.95323 to 0.95362, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2871 - auc: 0.9525 - accuracy: 0.8627 - val_loss: 0.3384 - val_auc: 0.9536 - val_accuracy: 0.8398 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 0.2819 - auc: 0.9537 - accuracy: 0.8626\n",
      "Epoch 9: val_auc improved from 0.95362 to 0.95548, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2817 - auc: 0.9538 - accuracy: 0.8626 - val_loss: 0.3154 - val_auc: 0.9555 - val_accuracy: 0.8509 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2799 - auc: 0.9540 - accuracy: 0.8617\n",
      "Epoch 10: val_auc did not improve from 0.95548\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2799 - auc: 0.9540 - accuracy: 0.8617 - val_loss: 0.3203 - val_auc: 0.9550 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2784 - auc: 0.9562 - accuracy: 0.8641\n",
      "Epoch 11: val_auc improved from 0.95548 to 0.95802, saving model to saved_models/final_models/f_model.hdf5\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2783 - auc: 0.9562 - accuracy: 0.8640 - val_loss: 0.2698 - val_auc: 0.9580 - val_accuracy: 0.8751 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      " 163/1000 [===>..........................] - ETA: 17s - loss: 0.2703 - auc: 0.9573 - accuracy: 0.8731"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'EagerPyFunc' defined at (most recent call last):\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 530, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_13167/1570016512.py\", line 5, in <module>\n      model.fit(x_train_1,y_train_1,epochs=30,batch_size=64,class_weight=cl,validation_data=(x_cv,y_cv), callbacks=[learning_rate_reduction,checkpoint_save])\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1028, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1122, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/tmp/ipykernel_13167/618321739.py\", line 4, in auc\n      return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)\nNode: 'EagerPyFunc'\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n    return _average_binary_score(\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n    raise ValueError(\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[{{node EagerPyFunc}}]] [Op:__inference_train_function_65566]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.0001\u001b[39m),loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[auc,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_cv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlearning_rate_reduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcheckpoint_save\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'EagerPyFunc' defined at (most recent call last):\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 530, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_13167/1570016512.py\", line 5, in <module>\n      model.fit(x_train_1,y_train_1,epochs=30,batch_size=64,class_weight=cl,validation_data=(x_cv,y_cv), callbacks=[learning_rate_reduction,checkpoint_save])\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1028, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1122, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/tmp/ipykernel_13167/618321739.py\", line 4, in auc\n      return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)\nNode: 'EagerPyFunc'\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\nTraceback (most recent call last):\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n    return _average_binary_score(\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n\n  File \"/home/josephnadar1998/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n    raise ValueError(\n\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\n\n\t [[{{node EagerPyFunc}}]] [Op:__inference_train_function_65566]"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_1,y_train_1,epochs=30,batch_size=64,class_weight=cl,validation_data=(x_cv,y_cv), callbacks=[learning_rate_reduction,checkpoint_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The error occuring above is because at some point the batch selected in the model to calculate AUC is selecting data points of single class.\n",
    "model.load_weights('saved_models/final_models/f_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 198s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test=model.predict(X_test_pooled_output, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.9607595314284852, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(auc(y_test[:,1],y_pred_test[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcILeYZI9pxm"
   },
   "source": [
    "<Pre><font size=6>Part-6: Creating a Data pipeline for BERT Model</font> \n",
    "1. Pipeline is a way to codify and automate the workflow.\n",
    "2. Download the test.csv file from here <a href=\"https://drive.google.com/file/d/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo/view?usp=sharing\">here</a> </pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_74n3sgFjvlM"
   },
   "outputs": [],
   "source": [
    "#there is an alterante way to load files from Google drive directly to your Colab session\n",
    "# you can use gdown module to import the files as follows\n",
    "#for example for test.csv you can write your code as !gdown --id file_id (remove the # from next line and run it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwv_BIV9xWt7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lQcoHbUKjgvF"
   },
   "outputs": [],
   "source": [
    "#read the csv file\n",
    "test_df= pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zii6hgejdhQ"
   },
   "source": [
    "<Pre>1. You have to write a function that takes the test_df,trained model and the required parameters as input. \n",
    "2. Perform all the preproceesing steps inside the function.\n",
    "- Remove all the html tags\n",
    "- Now do tokenization [Part 3 as mentioned above]\n",
    "- Create tokens,mask array and segment array\n",
    "- Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n",
    "- Print the shape of output(X_test.shape).You should get (352,768)\n",
    "3. Predict the output of X_test with the neural network model which we trained earlier.\n",
    "\n",
    "4. Return the occurences of class labels from the function.\n",
    "The output should be the count of datapoints classified as 1 or 0.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9g6C_kgjcan"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def final_model(df,model):\n",
    "    #Dropping NA values\n",
    "    df=df.dropna()\n",
    "    \n",
    "    #Renaming the dataframe to x_test\n",
    "    x_test=df['Text'].copy()\n",
    "    \n",
    "    def html_tag_remover(x):\n",
    "        pattern=r'<.+>'\n",
    "        a=re.sub(pattern,'',x)\n",
    "        return a\n",
    "    \n",
    "    x_test=x_test.apply(html_tag_remover)\n",
    "    \n",
    "    x_test=x_test.astype(str)\n",
    "    \n",
    "    def preprocess(x):\n",
    "        tokens=x[:(max_seq_length-2)]\n",
    "        tokens=['[CLS]',*tokens,'[SEP]']\n",
    "        return tokens\n",
    "    \n",
    "    x_test_tokens=x_test.apply(tokenizer.tokenize)\n",
    "    x_test_tokens=x_test_tokens.apply(preprocess)\n",
    "    \n",
    "    def padding(x):\n",
    "        if len(x)>max_seq_length:\n",
    "            a=x[:max_seq_length]\n",
    "            a=np.array([*a,'[SEP]'])\n",
    "        \n",
    "        elif len(x)<max_seq_length:\n",
    "            a=x.copy()\n",
    "            pad=[]\n",
    "            for i in range((max_seq_length-len(x))):\n",
    "                pad.append('[PAD]')\n",
    "            a=np.array([*a,*pad])\n",
    "        else:\n",
    "            a=x\n",
    "        return a\n",
    "    \n",
    "    x_test_tokens=x_test_tokens.apply(padding)\n",
    "    \n",
    "    def masking(x):\n",
    "        mask=[]\n",
    "        for tokens in x:\n",
    "            if tokens=='[PAD]':\n",
    "                mask.append(0)\n",
    "            else:\n",
    "                mask.append(1)\n",
    "        return np.array(mask)\n",
    "    \n",
    "    \n",
    "    x_test_mask=x_test_tokens.apply(masking)\n",
    "    x_test_tokens=x_test_tokens.apply(tokenizer.convert_tokens_to_ids)\n",
    "    \n",
    "    #converting to numpy arrays\n",
    "    x_test_mask=np.array([np.array(i) for i in x_test_mask])\n",
    "    x_test_tokens=np.array([np.array(i) for i in x_test_tokens])\n",
    "    x_test_segment=np.ones(x_test_tokens.shape)\n",
    "    print(x_test_segment.shape)\n",
    "    x_test_bert_output=bert_model.predict([x_test_tokens,x_test_mask,x_test_segment])\n",
    "    \n",
    "    y_pred_test=model.predict(x_test_bert_output, batch_size=1)\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 55)\n",
      "11/11 [==============================] - 1s 125ms/step\n",
      "352/352 [==============================] - 5s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=final_model(test_df,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_test=y_test_pred[:,1]\n",
    "p_values_test[p_values_test>=0.5]=1\n",
    "p_values_test[p_values_test<0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Love them, very \"gingery\".  Great with your favorite tea or coffee.  Love that they are using natural ingredients.']\n",
      "[1.]\n",
      "**************************************************\n",
      "['My husband puts this on everything. It is very expensive to buy in the grocery store and it comes in a small bottle. This bottle is huge. It is a great buy. There is enough to bottle and give away to others.']\n",
      "[1.]\n",
      "**************************************************\n",
      "['I bought this popcorn when my in laws got me a popcorn maker for christmas.  This popcorn is BETTER then movie theater popcorn!  I will definitely be buying more once I run out!']\n",
      "[1.]\n",
      "**************************************************\n",
      "['These were nummy!  a bit over priced for one pound of nuts - but the quality is truly there! :)<br />I would order again!']\n",
      "[1.]\n",
      "**************************************************\n",
      "['We enjoy the taste and, having flax in it, is good for you. We can take care of our bodies and like the taste. A win-win!']\n",
      "[0.]\n",
      "**************************************************\n",
      "['I have never ordered sea salt before. i thought this was great. I was afraid it would have some additional flavor that I wouldnt like. Instead it was fresh tasting & natural. I like the pink color, but glad it doesnt come out pink.']\n",
      "[1.]\n",
      "**************************************************\n",
      "['I love this fudge. It just literally takes 5 minutes from start to finish and I think it tastes wonderful.  I like to give these as gifts during the holidays.  People can make their own fudge in minutes.<br />Sharon Jensen']\n",
      "[1.]\n",
      "**************************************************\n",
      "['Sweet, crunchy and healthy. The kids love these and so do the adults. I do wish the pieces were a bit bigger but still love them!']\n",
      "[1.]\n",
      "**************************************************\n",
      "[\"Well, though some others don't like...I happen to love them.  Apparently I am not the only one, since every store in my area keeps selling out of them the day they re-stock.  Delicious!\"]\n",
      "[1.]\n",
      "**************************************************\n",
      "[\"This product is delicious.  Not only that, it was delivered quickly and arrived in excellent condition.  It has a great flavor, not bitter.  I hadn't ordered this before but was pleasantly delighted by the prompt delivery and delicious taste and aroma.\"]\n",
      "[1.]\n",
      "**************************************************\n",
      "[\"I am pleased that this Gluten flour works very well.  I bought this gluten flour because I think it's a pretty good deal for the amount that's in the package.  I highly recommend this product because it is versatile.\"]\n",
      "[1.]\n",
      "**************************************************\n",
      "['their not only good for you but their yummy.they smell like cloves when their cooking and taste  a little sweet.']\n",
      "[1.]\n",
      "**************************************************\n",
      "['I love this oil! I use it for everything from cooking with it to using it as a moisturizer and on my scalp for dandruff. I would totally recommend this to everyone!']\n",
      "[1.]\n",
      "**************************************************\n",
      "['Love this product! Texture is just right -- touch gritty yet not heavy. If you plan on eating it with honey and butter, the sugar recommended in the recipe is enough, but for folks who prefer a sweeter cornbread, I would add more sugar or a bit of honey.']\n",
      "[1.]\n",
      "**************************************************\n",
      "['This is our preferred clam chowder . We like the natural taste with lots of potatoes. The only complaint is I think the soup can be creamier. Amazon has much better price on this with subscribe and save.']\n",
      "[0.]\n",
      "**************************************************\n",
      "[\"I don't like campbell's tomato soup and this tastes a lot like it, except that it has tofu, some vegies and a slight curry flavor. There wasn't anything special about the flavor or taste. I will finish the bag but won't be ordering more.\"]\n",
      "[0.]\n",
      "**************************************************\n",
      "[\"This is my favorite unflavored K Cup coffee.  I've tried many brands and flavors, and this one comes out on top.  It doesn't taste watered down like some of them do.  It has an excellent, medium-bodied flavor.\"]\n",
      "[1.]\n",
      "**************************************************\n",
      "[\"This powdered lime preparation is the closest thing to fresh citrus ever.  It's handy for mixed drinks, salad dressing, etc. It's priced well and I would definitely reorder it and recommend it to friends.\"]\n",
      "[1.]\n",
      "**************************************************\n",
      "[\"I used to say i'd never buy my groceries at a hardwhare store, but  chef boyardee is cheep there. .88/can. then they go on sale even cheaper.\"]\n",
      "[0.]\n",
      "**************************************************\n",
      "['They arrived in a nicely packaged box, so unbelievably cute and yummy. Will definitely buy from again.']\n",
      "[1.]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for values in range(20):\n",
    "    n=random.sample(range(len(p_values_test)),1)\n",
    "    print(test_df['Text'].values[n])\n",
    "    print(p_values_test[n])\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZc7XTQOxcIO"
   },
   "source": [
    "## Please write your observations at the end of notebook and  explain each and every step you followed in solving this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQfm5vO1xoVR"
   },
   "source": [
    "### Observations and Approach Taken:\n",
    "- As a first step, I watched all the lectures on BERT and then read through the blog, mentioned in the notebook to understand, how the classification is done using BERT Model.\n",
    "- Then I started following the instructions as mentioned in the Notebook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
