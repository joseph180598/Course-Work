{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "import csv\n",
    "from multiprocessing import Process# this isused for multithreading\n",
    "import multiprocessing \n",
    "import random as r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import dask.array as da\n",
    "import dask.distributed\n",
    "import pickle\n",
    "import pandas.util.testing as tm\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vocab=list(pd.read_csv('bigram_vocab.txt',delimiter=',',header=None, dtype=str).to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''bytebigram_vect = scipy.sparse.csr_matrix((10,20))\n",
    "type(random.sample(os.listdir('byteFiles_train'), len(os.listdir('byteFiles_train'))))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [1:24:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "#creating BOW of 2-gram data\n",
    "import random\n",
    "file_names=[]\n",
    "vector = CountVectorizer(lowercase=False,ngram_range=(2,2), vocabulary=bigram_vocab)\n",
    "bytebigram_vect = scipy.sparse.csr_matrix((2001, len(bigram_vocab)))\n",
    "for i, file in tqdm(enumerate(random.sample(os.listdir('byteFiles_train'),len(os.listdir('byteFiles_train'))))):\n",
    "    if file.endswith('.bytes'):\n",
    "        name=file.split('.')[0]\n",
    "        f = open('byteFiles_train/' + file)\n",
    "        bytebigram_vect[i]=scipy.sparse.csr_matrix(vector.transform([f.read().replace('\\n', ' ').upper()]))\n",
    "        file_names.append(file)\n",
    "        if i==2000:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pickle\n",
    "with open('Bigram_BOW_Vectors.pkl','wb') as f:\n",
    "    pickle.dump(bytebigram_vect, f)\n",
    "with open('file_names.pkl','wb') as f:\n",
    "    pickle.dump(file_names, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Bigram_BOW_Vectors.pkl','rb') as fe_data_file:\n",
    "    Bigram_BOW_Vectors=pickle.load(fe_data_file)\n",
    "with open('file_names.pkl','rb') as fe_data_file:\n",
    "    file_names=pickle.load(fe_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2001x70226 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 91222950 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bigram_BOW_Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y=pd.read_csv(\"trainLabels.csv\")\n",
    "total = len(Y)*1.\n",
    "ax=sns.countplot(x=\"Class\", data=Y)\n",
    "for p in ax.patches:\n",
    "        ax.annotate('{:.1f}%'.format(100*p.get_height()/total), (p.get_x()+0.1, p.get_height()+5))\n",
    "\n",
    "#put 11 ticks (therefore 10 steps), from 0 to the total number of rows in the dataframe\n",
    "ax.yaxis.set_ticks(np.linspace(0, total, 11))\n",
    "\n",
    "#adjust the ticklabel to the desired format, without changing the position of the ticks. \n",
    "ax.set_yticklabels(map('{:.1f}%'.format, 100*ax.yaxis.get_majorticklocs()/total))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2001/2001 [00:03<00:00, 528.28it/s]\n"
     ]
    }
   ],
   "source": [
    "list_of_files=file_names\n",
    "train=[]\n",
    "\n",
    "for files in list_of_files:\n",
    "    train.append(files.split('.')[0])\n",
    "\n",
    "class_detail=pd.read_csv('trainLabels.csv', delimiter=',')\n",
    "class_detail.shape\n",
    "\n",
    "train_class=[]\n",
    "for values in tqdm(train):\n",
    "    train_class.append(int(class_detail[class_detail['Id']==values]['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5; 1/10] START colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:26:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 1/10] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3;, score=0.970 total time= 3.9min\n",
      "[CV 2/5; 1/10] START colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 1/10] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3;, score=0.978 total time= 3.6min\n",
      "[CV 3/5; 1/10] START colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:33:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 1/10] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3;, score=0.970 total time= 3.5min\n",
      "[CV 4/5; 1/10] START colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 1/10] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3;, score=0.985 total time= 3.6min\n",
      "[CV 5/5; 1/10] START colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 1/10] END colsample_bytree=0.1, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.3;, score=0.983 total time= 3.6min\n",
      "[CV 1/5; 2/10] START colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 2/10] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5;, score=0.975 total time=10.5min\n",
      "[CV 2/5; 2/10] START colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:54:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 2/10] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5;, score=0.983 total time=10.5min\n",
      "[CV 3/5; 2/10] START colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 2/10] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5;, score=0.973 total time=10.6min\n",
      "[CV 4/5; 2/10] START colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:15:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 2/10] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5;, score=0.990 total time=10.7min\n",
      "[CV 5/5; 2/10] START colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 2/10] END colsample_bytree=0.3, learning_rate=0.15, max_depth=10, n_estimators=200, subsample=0.5;, score=0.985 total time=10.7min\n",
      "[CV 1/5; 3/10] START colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 3/10] END colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1;, score=0.948 total time= 6.5min\n",
      "[CV 2/5; 3/10] START colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 3/10] END colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1;, score=0.943 total time= 6.5min\n",
      "[CV 3/5; 3/10] START colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:50:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 3/10] END colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1;, score=0.945 total time= 6.4min\n",
      "[CV 4/5; 3/10] START colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:56:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 3/10] END colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1;, score=0.955 total time= 6.5min\n",
      "[CV 5/5; 3/10] START colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 3/10] END colsample_bytree=0.5, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.1;, score=0.963 total time= 6.5min\n",
      "[CV 1/5; 4/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 4/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5;, score=0.975 total time=16.9min\n",
      "[CV 2/5; 4/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:26:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 4/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5;, score=0.985 total time=17.0min\n",
      "[CV 3/5; 4/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:43:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 4/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5;, score=0.975 total time=16.8min\n",
      "[CV 4/5; 4/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 4/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5;, score=0.990 total time=17.3min\n",
      "[CV 5/5; 4/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:17:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 4/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.5;, score=0.985 total time=17.3min\n",
      "[CV 1/5; 5/10] START colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 5/10] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5;, score=0.975 total time=11.3min\n",
      "[CV 2/5; 5/10] START colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:46:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 5/10] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5;, score=0.983 total time=11.3min\n",
      "[CV 3/5; 5/10] START colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:57:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 5/10] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5;, score=0.978 total time=11.3min\n",
      "[CV 4/5; 5/10] START colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:08:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 5/10] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5;, score=0.990 total time=11.5min\n",
      "[CV 5/5; 5/10] START colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:20:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 5/10] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.5;, score=0.985 total time=11.5min\n",
      "[CV 1/5; 6/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:32:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 6/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1;, score=0.963 total time=13.5min\n",
      "[CV 2/5; 6/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:45:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 6/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1;, score=0.973 total time=13.5min\n",
      "[CV 3/5; 6/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:58:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 6/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1;, score=0.960 total time=13.4min\n",
      "[CV 4/5; 6/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 6/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1;, score=0.973 total time=13.6min\n",
      "[CV 5/5; 6/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:25:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 6/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.1;, score=0.973 total time=13.5min\n",
      "[CV 1/5; 7/10] START colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:39:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 7/10] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.975 total time= 3.8min\n",
      "[CV 2/5; 7/10] START colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:43:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 7/10] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.988 total time= 3.8min\n",
      "[CV 3/5; 7/10] START colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:46:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 7/10] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.973 total time= 3.8min\n",
      "[CV 4/5; 7/10] START colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 7/10] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.990 total time= 3.8min\n",
      "[CV 5/5; 7/10] START colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:54:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 7/10] END colsample_bytree=0.1, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.5;, score=0.983 total time= 3.8min\n",
      "[CV 1/5; 8/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 8/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3;, score=0.970 total time= 7.7min\n",
      "[CV 2/5; 8/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:06:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 8/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3;, score=0.975 total time= 7.7min\n",
      "[CV 3/5; 8/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:13:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 8/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3;, score=0.970 total time= 7.7min\n",
      "[CV 4/5; 8/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:21:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 8/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3;, score=0.975 total time= 7.8min\n",
      "[CV 5/5; 8/10] START colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 8/10] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.3;, score=0.980 total time= 7.8min\n",
      "[CV 1/5; 9/10] START colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 9/10] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.973 total time= 3.3min\n",
      "[CV 2/5; 9/10] START colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 9/10] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.980 total time= 3.3min\n",
      "[CV 3/5; 9/10] START colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:43:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 9/10] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.975 total time= 3.3min\n",
      "[CV 4/5; 9/10] START colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:46:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 9/10] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.990 total time= 3.4min\n",
      "[CV 5/5; 9/10] START colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:50:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 9/10] END colsample_bytree=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5;, score=0.980 total time= 3.3min\n",
      "[CV 1/5; 10/10] START colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 10/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1;, score=0.970 total time= 9.1min\n",
      "[CV 2/5; 10/10] START colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 10/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1;, score=0.968 total time= 8.9min\n",
      "[CV 3/5; 10/10] START colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:11:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 10/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1;, score=0.953 total time= 8.9min\n",
      "[CV 4/5; 10/10] START colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 10/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1;, score=0.978 total time= 9.0min\n",
      "[CV 5/5; 10/10] START colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 10/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200, subsample=0.1;, score=0.968 total time= 9.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:38:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   param_distributions={'colsample_bytree': [0.1, 0.3, 0.5],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [3, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 500],\n",
       "                                        'subsample': [0.1, 0.3, 0.5]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "x_cfl=XGBClassifier()\n",
    "\n",
    "prams={\n",
    "    'learning_rate':[0.05,0.1,0.15,0.2],\n",
    "     'n_estimators':[100,200,500],\n",
    "     'max_depth':[3,5,10],\n",
    "    'colsample_bytree':[0.1,0.3,0.5],\n",
    "    'subsample':[0.1,0.3,0.5]\n",
    "}\n",
    "\n",
    "random_cfl1=RandomizedSearchCV(x_cfl,param_distributions=prams,verbose=10)\n",
    "random_cfl1.fit(Bigram_BOW_Vectors,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.431162</td>\n",
       "      <td>9.358935</td>\n",
       "      <td>0.353105</td>\n",
       "      <td>0.105327</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'subsample': 0.3, 'n_estimators': 200, 'max_d...</td>\n",
       "      <td>0.970075</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.977015</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>634.950581</td>\n",
       "      <td>4.831496</td>\n",
       "      <td>0.321854</td>\n",
       "      <td>0.044849</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'subsample': 0.5, 'n_estimators': 200, 'max_d...</td>\n",
       "      <td>0.975062</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.981012</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388.345574</td>\n",
       "      <td>1.801027</td>\n",
       "      <td>0.300310</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'subsample': 0.1, 'n_estimators': 100, 'max_d...</td>\n",
       "      <td>0.947631</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.950526</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023.654483</td>\n",
       "      <td>11.751223</td>\n",
       "      <td>0.287481</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'subsample': 0.5, 'n_estimators': 200, 'max_d...</td>\n",
       "      <td>0.975062</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.982012</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>684.127961</td>\n",
       "      <td>6.289563</td>\n",
       "      <td>0.293720</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'subsample': 0.5, 'n_estimators': 200, 'max_d...</td>\n",
       "      <td>0.975062</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.982012</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>808.397487</td>\n",
       "      <td>3.366739</td>\n",
       "      <td>0.303098</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'subsample': 0.1, 'n_estimators': 500, 'max_d...</td>\n",
       "      <td>0.962594</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.968019</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>226.561200</td>\n",
       "      <td>1.023575</td>\n",
       "      <td>0.281229</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'subsample': 0.5, 'n_estimators': 200, 'max_d...</td>\n",
       "      <td>0.975062</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.981512</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>464.810097</td>\n",
       "      <td>3.312047</td>\n",
       "      <td>0.281229</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'subsample': 0.3, 'n_estimators': 100, 'max_d...</td>\n",
       "      <td>0.970075</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.974015</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>198.697256</td>\n",
       "      <td>1.702082</td>\n",
       "      <td>0.281221</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'subsample': 0.5, 'n_estimators': 100, 'max_d...</td>\n",
       "      <td>0.972569</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.979514</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>539.039302</td>\n",
       "      <td>3.445117</td>\n",
       "      <td>0.293719</td>\n",
       "      <td>0.011696</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'subsample': 0.1, 'n_estimators': 200, 'max_d...</td>\n",
       "      <td>0.970075</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.967015</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     216.431162      9.358935         0.353105        0.105327   \n",
       "1     634.950581      4.831496         0.321854        0.044849   \n",
       "2     388.345574      1.801027         0.300310        0.006907   \n",
       "3    1023.654483     11.751223         0.287481        0.007655   \n",
       "4     684.127961      6.289563         0.293720        0.011694   \n",
       "5     808.397487      3.366739         0.303098        0.007658   \n",
       "6     226.561200      1.023575         0.281229        0.009883   \n",
       "7     464.810097      3.312047         0.281229        0.009884   \n",
       "8     198.697256      1.702082         0.281221        0.000010   \n",
       "9     539.039302      3.445117         0.293719        0.011696   \n",
       "\n",
       "  param_subsample param_n_estimators param_max_depth param_learning_rate  \\\n",
       "0             0.3                200               5                0.15   \n",
       "1             0.5                200              10                0.15   \n",
       "2             0.1                100               5                0.05   \n",
       "3             0.5                200               5                0.05   \n",
       "4             0.5                200               3                 0.1   \n",
       "5             0.1                500               5                0.05   \n",
       "6             0.5                200               5                 0.2   \n",
       "7             0.3                100               5                0.05   \n",
       "8             0.5                100               5                 0.1   \n",
       "9             0.1                200              10                 0.1   \n",
       "\n",
       "  param_colsample_bytree                                             params  \\\n",
       "0                    0.1  {'subsample': 0.3, 'n_estimators': 200, 'max_d...   \n",
       "1                    0.3  {'subsample': 0.5, 'n_estimators': 200, 'max_d...   \n",
       "2                    0.5  {'subsample': 0.1, 'n_estimators': 100, 'max_d...   \n",
       "3                    0.3  {'subsample': 0.5, 'n_estimators': 200, 'max_d...   \n",
       "4                    0.3  {'subsample': 0.5, 'n_estimators': 200, 'max_d...   \n",
       "5                    0.3  {'subsample': 0.1, 'n_estimators': 500, 'max_d...   \n",
       "6                    0.1  {'subsample': 0.5, 'n_estimators': 200, 'max_d...   \n",
       "7                    0.3  {'subsample': 0.3, 'n_estimators': 100, 'max_d...   \n",
       "8                    0.1  {'subsample': 0.5, 'n_estimators': 100, 'max_d...   \n",
       "9                    0.5  {'subsample': 0.1, 'n_estimators': 200, 'max_d...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.970075             0.9775             0.9700             0.9850   \n",
       "1           0.975062             0.9825             0.9725             0.9900   \n",
       "2           0.947631             0.9425             0.9450             0.9550   \n",
       "3           0.975062             0.9850             0.9750             0.9900   \n",
       "4           0.975062             0.9825             0.9775             0.9900   \n",
       "5           0.962594             0.9725             0.9600             0.9725   \n",
       "6           0.975062             0.9875             0.9725             0.9900   \n",
       "7           0.970075             0.9750             0.9700             0.9750   \n",
       "8           0.972569             0.9800             0.9750             0.9900   \n",
       "9           0.970075             0.9675             0.9525             0.9775   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.9825         0.977015        0.006188                6  \n",
       "1             0.9850         0.981012        0.006430                4  \n",
       "2             0.9625         0.950526        0.007304               10  \n",
       "3             0.9850         0.982012        0.005985                1  \n",
       "4             0.9850         0.982012        0.005322                1  \n",
       "5             0.9725         0.968019        0.005549                8  \n",
       "6             0.9825         0.981512        0.006807                3  \n",
       "7             0.9800         0.974015        0.003726                7  \n",
       "8             0.9800         0.979514        0.005984                5  \n",
       "9             0.9675         0.967015        0.008130                9  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_cfl1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=0.5,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cfl1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=XGBClassifier(learning_rate=0.05, n_estimators=200,max_depth=5, colsample_bytree=0.3 )\n",
    "clf.fit(Bigram_BOW_Vectors,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features=np.argsort(clf.feature_importances_)\n",
    "sorted_top_features=[bigram_vocab[i] for i in top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_top_features.pkl','wb') as wr:\n",
    "    pickle.dump(sorted_top_features, wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.predict_proba(Bigram_BOW_Vectors)\n",
    "loss=log_loss(y_train,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003193845667999409"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
